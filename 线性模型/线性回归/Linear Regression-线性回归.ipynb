{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¹¿ä¹‰çº¿æ€§æ¨¡å‹ Generalized Linear Models\n",
    "---\n",
    "æœ¬ç« ä¸»è¦è®²è¿°ä¸€äº›ç”¨äºå›å½’çš„æ–¹æ³•ï¼Œå…¶ä¸­ç›®æ ‡å€¼ y æ˜¯è¾“å…¥å˜é‡ x çš„çº¿æ€§ç»„åˆã€‚ æ•°å­¦æ¦‚å¿µè¡¨ç¤ºä¸ºï¼šå¦‚æœ$\\hat{y}$æ˜¯é¢„æµ‹å€¼ï¼Œé‚£ä¹ˆæœ‰ï¼š\n",
    "\n",
    "$\\hat{y}(\\theta, x) = \\theta^{(0)} + \\theta^{(1)} x^{(1)} + ... + \\theta^{(p)} x^{(p)}$\n",
    "\n",
    "åœ¨æ•´ä¸ªæ¨¡å—ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰å‘é‡ $w = (\\theta_1,..., \\theta_p)$ ä½œä¸º`coef_`(coefficient, å›å½’ç³»æ•°)ï¼Œå®šä¹‰ $\\theta_0$ ä½œä¸º `intercept_`æˆªè·.\n",
    "çº¿æ€§æ¨¡å‹è™½ç®€å•, å´æœ‰ä¸°å¯Œçš„å˜åŒ–.è€ƒè™‘å•è°ƒå¯å¾®å‡½æ•°$g(\\cdot)$\n",
    "($g(\\cdot)$è¿ç»­ä¸”å……åˆ†å…‰æ»‘), ä»¤\n",
    "\n",
    "$$y = g^{-1}(\\theta^Tx+b)$$\n",
    "è¿™æ ·å¾—åˆ°çš„æ¨¡å‹ç§°ä¸º`å¹¿ä¹‰çº¿æ€§æ¨¡å‹`,å‡½æ•°$g(\\cdot)$ç§°ä¸º`è”ç³»å‡½æ•°`(link function). å¯¹æ•°çº¿æ€§å›å½’(Logistic Regression)æ˜¯$g(\\cdot)=ln(\\cdot)$æ—¶çš„ç‰¹ä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## çº¿æ€§å›å½’\n",
    "---\n",
    "\n",
    "å›å½’çš„ç›®çš„æ˜¯é¢„æµ‹æ•°å€¼å‹çš„ç›®æ ‡å€¼ã€‚æœ€ç›´æ¥çš„åŠæ³•æ˜¯ä¾æ®è¾“å…¥å†™å‡ºä¸€ä¸ªç›®æ ‡å€¼çš„è®¡ç®—å…¬å¼ã€‚\n",
    "\n",
    "å‡å¦‚ä½ æƒ³è¦é¢„æµ‹å…°åšåŸºå°¼è·‘è½¦çš„åŠŸç‡å¤§å°ï¼Œå¯èƒ½ä¼šè¿™æ ·è®¡ç®—:\n",
    "\n",
    "HorsePower = 0.0015 * annualSalary - 0.99 * hoursListeningToPublicRadio\n",
    "\n",
    "è¿™å°±æ˜¯æ‰€è°“çš„ `å›å½’æ–¹ç¨‹(regression equation)`ï¼Œå…¶ä¸­çš„ 0.0015 å’Œ -0.99 ç§°ä½œ `å›å½’ç³»æ•°ï¼ˆregression weightsï¼‰`ï¼Œæ±‚è¿™äº›å›å½’ç³»æ•°çš„è¿‡ç¨‹å°±æ˜¯å›å½’ã€‚\n",
    "\n",
    "ç»™å®šæ•°æ®é›† $D = \\{(x_1, y_1), (x_2, y_2), \\cdots, (x_n, y_n)\\}$, å…¶ä¸­$x_i=(x_i^{(1)}, x_i^{(2)}, \\cdots, x_i^{(d)}), y_i \\in \\mathbb{R}$. çº¿æ€§å›å½’(linear regression)è¯•å›¾å­¦å¾—ä¸€ä¸ªçº¿æ€§æ¨¡å‹ä»¥å°½å¯èƒ½å‡†ç¡®åœ°é¢„æµ‹å®å€¼è¾“å‡ºæ ‡è®°.\n",
    "$$f(x_i) = \\theta^T x_i, ä½¿å¾—f(x_i)\\simeq y_i$$\n",
    "\n",
    "å¯¹äºç¦»æ•£å±æ€§, è‹¥å±æ€§å€¼ä¹‹é—´å­˜åœ¨`åº`(order)å…³ç³», å¯é€šè¿‡è¿ç»­åŒ–å°†å…¶è½¬ä¸ºè¿ç»­å€¼; è‹¥å±æ€§å€¼é—´ä¸å­˜åœ¨åºå…³ç³»,å‡å®šæœ‰kä¸ªå±æ€§å€¼, åˆ™é€šå¸¸å°†å…¶è½¬ä¸ºkç»´å‘é‡(OneHotEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ™®é€šæœ€å°äºŒä¹˜æ³• Ordinary Least Squares\n",
    "---\n",
    "LinearRegression æ‹Ÿåˆä¸€ä¸ªå¸¦æœ‰ç³»æ•°$w = (\\theta^{(0)}, ...,\\theta^{(p)})$çš„çº¿æ€§æ¨¡å‹ï¼Œä½¿å¾—æ•°æ®é›†å®é™…è§‚æµ‹æ•°æ®å’Œé¢„æµ‹æ•°æ®ï¼ˆä¼°è®¡å€¼ï¼‰ä¹‹é—´çš„æ®‹å·®å¹³æ–¹å’Œ(å¯¹åº”äº†å¸¸ç”¨çš„æ¬§å‡ é‡Œå¾—è·ç¦»Euclidean distance)æœ€å°ã€‚å…¶æ•°å­¦è¡¨è¾¾å¼ä¸º:\n",
    "$$\\underset{\\theta}{min} {|| X\\theta - y||_2}^2$$\n",
    "æ±‚è§£\\thetaä½¿$E_{\\theta} = \\sum_{i=1}^{p}(\\theta^Tx_i-y_i)^2$(loss function)æœ€å°åŒ–çš„è¿‡ç¨‹, ç§°ä¸ºçº¿æ€§å›å½’æ¨¡å‹çš„æœ€å°äºŒä¹˜`å‚æ•°ä¼°è®¡`(parameter estimation). $E_{\\theta}$æ˜¯å…³äº$w$çš„å‡¸å‡½æ•°, å¯ä»¥ä»¤å…¶å¯¹$\\theta$å¹¶ä»¤å¯¼æ•°ä¸º0, å¾—åˆ°$\\theta$çš„æœ€ä¼˜è§£çš„é—­å¼(closed-form)è§£.\n",
    "\n",
    "ç”¨çŸ©é˜µå½¢å¼å¯ä»¥å†™æˆ$E_{\\theta} = (y-X\\theta)^T(y-X\\theta)$, å¯¹$w$æ±‚å¯¼å¾—åˆ°:\n",
    "$\\frac {\\partial E_\\theta}{\\partial \\theta} = 2X^T(X\\theta-y)$, ä»¤å…¶ä¸º0å¾—åˆ°$\\hat\\theta = (X^TX)^{-1}X^Ty$\n",
    "\n",
    "éœ€è¦å¯¹çŸ©é˜µæ±‚é€†ï¼Œå› æ­¤è¿™ä¸ªæ–¹ç¨‹åªåœ¨é€†çŸ©é˜µå­˜åœ¨çš„æ—¶å€™é€‚ç”¨ï¼Œæˆ‘ä»¬åœ¨ç¨‹åºä»£ç ä¸­å¯¹æ­¤ä½œå‡ºåˆ¤æ–­ã€‚ åˆ¤æ–­çŸ©é˜µæ˜¯å¦å¯é€†çš„ä¸€ä¸ªå¯é€‰æ–¹æ¡ˆæ˜¯:\n",
    "\n",
    "åˆ¤æ–­çŸ©é˜µçš„è¡Œåˆ—å¼æ˜¯å¦ä¸º 0ï¼Œè‹¥ä¸º0ï¼ŒçŸ©é˜µå°±ä¸å­˜åœ¨é€†çŸ©é˜µï¼Œä¸ä¸º0çš„è¯ï¼ŒçŸ©é˜µæ‰å­˜åœ¨é€†çŸ©é˜µã€‚\n",
    "\n",
    "[çŸ©é˜µæ±‚å¯¼å‚è€ƒ1](https://blog.csdn.net/daaikuaichuan/article/details/80620518)\n",
    "\n",
    "[çŸ©é˜µæ±‚å¯¼å‚è€ƒ2](http://blog.csdn.net/nomadlx53/article/details/50849941)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¾‹å­æ¥è‡ª**[æœºå™¨å­¦ä¹ å®æˆ˜](https://github.com/apachecn/AiLearning/blob/master/docs/ml/8.%E5%9B%9E%E5%BD%92.md)**\n",
    "___\n",
    "æ•°æ®æ ¼å¼\n",
    "## 1. çº¿æ€§å›å½’\n",
    "```\n",
    "x0       x1       y\n",
    "1.000000\t0.067732\t3.176513\n",
    "1.000000\t0.427810\t3.816464\n",
    "1.000000\t0.995731\t4.550095\n",
    "1.000000\t0.738336\t4.256571\n",
    "1.000000\t0.981083\t4.560815\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingularMatrixError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å–X å’Œ y\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "X  # ä¿æŒ X ä¸º n_sample * n_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def least_squares(X, y):\n",
    "        A = X.T * X\n",
    "        if np.linalg.det(A) == 0.0:\n",
    "            print('...')\n",
    "        w = A.I * X.T * y\n",
    "        return w\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.mat(X)\n",
    "        y = np.mat(y[:, np.newaxis])\n",
    "        theta = self.least_squares(X, y)  # n_feature * 1\n",
    "        self.intercept_ = theta[0, 0]\n",
    "        self.coef_ = np.array(theta[1:, 0]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression1():\n",
    "    data = np.loadtxt('data.txt')\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X, y)\n",
    "    print(clf.coef_, clf.intercept_)\n",
    "    \n",
    "    def line_(x0):\n",
    "        return clf.coef_[0] * x0 + clf.intercept_\n",
    "    \n",
    "    def corr_(X, y):\n",
    "        # ä½¿ç”¨é¢„æµ‹å€¼f(x)å’Œyçš„ç›¸å…³ç³»æ•°æ¥è¡¨ç¤º, é¢„æµ‹å€¼å’Œå®é™…å€¼çš„åŒ¹é…ç¨‹åº¦\n",
    "        corr = np.corrcoef(line_(X[:, 1]).ravel(), y)\n",
    "        print(f'ç›¸å…³ç³»æ•°:\\n{corr}\\n')\n",
    "        \n",
    "    corr_(X, y)\n",
    "    plt.figure()\n",
    "    plt.scatter(X[:,1], y[:], c='r', edgecolors='k')\n",
    "    xmin, xmax = X[:, 1].min(), X[:, 1].max()\n",
    "    plt.plot([xmin, xmax], [line_(xmin), line_(xmax)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ä½¿ç”¨ sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "data = np.loadtxt('data.txt')\n",
    "X, y = data[:, [1]], data[:, -1]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=123)\n",
    "clf = LinearRegression()\n",
    "clf.fit(X, y)\n",
    "clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ™®é€šæœ€å°äºŒä¹˜æ³•çš„å¤æ‚åº¦\n",
    "è¯¥æ–¹æ³•ä½¿ç”¨ X çš„å¥‡å¼‚å€¼åˆ†è§£æ¥è®¡ç®—æœ€å°äºŒä¹˜è§£ã€‚å¦‚æœ X æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º (n_samples, n_features)çš„çŸ©é˜µï¼Œè®¾$$n_{samples} \\geq n_{features}$$, åˆ™è¯¥æ–¹æ³•çš„å¤æ‚åº¦ä¸º$$O(n_{samples} n_{fearures}^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 å±€éƒ¨åŠ æƒçº¿æ€§å›å½’\n",
    "---\n",
    "çº¿æ€§å›å½’çš„ä¸€ä¸ªé—®é¢˜æ˜¯æœ‰å¯èƒ½å‡ºç°æ¬ æ‹Ÿåˆç°è±¡ï¼Œå› ä¸ºå®ƒæ±‚çš„æ˜¯å…·æœ‰æœ€å°å‡æ–¹å·®çš„æ— åä¼°è®¡ã€‚æ˜¾è€Œæ˜“è§ï¼Œå¦‚æœæ¨¡å‹æ¬ æ‹Ÿåˆå°†ä¸èƒ½å–å¾—æœ€å¥½çš„é¢„æµ‹æ•ˆæœã€‚æ‰€ä»¥æœ‰äº›æ–¹æ³•å…è®¸åœ¨ä¼°è®¡ä¸­å¼•å…¥ä¸€äº›åå·®ï¼Œä»è€Œé™ä½é¢„æµ‹çš„å‡æ–¹è¯¯å·®ã€‚\n",
    "\n",
    "ä¸€ä¸ªæ–¹æ³•æ˜¯`å±€éƒ¨åŠ æƒçº¿æ€§å›å½’`ï¼ˆLocally Weighted Linear Regressionï¼ŒLWLRï¼‰ã€‚åœ¨è¿™ä¸ªç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ç»™é¢„æµ‹ç‚¹é™„è¿‘çš„æ¯ä¸ªç‚¹èµ‹äºˆä¸€å®šçš„æƒé‡()ï¼Œç„¶åä¸ çº¿æ€§å›å½’ ç±»ä¼¼ï¼Œåœ¨è¿™ä¸ªå­é›†ä¸ŠåŸºäºæœ€å°å‡æ–¹è¯¯å·®æ¥è¿›è¡Œæ™®é€šçš„å›å½’ã€‚æˆ‘ä»¬éœ€è¦æœ€å°åŒ–çš„ç›®æ ‡å‡½æ•°å¤§è‡´ä¸º:\n",
    "$$\\sum_i w_i(y_i-\\theta^Tx_i)^2$$\n",
    "å‚è€ƒæœ€å°äºŒä¹˜æ³•,\n",
    "$$\\begin{aligned}J(\\theta)\n",
    "&= \\sum_{i=1}^m w_i(y_i-h_{\\theta}(x_i))^2 \\\\\n",
    "&= (X\\theta - y)^TW(X\\theta-y)\\end{aligned}$$\n",
    "$J(\\theta)$å¯¹$\\theta$æ±‚å¯¼:\n",
    "$$\\nabla_{\\theta}J(\\theta) = 2X^TWX\\theta - 2X^TWy$$\n",
    "è¯¥ç®—æ³•è§£å‡ºå›å½’ç³»æ•° $\\theta$ çš„å½¢å¼å¦‚ä¸‹:\n",
    "$$\\hat \\theta = (X^TWX)^{-1}X^TWy$$\n",
    "\n",
    "LWLR ä½¿ç”¨ â€œæ ¸â€ï¼ˆä¸æ”¯æŒå‘é‡æœºä¸­çš„æ ¸ç±»ä¼¼ï¼‰æ¥å¯¹é™„è¿‘çš„ç‚¹èµ‹äºˆæ›´é«˜çš„æƒé‡ã€‚æ ¸çš„ç±»å‹å¯ä»¥è‡ªç”±é€‰æ‹©ï¼Œæœ€å¸¸ç”¨çš„æ ¸å°±æ˜¯é«˜æ–¯æ ¸ï¼Œé«˜æ–¯æ ¸å¯¹åº”çš„æƒé‡å¦‚ä¸‹:\n",
    "$$w(i, i) = exp\\left(\\frac {(x_i-x)^2}{-2k^2}\\right)$$\n",
    "\n",
    "è¿™æ ·å°±æ„å»ºäº†ä¸€ä¸ªåªå«å¯¹è§’å…ƒç´ çš„æƒé‡çŸ©é˜µ wï¼Œå¹¶ä¸”ç‚¹ x ä¸ $x_i$ è¶Šè¿‘ï¼Œw(i, i) å°†ä¼šè¶Šå¤§ã€‚ä¸Šè¿°å…¬å¼ä¸­åŒ…å«ä¸€ä¸ªéœ€è¦ç”¨æˆ·æŒ‡å®šçš„å‚æ•° k ï¼Œå®ƒå†³å®šäº†å¯¹é™„è¿‘çš„ç‚¹èµ‹äºˆå¤šå¤§çš„æƒé‡ï¼Œè¿™ä¹Ÿæ˜¯ä½¿ç”¨ LWLR æ—¶å”¯ä¸€éœ€è¦è€ƒè™‘çš„å‚æ•°ï¼Œä¸‹é¢çš„å›¾ç»™å‡ºäº†å‚æ•° k ä¸æƒé‡çš„å…³ç³»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_w_(x, k):\n",
    "    # é¢„æµ‹ç‚¹x=.5\n",
    "    x_diff = x - .5\n",
    "    return np.exp(x_diff.T * x_diff / (-2 * k**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "ax1, ax2, ax3, ax4, ax5 = figure.subplots(5)\n",
    "ax1.scatter(X[:,0], y[:], c='r', edgecolors='k')\n",
    "x_ = np.linspace(0, 1, 500)\n",
    "print(plt_w_(x_, 0.5))\n",
    "ax2.plot(x_, plt_w_(x_, 0.5), label='k=0.5')\n",
    "ax2.legend()\n",
    "ax3.plot(x_, plt_w_(x_, 0.1), label='k=0.1')\n",
    "ax3.legend()\n",
    "ax4.plot(x_, plt_w_(x_, 0.01), label='k=0.01')\n",
    "ax4.legend()\n",
    "ax5.plot(x_, plt_w_(x_, 10), label='k=10')\n",
    "ax5.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢çš„å›¾æ˜¯ æ¯ä¸ªç‚¹çš„æƒé‡å›¾ï¼ˆå‡å®šæˆ‘ä»¬æ­£é¢„æµ‹çš„ç‚¹æ˜¯ x = 0.5ï¼‰ï¼Œæœ€ä¸Šé¢çš„å›¾æ˜¯åŸå§‹æ•°æ®é›†ï¼Œç¬¬äºŒä¸ªå›¾æ˜¾ç¤ºäº†å½“ k = 0.5 æ—¶ï¼Œå¤§éƒ¨åˆ†çš„æ•°æ®éƒ½ç”¨äºè®­ç»ƒå›å½’æ¨¡å‹ï¼›è€Œæœ€ä¸‹é¢çš„å›¾æ˜¾ç¤ºå½“ k=0.01 æ—¶ï¼Œä»…æœ‰å¾ˆå°‘çš„å±€éƒ¨ç‚¹è¢«ç”¨äºè®­ç»ƒå›å½’æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression_LW:\n",
    "    def __init__(self, k=1):\n",
    "        self.k_ = k\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def weight(X, k, test_point):\n",
    "        # è®¡ç®—æ¯ä¸ªæµ‹è¯•ç‚¹æ—¶, å…¶ä»–ç‚¹çš„æƒé‡\n",
    "        n_sample = X.shape[0]\n",
    "        w = np.eye(n_sample)\n",
    "        for i in range(n_sample):\n",
    "            diff_X = X[i,:] - test_point\n",
    "            w[i,i] = np.exp(diff_X * diff_X.T / (-2 * k**2))\n",
    "        return w\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = np.mat(X)\n",
    "        self.y = np.mat(y[:, np.newaxis])\n",
    "        \n",
    "    def predict(self, test_points):\n",
    "        y_pred = np.zeros(test_points.shape[0]) # n_sample, \n",
    "        \n",
    "        for i in range(test_points.shape[0]):\n",
    "            test_point = test_points[i, :]\n",
    "            w = self.weight(self.X, self.k_, test_point)\n",
    "            A = self.X.T * w * self.X\n",
    "            if np.linalg.det(A) == 0.0:\n",
    "                raise SingularMatrixError('å¥‡å¼‚çŸ©é˜µ, ç”¨å…¶å®ƒæ–¹æ³•æ±‚')\n",
    "            theta = A.I * self.X.T * w * self.y\n",
    "            y_pred[i] = test_point * theta  # 1*nf * n_f*1\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression2():\n",
    "    data = np.loadtxt('data.txt')\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    for ax, k in zip(fig.subplots(3), (1, 0.01, 0.003)):\n",
    "        clf = LinearRegression_LW(k)\n",
    "        clf.fit(X, y)\n",
    "        ax.scatter(X[:,1], y[:], c='r', edgecolors='k', s=2)\n",
    "        y_pred = clf.predict(X)\n",
    "        print(f'k:{k}, errorr: {((y_pred - y)**2).sum()}')\n",
    "        ind = X[:, 1].argsort()  # x ä»å°åˆ°å¤§æ’åº\n",
    "        ax.plot(X[:, 1][ind], y_pred[ind])  # ç”»å‡º é¢„æµ‹çš„æ›²çº¿\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šå›¾ä½¿ç”¨äº† 3 ç§ä¸åŒå¹³æ»‘å€¼ç»˜å‡ºçš„å±€éƒ¨åŠ æƒçº¿æ€§å›å½’çš„ç»“æœã€‚ä¸Šå›¾ä¸­çš„å¹³æ»‘ç³»æ•° k =1.0ï¼Œä¸­å›¾ k = 0.01ï¼Œä¸‹å›¾ k = 0.003 ã€‚å¯ä»¥çœ‹åˆ°ï¼Œk = 1.0 æ—¶çš„ä½¿æ‰€æœ‰æ•°æ®ç­‰æ¯”é‡ï¼Œå…¶æ¨¡å‹æ•ˆæœä¸åŸºæœ¬çš„çº¿æ€§å›å½’ç›¸åŒï¼Œk=0.01æ—¶è¯¥æ¨¡å‹å¯ä»¥æŒ–å‡ºæ•°æ®çš„æ½œåœ¨è§„å¾‹ï¼Œè€Œ k=0.003æ—¶åˆ™è€ƒè™‘äº†å¤ªå¤šçš„å™ªå£°ï¼Œè¿›è€Œå¯¼è‡´äº†è¿‡æ‹Ÿåˆç°è±¡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¤ºä¾‹: é¢„æµ‹é²é±¼çš„å¹´é¾„\n",
    "---\n",
    "å°†æ•°æ®åˆ†ä¸ºæµ‹è¯•é›†å’Œè®­ç»ƒé›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('abalone.txt')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abalone_age():\n",
    "    data = np.loadtxt('abalone.txt')\n",
    "    for i in range(10):\n",
    "        print(\"*\"*30)\n",
    "        print(f'ç¬¬{i+1}æ¬¡æµ‹è¯•:')\n",
    "        X, y = data[300*i:300*i + 300, :-1], data[300 * i:300*i + 300, -1]  # æ¯æ¬¡å–300æ¥æµ‹è¯•\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=123)\n",
    "        def error_(y1, y2):\n",
    "            return ((y1-y2)**2).sum() / len(y1)\n",
    "        for k in (10, 1, 0.1):  # ä¸åŒçš„æ ¸\n",
    "            clf = LinearRegression_LW(k)\n",
    "            clf.fit(X_train, y_train)\n",
    "            try:\n",
    "                y_pred_train = clf.predict(X_train)\n",
    "                y_pred_test = clf.predict(X_test)\n",
    "                print(f\"k:{k}, è®­ç»ƒé›†è¯¯å·®: {error_(y_train, y_pred_train)}, æµ‹è¯•é›†è¯¯å·®: {error_(y_test, y_pred_test)}\")\n",
    "            except SingularMatrixError as e:\n",
    "                print(e.args)\n",
    "                continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_age()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ ¹æ®æˆ‘ä»¬ä¸Šè¾¹çš„æµ‹è¯•ï¼Œå¯ä»¥çœ‹å‡º:\n",
    "ç®€å•çº¿æ€§å›å½’è¾¾åˆ°äº†ä¸å±€éƒ¨åŠ æƒç°è¡Œå›å½’ç±»ä¼¼çš„æ•ˆæœ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 ç¼©å‡ç³»æ•°æ¥ â€œç†è§£â€ æ•°æ®\n",
    "---\n",
    "å¦‚æœæ•°æ®çš„ç‰¹å¾æ¯”æ ·æœ¬ç‚¹è¿˜å¤šåº”è¯¥æ€ä¹ˆåŠï¼Ÿæ˜¯å¦è¿˜å¯ä»¥ä½¿ç”¨çº¿æ€§å›å½’å’Œä¹‹å‰çš„æ–¹æ³•æ¥åšé¢„æµ‹ï¼Ÿç­”æ¡ˆæ˜¯å¦å®šçš„ï¼Œå³æˆ‘ä»¬ä¸èƒ½å†ä½¿ç”¨å‰é¢ä»‹ç»çš„æ–¹æ³•ã€‚è¿™æ˜¯å› ä¸ºåœ¨è®¡ç®—$(X^TX)^{-1}$ çš„æ—¶å€™ä¼šå‡ºé”™ã€‚\n",
    "\n",
    "å¦‚æœç‰¹å¾æ¯”æ ·æœ¬ç‚¹è¿˜å¤š(n_feature > n_sample)ï¼Œä¹Ÿå°±æ˜¯è¯´è¾“å…¥æ•°æ®çš„çŸ©é˜µxå¯èƒ½ä¸æ˜¯**æ»¡ç§©çŸ©é˜µ**ã€‚éæ»¡ç§©çŸ©é˜µæ±‚é€†æ—¶ä¼šå‡ºç°é—®é¢˜ã€‚\n",
    "\n",
    "ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†`å²­å›å½’ï¼ˆridge regressionï¼‰`è¿™ç§ç¼©å‡æ–¹æ³•ã€‚æ¥ç€æ˜¯`lassoæ³•`ï¼Œæœ€åä»‹ç»`å‰å‘é€æ­¥å›å½’`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12).reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.dot(a.T, a)\n",
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.reshape(4, 3)\n",
    "np.linalg.det(np.dot(b.T, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 1 å²­å›å½’ Ridge ï¼ˆL2 æƒ©ç½šï¼‰\n",
    "---\n",
    "å²­ä¼°è®¡å™¨æ˜¯æ™®é€š`LinearRegression`çš„ç®€å•æ­£åˆ™åŒ–ï¼ˆç§°ä¸º`l2`æƒ©ç½šï¼‰, é€šè¿‡å¯¹ç³»æ•°çš„å¤§å°æ–½åŠ æƒ©ç½šæ¥è§£å†³æ™®é€šæœ€å°äºŒä¹˜æ³•çš„ä¸€äº›é—®é¢˜.  ç‰¹åˆ«æ˜¯ï¼Œå®ƒå…·æœ‰çš„ä¼˜ç‚¹æ˜¯ï¼Œåœ¨è®¡ç®—ä¸Šä¸æ¯”æ™®é€šçš„æœ€å°äºŒä¹˜ä¼°è®¡æ›´æ˜‚è´µ. \n",
    "> L2èŒƒæ•°æ˜¯æŒ‡å‘é‡ä¸­å„å…ƒç´ çš„çš„å¹³æ–¹å’Œç„¶åå†æ±‚å¹³æ–¹æ ¹ã€‚æœ‰äººæŠŠå®ƒå«â€œå²­å›å½’â€ï¼ˆRidge Regressionï¼‰ï¼Œæœ‰äººä¹Ÿå«å®ƒâ€œæƒå€¼è¡°å‡weight decayâ€ã€‚\n",
    ">L2èŒƒæ•°ä¸L1ä¸åŒï¼Œä»–ä¸ä¼šè®©å‚æ•°ç­‰äº0ï¼Œè€Œæ˜¯è®©æ¯ä¸ªå‚æ•°éƒ½æ¥è¿‘äº0ã€‚é‚£ä¹ˆL2èŒƒæ•°åˆæœ‰ä»€ä¹ˆå¥½å¤„å‘¢ï¼Ÿ\n",
    "- é˜²æ­¢è¿‡æ‹Ÿåˆ : ä¸€èˆ¬çš„ç”¨æ³•æ˜¯åœ¨æŸå¤±å‡½æ•°åé¢åŠ ä¸Š$\\theta$çš„L2èŒƒæ•°ã€‚è¿™æ˜¯ä¸€ç§è§„åˆ™åŒ–ã€‚\n",
    "- ä¼˜åŒ–æ±‚è§£å˜å¾—ç¨³å®šå¿«é€Ÿ: ç®€å•åœ°è¯´ä»–å¯ä»¥è®©$\\theta$åœ¨æ¥è¿‘å…¨å±€æœ€ä¼˜ç‚¹$\\theta^*$çš„æ—¶å€™ï¼Œè¿˜ä¿æŒç€è¾ƒå¤§çš„æ¢¯åº¦ã€‚è¿™æ ·å¯ä»¥è·³å‡ºå±€éƒ¨æœ€ä¼˜ï¼Œä¹Ÿä½¿å¾—æ”¶æ•›é€Ÿåº¦å˜å¿«ã€‚\n",
    "\n",
    "\n",
    "å²­å›å½’æœ€å°åŒ–çš„æ˜¯å¸¦ç½šé¡¹çš„æ®‹å·®å¹³æ–¹å’Œ\n",
    "$$\\underset {\\theta}{min} ||X\\theta - y||_2^2 + \\alpha ||\\theta||_2^2$$\n",
    "å…¶ä¸­ï¼Œ $\\alpha \\geq 0$ æ˜¯æ§åˆ¶ç³»æ•°æ”¶ç¼©é‡çš„å¤æ‚æ€§å‚æ•°ï¼š $\\alpha$ çš„å€¼è¶Šå¤§ï¼Œæ”¶ç¼©é‡è¶Šå¤§ï¼Œæ¨¡å‹å¯¹å…±çº¿æ€§çš„é²æ£’æ€§ä¹Ÿæ›´å¼ºã€‚\n",
    "\n",
    "ä¸ä¸Šé¢çš„æ“ä½œä¸€æ ·å¯¹$\\theta$æ±‚å¯¼, \n",
    "$$\\nabla_{\\theta}J(\\theta) = 2X^T(X\\theta-y) + 2\\alpha I\\theta$$\n",
    "å¾—åˆ°æœ€ä¼˜çš„$\\hat \\theta = (X^TX+\\alpha I)^{-1}X^Ty$, å®ƒæ˜¯ä¸€ä¸ªå…³äº$\\alpha$çš„å‡½æ•°.  \n",
    "å¯ä»¥è¿™æ ·è®¤ä¸º: å²­å›å½’å°±æ˜¯åœ¨çŸ©é˜µ$X^TX$ ä¸ŠåŠ ä¸€ä¸ª$\\alpha I$ä»è€Œä½¿å¾—çŸ©é˜µéå¥‡å¼‚ï¼Œè¿›è€Œèƒ½å¯¹$X^TX+\\alpha I$æ±‚é€†ã€‚å…¶ä¸­çŸ©é˜µIæ˜¯ä¸€ä¸ª n_feature * n_featureï¼ˆç­‰äºåˆ—æ•°)çš„å•ä½çŸ©é˜µ\n",
    "\n",
    "å²­å›å½’æœ€å…ˆç”¨æ¥å¤„ç†ç‰¹å¾æ•°å¤šäºæ ·æœ¬æ•°çš„æƒ…å†µï¼Œç°åœ¨ä¹Ÿç”¨äºåœ¨ä¼°è®¡ä¸­åŠ å…¥åå·®ï¼Œä»è€Œå¾—åˆ°æ›´å¥½çš„ä¼°è®¡.é€šè¿‡å¼•å…¥æƒ©ç½šé¡¹ï¼Œèƒ½å¤Ÿå‡å°‘ä¸é‡è¦çš„å‚æ•°ï¼Œè¿™ä¸ªæŠ€æœ¯åœ¨ç»Ÿè®¡å­¦ä¸­ä¹Ÿå«ä½œ `ç¼©å‡(shrinkage)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-2, 6, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(X):\n",
    "    return (X - X.mean(0)) / X.var(0) \n",
    "data = np.loadtxt('abalone.txt')\n",
    "X, y = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ridge(X, y, num=30):\n",
    "    y = y - y.mean()\n",
    "    X = (X - X.mean(0)) / X.var(0)\n",
    "    X = np.mat(X)\n",
    "    y = np.mat(y)\n",
    "    # éœ€è¦å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†\n",
    "    I = np.eye(X.shape[1])\n",
    "    alpha_list = np.logspace(-10, num-11, num)\n",
    "    theta_list = []\n",
    "#     print(f\"Xæ˜¯å¥‡å¼‚çŸ©é˜µä¹ˆ: {'yes' if not np.linalg.det(X) else 'no'}\")\n",
    "    for alpha in alpha_list:\n",
    "        A = (np.dot(X.T, X) + alpha * I)\n",
    "        theta = A.I * X.T * y\n",
    "        theta_list.append(theta)\n",
    "    return theta_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('abalone.txt')\n",
    "X, y = data[:, :-1], data[:, [-1]]\n",
    "num = 30\n",
    "theta_list = test_ridge(X, y, num)\n",
    "alpha_list = np.logspace(-10, num-11, num)\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(X.shape[1]):\n",
    "    thetas = list(map(lambda x:x[i, 0], theta_list))\n",
    "    plt.plot(alpha_list, thetas)\n",
    "ax = plt.gca()\n",
    "# ax.invert_xaxis()\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-10, 20-1, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğ›¼ çš„å€¼è¶Šå¤§ï¼Œæ”¶ç¼©é‡è¶Šå¤§ï¼Œæ¨¡å‹å¯¹å…±çº¿æ€§çš„é²æ£’æ€§ä¹Ÿæ›´å¼º. \n",
    "åœ¨æœ€å·¦è¾¹ï¼Œå³ğ›¼ æœ€å°æ—¶ï¼Œå¯ä»¥å¾—åˆ°æ‰€æœ‰ç³»æ•°çš„åŸå§‹å€¼ï¼ˆä¸çº¿æ€§å›å½’ä¸€è‡´ï¼‰ï¼›è€Œåœ¨å³è¾¹ï¼Œç³»æ•°å…¨éƒ¨ç¼©å‡ä¸º0ï¼›åœ¨ä¸­é—´éƒ¨åˆ†çš„æŸå€¼å°†å¯ä»¥å–å¾—æœ€å¥½çš„é¢„æµ‹æ•ˆæœã€‚ä¸ºäº†å®šé‡åœ°æ‰¾åˆ°æœ€ä½³å‚æ•°å€¼ï¼Œè¿˜éœ€è¦è¿›è¡Œäº¤å‰éªŒè¯ã€‚å¦å¤–ï¼Œè¦åˆ¤æ–­å“ªäº›å˜é‡å¯¹ç»“æœé¢„æµ‹æœ€å…·æœ‰å½±å“åŠ›ï¼Œåœ¨ä¸Šå›¾ä¸­è§‚å¯Ÿå®ƒä»¬å¯¹åº”çš„ç³»æ•°å¤§å°å°±å¯ä»¥äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Lassoï¼ˆL1 æƒ©ç½šï¼‰\n",
    "---\n",
    "**å¥—ç´¢æ–¹æ³•(Lassoï¼ŒThe Least Absolute Shrinkage and Selection Operator)**\n",
    "Lassoä¼°è®¡å™¨å¯ç”¨äºå¯¹ç³»æ•°æ–½åŠ ç¨€ç–æ€§, å®ƒåœ¨ä¸€äº›æƒ…å†µä¸‹æ˜¯æœ‰ç”¨çš„ï¼Œå› ä¸ºå®ƒå€¾å‘äºä½¿ç”¨å…·æœ‰è¾ƒå°‘å‚æ•°å€¼çš„æƒ…å†µï¼Œæœ‰æ•ˆåœ°å‡å°‘ç»™å®šè§£å†³æ–¹æ¡ˆæ‰€ä¾èµ–å˜é‡çš„æ•°é‡ã€‚ æ¢å¥è¯è¯´ï¼Œå¦‚æœæˆ‘ä»¬è®¤ä¸ºè®¸å¤šç‰¹å¾ä¸ç›¸å…³ï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¼šæ›´å–œæ¬¢å®ƒã€‚è¿™æ˜¯é€šè¿‡æ‰€è°“çš„ `l1` æƒ©ç½šæ¥å®Œæˆçš„ã€‚\n",
    "\n",
    "> L1èŒƒæ•°æ˜¯æŒ‡å‘é‡ä¸­å„ä¸ªå…ƒç´ ç»å¯¹å€¼ä¹‹å’Œï¼Œä¹Ÿå«â€œç¨€ç–è§„åˆ™ç®—å­â€ï¼ˆLasso regularizationï¼‰\n",
    "\n",
    "å…¶æœ€å°åŒ–çš„ç›®æ ‡å‡½æ•°æ˜¯\n",
    "$$\\underset {\\theta} {min} ||X\\theta-y||^2 + \\alpha||\\theta||_1$$\n",
    "\n",
    "åœ¨å¢åŠ å¦‚ä¸‹çº¦æŸæ—¶ï¼Œæ™®é€šçš„æœ€å°äºŒä¹˜æ³•å›å½’ä¼šå¾—åˆ°ä¸å²­å›å½’ä¸€æ ·çš„å…¬å¼:\n",
    "\n",
    "$\\sum_{k=1}^n \\theta_k^2 \\leq \\alpha$\n",
    "\n",
    "ä¸Šå¼é™å®šäº†æ‰€æœ‰å›å½’ç³»æ•°çš„å¹³æ–¹å’Œä¸èƒ½å¤§äº$\\alpha$ã€‚ä½¿ç”¨æ™®é€šçš„æœ€å°äºŒä¹˜æ³•å›å½’åœ¨å½“ä¸¤ä¸ªæˆ–æ›´å¤šçš„ç‰¹å¾ç›¸å…³æ—¶ï¼Œå¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ªå¾ˆå¤§çš„æ­£ç³»æ•°å’Œä¸€ä¸ªå¾ˆå¤§çš„è´Ÿç³»æ•°ã€‚æ­£æ˜¯å› ä¸ºä¸Šè¿°é™åˆ¶æ¡ä»¶çš„å­˜åœ¨ï¼Œä½¿ç”¨å²­å›å½’å¯ä»¥é¿å…è¿™ä¸ªé—®é¢˜ã€‚\n",
    "\n",
    "ä¸å²­å›å½’ç±»ä¼¼ï¼Œå¦ä¸€ä¸ªç¼©å‡æ–¹æ³•lassoä¹Ÿå¯¹å›å½’ç³»æ•°åšäº†é™å®šï¼Œå¯¹åº”çš„çº¦æŸæ¡ä»¶å¦‚ä¸‹:\n",
    "\n",
    "$\\sum_{k=1}^n |\\theta_k| \\leq \\alpha$\n",
    "\n",
    "å”¯ä¸€çš„ä¸åŒç‚¹åœ¨äºï¼Œè¿™ä¸ªçº¦æŸæ¡ä»¶ä½¿ç”¨ç»å¯¹å€¼å–ä»£äº†å¹³æ–¹å’Œã€‚è™½ç„¶çº¦æŸå½¢å¼åªæ˜¯ç¨ä½œå˜åŒ–ï¼Œç»“æœå´å¤§ç›¸å¾„åº­: åœ¨$\\alpha$è¶³å¤Ÿå°çš„æ—¶å€™ï¼Œä¸€äº›ç³»æ•°ä¼šå› æ­¤è¢«è¿«ç¼©å‡åˆ°0.è¿™ä¸ªç‰¹æ€§å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 å‰å‘é€æ­¥å›å½’ \n",
    "å‰å‘é€æ­¥å›å½’ç®—æ³•å¯ä»¥å¾—åˆ°ä¸ lasso å·®ä¸å¤šçš„æ•ˆæœï¼Œä½†æ›´åŠ ç®€å•ã€‚å®ƒå±äºä¸€ç§è´ªå¿ƒç®—æ³•ï¼Œå³æ¯ä¸€æ­¥éƒ½å°½å¯èƒ½å‡å°‘è¯¯å·®ã€‚ä¸€å¼€å§‹ï¼Œæ‰€æœ‰æƒé‡éƒ½è®¾ç½®ä¸º 0ï¼Œç„¶åæ¯ä¸€æ­¥æ‰€åšçš„å†³ç­–æ˜¯å¯¹æŸä¸ªæƒé‡å¢åŠ æˆ–å‡å°‘ä¸€ä¸ªå¾ˆå°çš„å€¼\n",
    "ä¼ªä»£ç å¦‚ä¸‹:\n",
    "\n",
    "```\n",
    "æ•°æ®æ ‡å‡†åŒ–ï¼Œä½¿å…¶åˆ†å¸ƒæ»¡è¶³ 0 å‡å€¼ å’Œå•ä½æ–¹å·®\n",
    "åœ¨æ¯è½®è¿­ä»£è¿‡ç¨‹ä¸­: \n",
    "    è®¾ç½®å½“å‰æœ€å°è¯¯å·® lowestError ä¸ºæ­£æ— ç©·\n",
    "    å¯¹æ¯ä¸ªç‰¹å¾:\n",
    "        å¢å¤§æˆ–ç¼©å°:\n",
    "            æ”¹å˜ä¸€ä¸ªç³»æ•°å¾—åˆ°ä¸€ä¸ªæ–°çš„ w\n",
    "            è®¡ç®—æ–° w ä¸‹çš„è¯¯å·®\n",
    "            å¦‚æœè¯¯å·® Error å°äºå½“å‰æœ€å°è¯¯å·® lowestError: è®¾ç½® Wbest ç­‰äºå½“å‰çš„ W\n",
    "        å°† W è®¾ç½®ä¸ºæ–°çš„ Wbest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_wise_abalone(iter_num=100, epsilon=0.01):\n",
    "    def standard_(X):\n",
    "        return (X - X.mean(0)) / X.var(0)\n",
    "    \n",
    "    def error_(y1, y2):\n",
    "        return ((y1-y2)**2).sum() / len(y1)\n",
    "    \n",
    "    def stage_wise(X, y, iter_num, epsilon):\n",
    "        n_sample, n_feature = X.shape\n",
    "        weights = np.zeros((n_feature, 1))\n",
    "        weights_best = weights.copy()\n",
    "        w_list = []\n",
    "        for i in range(iter_num):\n",
    "            error_least = np.inf\n",
    "            for j in range(n_feature):\n",
    "                for sign in (-1, +1):\n",
    "                    weights_new = weights.copy()\n",
    "                    weights_new[j] += sign * epsilon\n",
    "                    error_new = error_(np.dot(X, weights_new), y)\n",
    "                    if error_new < error_least:\n",
    "                        error_least = error_new\n",
    "                        weights_best = weights_new\n",
    "                weights = weights_best.copy()\n",
    "            w_list.append(weights)\n",
    "        return w_list, error_least\n",
    "    \n",
    "    data = np.loadtxt('abalone.txt')\n",
    "    X, y = data[:, :-1], data[:, [-1]]\n",
    "    X = standard_(X)\n",
    "    y = y - y.mean()\n",
    "\n",
    "    w_list, error_least = stage_wise(X, y, iter_num, epsilon)\n",
    "    print(f'æœ€ç»ˆçš„è¯¯å·®{error_least}')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(X.shape[1]):\n",
    "        thetas = list(map(lambda x:x[i, 0], w_list))\n",
    "        plt.plot(range(len(w_list)), thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_wise_abalone(200, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€æ­¥çº¿æ€§å›å½’ç®—æ³•çš„ä¸»è¦ä¼˜ç‚¹åœ¨äºå®ƒå¯ä»¥å¸®åŠ©äººä»¬ç†è§£ç°æœ‰çš„æ¨¡å‹å¹¶ä½œå‡ºæ”¹è¿›ã€‚å½“æ„å»ºäº†ä¸€ä¸ªæ¨¡å‹åï¼Œå¯ä»¥è¿è¡Œè¯¥ç®—æ³•æ‰¾å‡ºé‡è¦çš„ç‰¹å¾ï¼Œè¿™æ ·å°±æœ‰å¯èƒ½åŠæ—¶åœæ­¢å¯¹é‚£äº›ä¸é‡è¦ç‰¹å¾çš„æ”¶é›†ã€‚æœ€åï¼Œå¦‚æœç”¨äºæµ‹è¯•ï¼Œè¯¥ç®—æ³•æ¯100æ¬¡è¿­ä»£åå°±å¯ä»¥æ„å»ºå‡ºä¸€ä¸ªæ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨ç±»ä¼¼äº10æŠ˜äº¤å‰éªŒè¯çš„æ–¹æ³•æ¯”è¾ƒè¿™äº›æ¨¡å‹ï¼Œæœ€ç»ˆé€‰æ‹©ä½¿è¯¯å·®æœ€å°çš„æ¨¡å‹ã€‚\n",
    "\n",
    "å½“åº”ç”¨ç¼©å‡æ–¹æ³•ï¼ˆå¦‚é€æ­¥çº¿æ€§å›å½’æˆ–å²­å›å½’ï¼‰æ—¶ï¼Œæ¨¡å‹ä¹Ÿå°±å¢åŠ äº†åå·®ï¼ˆbiasï¼‰ï¼Œä¸æ­¤åŒæ—¶å´å‡å°äº†æ¨¡å‹çš„æ–¹å·®ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
