{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori算法\n",
    "--- \n",
    "## 关联分析Association Analysis\n",
    "\n",
    "关联分析是一种在大规模数据集中寻找有趣关系的任务。 这些关系可以有两种形式:\n",
    "\n",
    "- 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。\n",
    "- 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。\n",
    "\n",
    "支持度与可信度\n",
    "- 支持度(support): 数据集中包含该项集(子集合)的记录所占的比例\n",
    "- 可信度或置信度(confidence): 一条规则 A -> B 的可信度定义为 support(A | B) / support(A)。\n",
    "\n",
    "`支持度`和 `可信度` 是用来量化` 关联分析 `是否成功的一个方法. 。 假设想找到支持度大于 0.8 的所有项集，应该如何去做呢？ 一个办法是生成一个物品所有可能组合的清单，然后对每一种组合统计它出现的频繁程度，但是当物品成千上万时，上述做法就非常非常慢了."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori算法原理\n",
    "假设有4个商品{0, 1, 2, 3}的所有可能的项集合 2^4 - 1 = 15个.随着物品的增加，计算的次数呈指数的形式增长.\n",
    "\n",
    "为了降低计算次数和时间，研究人员发现了一种所谓的 `Apriori `原理，即某个项集是频繁的，那么它的所有子集也是频繁的。 例如，如果 {0, 1} 是频繁的，那么 {0}, {1} 也是频繁的。 该原理直观上没有什么帮助，但是如果反过来看就有用了，也就是说如果一个项集是 `非频繁项集`，那么它的所有`超集`也是非频繁项集.\n",
    "![Apriori](../img/Apriori.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori 算法优缺点\n",
    "\n",
    "* 优点：易编码实现\n",
    "* 缺点：在大数据集上可能较慢\n",
    "* 适用数据类型：数值型 或者 标称型数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_c1(data_set):\n",
    "    # 生成含单个元素的集合的列表\n",
    "    C1 = []\n",
    "    for transaction in data_set:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    # frozenset 不可变集合\n",
    "    return list(map(set, C1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "def loadDataSet():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1}, {2}, {3}, {4}, {5}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadDataSet()\n",
    "c1 = create_c1(data)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(set.union, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{1, 2},\n",
       " {1, 3},\n",
       " {1, 4},\n",
       " {1, 5},\n",
       " {2, 3},\n",
       " {2, 4},\n",
       " {2, 5},\n",
       " {3, 4},\n",
       " {3, 5},\n",
       " {4, 5}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apriori_gen(Lk, k):\n",
    "    # 输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck\n",
    "    # ck = [{1, 2}, {0, 1}, {2, 3}] k=3 -> [{0, 1,2 }, {1, 2, 3}, {0, 2, 3}]\n",
    "#         union_set = reduce(set.union, map(set, Lk))\n",
    "#         return list(map(frozenset, combinations(union_set, k)))\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            L1 = list(Lk[i])[: k-2]\n",
    "            L2 = list(Lk[j])[: k-2]\n",
    "            # print '-----i=', i, k-2, Lk, Lk[i], list(Lk[i])[: k-2]\n",
    "            # print '-----j=', j, k-2, Lk, Lk[j], list(Lk[j])[: k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            print(L1, L2)\n",
    "            # 第一次 L1,L2 为空，元素直接进行合并，返回元素两两合并的数据集\n",
    "            # if first k-2 elements are equal\n",
    "            # {1, 2} {1, 3} [1] == [1] -> {1, 2, 3}\n",
    "            # {2, 3} {2, 4} [2] == [2] -> {2, 3, 4}\n",
    "            if L1 == L2:\n",
    "                # set union\n",
    "                # print 'union=', Lk[i] | Lk[j], Lk[i], Lk[j]\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "ck = [[{0}, {1}, {2}, {3}]]\n",
    "l = apriori_gen(c1, 2)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [2]\n",
      "[1] [2]\n",
      "[1] [2]\n",
      "[1] [3]\n",
      "[1] [3]\n",
      "[1] [4]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [2]\n",
      "[1] [2]\n",
      "[1] [2]\n",
      "[1] [3]\n",
      "[1] [3]\n",
      "[1] [4]\n",
      "[1] [1]\n",
      "[1] [2]\n",
      "[1] [2]\n",
      "[1] [2]\n",
      "[1] [3]\n",
      "[1] [3]\n",
      "[1] [4]\n",
      "[1] [2]\n",
      "[1] [2]\n",
      "[1] [2]\n",
      "[1] [3]\n",
      "[1] [3]\n",
      "[1] [4]\n",
      "[2] [2]\n",
      "[2] [2]\n",
      "[2] [3]\n",
      "[2] [3]\n",
      "[2] [4]\n",
      "[2] [2]\n",
      "[2] [3]\n",
      "[2] [3]\n",
      "[2] [4]\n",
      "[2] [3]\n",
      "[2] [3]\n",
      "[2] [4]\n",
      "[3] [3]\n",
      "[3] [4]\n",
      "[3] [4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{1, 2, 3},\n",
       " {1, 2, 4},\n",
       " {1, 2, 5},\n",
       " {1, 3, 4},\n",
       " {1, 3, 5},\n",
       " {1, 4, 5},\n",
       " {2, 3, 4},\n",
       " {2, 3, 5},\n",
       " {2, 4, 5},\n",
       " {3, 4, 5}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori_gen(l, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Apriori:\n",
    "    def __init__(self, min_support=0.5):\n",
    "        # 支持度 >= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。\n",
    "        self.min_support = min_support\n",
    "    @staticmethod\n",
    "    def create_c1(data_set):\n",
    "        # 生成含单个元素的集合的列表\n",
    "        C_1 = []\n",
    "        for transaction in data_set:\n",
    "            for item in transaction:\n",
    "                if not [item] in C_1:\n",
    "                    C_1.append([item])\n",
    "        C_1.sort()\n",
    "        # frozenset 不可变集合  hashable\n",
    "        return list(map(frozenset, C_1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def apriori_gen(Lk, k):\n",
    "        # 输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck\n",
    "        # ck = [{1, 2}, {0, 1}, {2, 3}] k=3 -> [{0, 1,2 }, {1, 2, 3}, {0, 2, 3}]\n",
    "#         union_set = reduce(set.union, map(set, Lk))\n",
    "#         return list(map(frozenset, combinations(union_set, k)))\n",
    "        retList = []\n",
    "        lenLk = len(Lk)\n",
    "        for i in range(lenLk):\n",
    "            for j in range(i+1, lenLk):\n",
    "                L1 = list(Lk[i])[: k-2]\n",
    "                L2 = list(Lk[j])[: k-2]\n",
    "                # print '-----i=', i, k-2, Lk, Lk[i], list(Lk[i])[: k-2]\n",
    "                # print '-----j=', j, k-2, Lk, Lk[j], list(Lk[j])[: k-2]\n",
    "                L1.sort()\n",
    "                L2.sort()\n",
    "                # 第一次 L1,L2 为空，元素直接进行合并，返回元素两两合并的数据集\n",
    "                # if first k-2 elements are equal\n",
    "                if L1 == L2:\n",
    "                    # set union\n",
    "                    # print 'union=', Lk[i] | Lk[j], Lk[i], Lk[j]\n",
    "                    retList.append(Lk[i] | Lk[j])\n",
    "        return retList\n",
    "    \n",
    "    def fit(self, data):\n",
    "        c_1 = self.create_c1(data)\n",
    "        D = list(map(set, data))\n",
    "        \n",
    "        # 按子集元素个数排列 [[含1个元素的子集,], [2个], [3个]]\n",
    "        support_list = []\n",
    "        l, support_dict = self.scan(D, c_1)\n",
    "        support_list.append(l)\n",
    "        k = 2\n",
    "        while True: \n",
    "            # 由满足支持度条件的ck 生成的含2, 3 ..个元素组成的集合列表\n",
    "            c_k = self.apriori_gen(support_list[k-2], k)\n",
    "            list_, dict_ = self.scan(D, c_k)\n",
    "            support_dict.update(dict_)\n",
    "            \n",
    "            # 子集含元素数目增加过程中 若不满足支持度 超集也不满足\n",
    "            if not list_:\n",
    "                break\n",
    "            support_list.append(list_)\n",
    "            k += 1\n",
    "        return support_dict, support_list\n",
    "            \n",
    "    def scan(self, D, C_k):\n",
    "        # 数据集ck在数据集D中的支持度, \n",
    "        # 并返回支持度大于最小支持度（minSupport）的数据\n",
    "        \n",
    "        # 计算频数\n",
    "        cnt = {}\n",
    "        for set_ in D:\n",
    "            for C in C_k:\n",
    "                # 若C为D中数据集的子集, C频数+1\n",
    "                if C.issubset(set_):\n",
    "                    cnt[C] = cnt.get(C, 0) + 1\n",
    "        num = len(D)\n",
    "        ret_C = {}\n",
    "        retList = []\n",
    "        for key in cnt:\n",
    "            support = cnt[key] / num\n",
    "            if support >= self.min_support:\n",
    "                retList.insert(0, key)\n",
    "            ret_C.update({key: support})\n",
    "                \n",
    "        return retList, ret_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "apriori = Apriori(0.5)\n",
    "dict_, l1 = apriori.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({1}): 0.5,\n",
       " frozenset({3}): 0.75,\n",
       " frozenset({4}): 0.25,\n",
       " frozenset({2}): 0.75,\n",
       " frozenset({5}): 0.75,\n",
       " frozenset({1, 3}): 0.5,\n",
       " frozenset({2, 5}): 0.75,\n",
       " frozenset({3, 5}): 0.5,\n",
       " frozenset({2, 3}): 0.5,\n",
       " frozenset({1, 5}): 0.25,\n",
       " frozenset({1, 2}): 0.25,\n",
       " frozenset({2, 3, 5}): 0.5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从频繁项集中挖掘关联规则\n",
    "如下图所示，给出的是项集 {0,1,2,3} 产生的所有关联规则:\n",
    "![2](../img/Apriori2.png)\n",
    "\n",
    "通过观察，我们可以知道，如果某条规则并不满足 `最小可信度` 要求，那么该规则的所有子集也不会满足 最小可信度 的要求。\n",
    "如上图所示，假设` 123 -> 3 `并不满足最小可信度要求，那么就知道任何左部为{0,1,2} 子集的规则也不会满足 最小可信度 的要求。 即` 12 -> 03 , 02 -> 13 , 01 -> 23 , 2 -> 013, 1 -> 023, 0 -> 123 `都不满足 最小可信度 要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApriorRules(Apriori):\n",
    "    def __init__(self, min_support=0.5, min_confidence=0.5):\n",
    "        super().__init__(min_support)\n",
    "        self.min_confidence = min_confidence\n",
    "    \n",
    "    def calc_confidence(self, sub_sets, freq_set):\n",
    "        # freq_set 频繁项集中的元素\n",
    "        # sub_sets freq_set子集 组成的list\n",
    "        # 规则 freq_set - set_ -> set_ 的置信度\n",
    "        subs = []  # freq_set的子集\n",
    "        for set_ in sub_sets:\n",
    "            conf = self.support_dict[freq_set] / self.support_dict[freq_set - set_]\n",
    "            # print(freq_set - set_, set_, conf)\n",
    "            if conf > self.min_confidence:\n",
    "                self.rules.append((freq_set - set_, set_, conf))\n",
    "                subs.append(set_)             \n",
    "        return subs\n",
    "   \n",
    "    def rules_from_conseq(self, freq_set, sub_sets):\n",
    "        # freq_set 频繁集 {1, 2, 3}\n",
    "        # 子元素集合 [{1}, {2}, {3}]  [{1, 2}, {2, 3}, {1, 3}]\n",
    "        sub_len = len(sub_sets[0])  # 每次sub_sets元素长度一致\n",
    "        if len(freq_set) > sub_len:\n",
    "            # 生成元素数量+1的子集\n",
    "            \n",
    "            subs = self.calc_confidence(sub_sets, freq_set)\n",
    "            subs = self.apriori_gen(sub_sets, sub_len + 1)\n",
    "\n",
    "            # {2, 3} -> {3} 不符合要求,就不会检查 {2, } -> {1 , 3}了\n",
    "            if len(subs) > 1:\n",
    "                self.rules_from_conseq(freq_set, subs)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.support_dict, support_list = super().fit(data)\n",
    "        self.rules = []\n",
    "        for i in range(1, len(support_list)):\n",
    "            for freq_set in support_list[i]:\n",
    "                # {1, 2, 3} -> [{1}, {2}, {3}]\n",
    "                subs = [frozenset([item]) for item in freq_set]\n",
    "                if i > 1: \n",
    "                    self.rules_from_conseq(freq_set, subs)\n",
    "                else:\n",
    "                    # 只含2个元素 A -> B, B->A\n",
    "                    self.calc_confidence(subs, freq_set)\n",
    "        return self.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({3}), frozenset({2}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({5}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({3}), frozenset({1}), 0.6666666666666666),\n",
       " (frozenset({1}), frozenset({3}), 1.0),\n",
       " (frozenset({3, 5}), frozenset({2}), 1.0),\n",
       " (frozenset({2, 5}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({2, 3}), frozenset({5}), 1.0),\n",
       " (frozenset({5}), frozenset({2, 3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({2, 5}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori_rules = ApriorRules()\n",
    "apriori_rules.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目案例: 发现毒菇的相似特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   3.,   9.,  13.,  23.,  25.,  34.,  36.,  38.,  40.,  52.,\n",
       "         54.,  59.,  63.,  67.,  76.,  85.,  86.,  90.,  93.,  98., 107.,\n",
       "        113.],\n",
       "       [  2.,   3.,   9.,  14.,  23.,  26.,  34.,  36.,  39.,  40.,  52.,\n",
       "         55.,  59.,  63.,  67.,  76.,  85.,  86.,  90.,  93.,  99., 108.,\n",
       "        114.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mushroom = np.loadtxt('./mushroom.dat')\n",
    "mushroom[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个特征表示有毒或可食用. 有毒为2, 可食用为1. 第二个为蘑菇伞的形状, 有六种可能的值3-8.\n",
    "\n",
    "为了寻找毒蘑菇中存在的公共特征, 寻找包含特征值2的频繁集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "455\n",
      "725\n",
      "712\n",
      "441\n",
      "169\n",
      "38\n",
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "mushroom_apriori= Apriori(min_support=.3)\n",
    "support_dict, support_list = mushroom_apriori.fit(mushroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
