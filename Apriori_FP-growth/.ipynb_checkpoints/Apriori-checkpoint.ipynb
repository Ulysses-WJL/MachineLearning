{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori算法\n",
    "--- \n",
    "## 关联分析Association Analysis\n",
    "\n",
    "关联分析是一种在大规模数据集中寻找有趣关系的任务。 这些关系可以有两种形式:\n",
    "\n",
    "- 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。\n",
    "- 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。\n",
    "\n",
    "支持度与可信度\n",
    "- 支持度(support): 数据集中包含该项集(子集合)的记录所占的比例\n",
    "- 可信度或置信度(confidence): 一条规则 A -> B 的可信度定义为 support(A | B) / support(A)。\n",
    "\n",
    "`支持度`和 `可信度` 是用来量化` 关联分析 `是否成功的一个方法. 。 假设想找到支持度大于 0.8 的所有项集，应该如何去做呢？ 一个办法是生成一个物品所有可能组合的清单，然后对每一种组合统计它出现的频繁程度，但是当物品成千上万时，上述做法就非常非常慢了."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori算法原理\n",
    "假设有4个商品{0, 1, 2, 3}的所有可能的项集合 2^4 - 1 = 15个.随着物品的增加，计算的次数呈指数的形式增长.\n",
    "\n",
    "为了降低计算次数和时间，研究人员发现了一种所谓的 `Apriori `原理，即某个项集是频繁的，那么它的所有子集也是频繁的。 例如，如果 {0, 1} 是频繁的，那么 {0}, {1} 也是频繁的。 该原理直观上没有什么帮助，但是如果反过来看就有用了，也就是说如果一个项集是 `非频繁项集`，那么它的所有`超集`也是非频繁项集.\n",
    "![Apriori](../img/Apriori.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {0, 1, 2, 3}\n",
    "union = []\n",
    "for i in range(1, 5):\n",
    "    union.extend(list(combinations(a, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,),\n",
       " (1,),\n",
       " (2,),\n",
       " (3,),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (2, 3),\n",
       " (0, 1, 2),\n",
       " (0, 1, 3),\n",
       " (0, 2, 3),\n",
       " (1, 2, 3),\n",
       " (0, 1, 2, 3)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori 算法优缺点\n",
    "\n",
    "* 优点：易编码实现\n",
    "* 缺点：在大数据集上可能较慢\n",
    "* 适用数据类型：数值型 或者 标称型数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_c1(data_set):\n",
    "    # 生成含单个元素的集合的列表\n",
    "    C1 = []\n",
    "    for transaction in data_set:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    # frozenset 不可变集合\n",
    "    return list(map(set, C1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
    "c1 = create_c1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(set.union, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Apriori:\n",
    "    def __init__(self, min_support=0.5):\n",
    "        # 支持度 >= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。\n",
    "        self.min_support = min_support\n",
    "    @staticmethod\n",
    "    def create_c1(data_set):\n",
    "        # 生成含单个元素的集合的列表\n",
    "        C_1 = []\n",
    "        for transaction in data_set:\n",
    "            for item in transaction:\n",
    "                if not [item] in C_1:\n",
    "                    C_1.append([item])\n",
    "        C_1.sort()\n",
    "        # frozenset 不可变集合  hashable\n",
    "        return list(map(frozenset, C_1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def apriori_gen(ck, k):\n",
    "        # 输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck\n",
    "        # ck = [{1, 2}, {0, 1}, {2, 3}] k=3 -> [{0, 1,2 }, {1, 2, 3}, {0, 2, 3}]\n",
    "        union_set = reduce(set.union, map(set, ck))\n",
    "        return list(map(frozenset, combinations(union_set, k)))\n",
    "    \n",
    "    def fit(self, data):\n",
    "        c_k = self.create_c1(data)\n",
    "        D = list(map(set, data))\n",
    "        \n",
    "        # 按子集元素个数排列 [[含1个元素的子集,], [2个], [3个]]\n",
    "        support_list = []\n",
    "        support_dict = self.scan(D, c_k)\n",
    "        support_list.append(list(support_dict.keys()))\n",
    "        k = 2\n",
    "        total_num = len(c_k)\n",
    "        while k < total_num:\n",
    "            # 由满足支持度条件的ck 生成的含2, 3 ..个元素组成的集合列表\n",
    "            c_k = self.apriori_gen(c_k, k)\n",
    "            dict_ = self.scan(D, c_k)\n",
    "            if not dict_:\n",
    "                break\n",
    "            support_dict.update(dict_)\n",
    "            support_list.append(list(dict_.keys()))\n",
    "            k += 1\n",
    "        return support_dict, support_list\n",
    "            \n",
    "    def scan(self, D, C_k):\n",
    "        # 数据集ck在数据集D中的支持度, \n",
    "        # 并返回支持度大于最小支持度（minSupport）的数据\n",
    "        \n",
    "        # 计算频数\n",
    "        cnt = {}\n",
    "        for set_ in D:\n",
    "            for C in C_k:\n",
    "                # 若C为D中数据集的子集, C频数+1\n",
    "                if C.issubset(set_):\n",
    "                    cnt[C] = cnt.get(C, 0) + 1\n",
    "        num = len(D)\n",
    "        ret_C = {}\n",
    "        for key in cnt:\n",
    "            support = cnt[key] / num\n",
    "            if support >= self.min_support:\n",
    "                ret_C.update({key: support})\n",
    "        return ret_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({frozenset({1}): 0.5,\n",
       "  frozenset({3}): 0.75,\n",
       "  frozenset({2}): 0.75,\n",
       "  frozenset({5}): 0.75,\n",
       "  frozenset({1, 3}): 0.5,\n",
       "  frozenset({2, 3}): 0.5,\n",
       "  frozenset({2, 5}): 0.75,\n",
       "  frozenset({3, 5}): 0.5,\n",
       "  frozenset({2, 3, 5}): 0.5},\n",
       " [[frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})],\n",
       "  [frozenset({1, 3}), frozenset({2, 3}), frozenset({2, 5}), frozenset({3, 5})],\n",
       "  [frozenset({2, 3, 5})]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori = Apriori(0.5)\n",
    "apriori.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从频繁项集中挖掘关联规则\n",
    "如下图所示，给出的是项集 {0,1,2,3} 产生的所有关联规则:\n",
    "![2](../img/Apriori2.png)\n",
    "\n",
    "通过观察，我们可以知道，如果某条规则并不满足 `最小可信度` 要求，那么该规则的所有子集也不会满足 最小可信度 的要求。\n",
    "如上图所示，假设` 123 -> 3 `并不满足最小可信度要求，那么就知道任何左部为{0,1,2} 子集的规则也不会满足 最小可信度 的要求。 即` 12 -> 03 , 02 -> 13 , 01 -> 23 , 2 -> 013, 1 -> 023, 0 -> 123 `都不满足 最小可信度 要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApriorRules(Apriori):\n",
    "    def __init__(self, min_support=0.5, min_confidence=0.5):\n",
    "        super().__init__(min_support)\n",
    "        self.min_confidence = min_confidence\n",
    "    \n",
    "    def calc_confidence(self, sub_sets, freq_set):\n",
    "        # freq_set 频繁项集中的元素\n",
    "        # sub_sets freq_set子集 组成的list\n",
    "        # 规则 freq_set - set_ -> set_ 的置信度\n",
    "        subs = []  # freq_set的子集\n",
    "        for set_ in sub_sets:\n",
    "            conf = self.support_dict[freq_set] / self.support_dict[freq_set - set_]\n",
    "            # print(freq_set - set_, set_, conf)\n",
    "            if conf > self.min_confidence:\n",
    "                self.rules.append((freq_set - set_, set_, conf))\n",
    "                subs.append(set_)             \n",
    "        return subs\n",
    "   \n",
    "    def rules_from_conseq(self, freq_set, sub_sets):\n",
    "        # freq_set 频繁集 {1, 2, 3}\n",
    "        # 子元素集合 [{1}, {2}, {3}]  [{1, 2}, {2, 3}, {1, 3}]\n",
    "        sub_len = len(sub_sets[0])  # 每次sub_sets元素长度一致\n",
    "        if len(freq_set) > sub_len:\n",
    "            # 生成元素数量+1的子集\n",
    "            \n",
    "            subs = self.calc_confidence(sub_sets, freq_set)\n",
    "            subs = self.apriori_gen(sub_sets, sub_len + 1)\n",
    "\n",
    "            # {2, 3} -> {3} 不符合要求,就不会检查 {2, } -> {1 , 3}了\n",
    "            if len(subs) > 1:\n",
    "                self.rules_from_conseq(freq_set, subs)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.support_dict, support_list = super().fit(data)\n",
    "        self.rules = []\n",
    "        for i in range(1, len(support_list)):\n",
    "            for freq_set in support_list[i]:\n",
    "                # {1, 2, 3} -> [{1}, {2}, {3}]\n",
    "                subs = [frozenset([item]) for item in freq_set]\n",
    "                if i > 1: \n",
    "                    self.rules_from_conseq(freq_set, subs)\n",
    "                else:\n",
    "                    # 只含2个元素 A -> B, B->A\n",
    "                    self.calc_confidence(subs, freq_set)\n",
    "        return self.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({3}), frozenset({1}), 0.6666666666666666),\n",
       " (frozenset({1}), frozenset({3}), 1.0),\n",
       " (frozenset({3}), frozenset({2}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({5}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({5}), 0.6666666666666666),\n",
       " (frozenset({3, 5}), frozenset({2}), 1.0),\n",
       " (frozenset({2, 5}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({2, 3}), frozenset({5}), 1.0),\n",
       " (frozenset({5}), frozenset({2, 3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({2, 5}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori_rules = ApriorRules()\n",
    "apriori_rules.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
