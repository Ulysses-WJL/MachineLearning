{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6章 逻辑斯谛回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑斯谛回归(LR)是经典的分类方法\n",
    "\n",
    "1．逻辑斯谛回归模型是由以下条件概率分布表示的分类模型。逻辑斯谛回归模型可以用于二类或多类分类。\n",
    "\n",
    "$$P(Y=k | x)=\\frac{\\exp \\left(w_{k} \\cdot x\\right)}{1+\\sum_{k=1}^{K-1} \\exp \\left(w_{k} \\cdot x\\right)}, \\quad k=1,2, \\cdots, K-1$$\n",
    "\n",
    "$$P(Y=K | x)=\\frac{1}{1+\\sum_{k=1}^{K-1} \\exp \\left(w_{k} \\cdot x\\right)}$$\n",
    "这里，$x$为输入特征$(x^{1}, x^{(2)}, \\dots, x^{(n)}, 1)^T$，$w$为特征的权值$(w^{1}, w^{(2)}, \\dots, w^{(n)}, b)^T$。  \n",
    "softmax\n",
    "$$\n",
    "P(Y=k|x)=\\frac{\\exp(w_k\\cdot x)}{\\sum_{k=1}^K\\exp(w_k\\cdot x)}, k=1,2,\\dots,K\n",
    "$$\n",
    "\n",
    "事件的几率(odds)是指事件发生的概率(p)与该事件不发生的概率(1-p)的比值. 事件的对数几率(log odds)或logit函数是:\n",
    "$$logit(p) = log\\frac p {1-p}$$\n",
    "考虑二类分类问题:\n",
    "$$logit\\frac {P(Y=1|x)}{1-P(Y=1|x)} = log(exp(w \\cdot x)) = w \\cdot x$$\n",
    "**输出$Y=1$的对数几率是由输入x的线性函数表示的模型, 即逻辑斯蒂回归模型**\n",
    "\n",
    "逻辑斯谛回归模型源自逻辑斯谛分布，其分布函数$F(x)$是$S$形函数。逻辑斯谛回归模型是由输入的线性函数表示的输出的对数几率模型。\n",
    "\n",
    "2．最大熵模型是由以下条件概率分布表示的分类模型。最大熵模型也可以用于二类或多类分类。\n",
    "\n",
    "$$P_{w}(y | x)=\\frac{1}{Z_{w}(x)} \\exp \\left(\\sum_{i=1}^{n} w_{i} f_{i}(x, y)\\right)$$\n",
    "$$Z_{w}(x)=\\sum_{y} \\exp \\left(\\sum_{i=1}^{n} w_{i} f_{i}(x, y)\\right)$$\n",
    "\n",
    "其中，$Z_w(x)$是规范化因子，$f_i$为特征函数，$w_i$为特征的权值。\n",
    "\n",
    "3．最大熵模型可以由最大熵原理推导得出。最大熵原理是概率模型学习或估计的一个准则。最大熵原理认为在所有可能的概率模型（分布）的集合中，熵最大的模型是最好的模型。\n",
    "\n",
    "最大熵原理应用到分类模型的学习中，有以下约束最优化问题：\n",
    "\n",
    "$$\\min -H(P)=\\sum_{x, y} \\tilde{P}(x) P(y | x) \\log P(y | x)$$\n",
    "\n",
    "$$s.t.  \\quad P\\left(f_{i}\\right)-\\tilde{P}\\left(f_{i}\\right)=0, \\quad i=1,2, \\cdots, n$$\n",
    " \n",
    " $$\\sum_{y} P(y | x)=1$$\n",
    "\n",
    " \n",
    "求解此最优化问题的对偶问题得到最大熵模型。\n",
    "\n",
    "\n",
    "4．逻辑斯谛回归模型与最大熵模型都属于对数线性模型。\n",
    "\n",
    "5．逻辑斯谛回归模型及最大熵模型学习一般采用极大似然估计，或正则化的极大似然估计。逻辑斯谛回归模型及最大熵模型学习可以形式化为无约束最优化问题。求解该最优化问题的算法有改进的迭代尺度法、梯度下降法、拟牛顿法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "回归模型：$f(x) = \\frac{1}{1+e^{-wx}}$\n",
    "\n",
    "其中wx线性函数：$wx =w_0\\cdot x_0 + w_1\\cdot x_1 + w_2\\cdot x_2 +...+w_n\\cdot x_n,(x_0=1)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**逻辑思谛分布(logistic distribution)**   \n",
    "分布函数:\n",
    "$$F(x)=P(X \\leq x) = \\frac 1 {1+e^{-(x-\\mu)/\\gamma}}$$\n",
    "是一条S形曲线(sigmoid curve), 以$(\\mu, \\frac 1 2)$为对称中心  \n",
    "密度函数:\n",
    "$$f(x) = F'(x) = \\frac {e^{-(x-\\mu)/\\gamma}} {\\gamma(1+e^{-(x-\\mu)/\\gamma)^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**逻辑斯蒂模型参数估计**\n",
    "\n",
    "似然函数:\n",
    "$$\n",
    "\\prod\\limits_{i=1}\\limits^NP(y_i|x_i,W)=\\prod\\limits_{i=1}\\limits^N\\frac{(\\exp(w\\cdot x_i))^{y_i}}{1+\\exp(w\\cdot x_i)}\n",
    "$$\n",
    "使用对数技巧\n",
    "$$\n",
    "\\sum_{i=1}^N\\log\\frac{(\\exp(w\\cdot x_i))^{y_i}}{1+\\exp(w\\cdot x_i)}=\\sum_{i=1}^N[y_i(w\\cdot x_i)-\\log(1+\\exp(w\\cdot x_i)) ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid 函数\n",
    "x = np.linspace(-3, 5, 50)\n",
    "mu, gamma = 1, 0.1  # gamma 越小 曲线在中心增长越快\n",
    "y = 1 / (1+ np.exp(-(x-mu)/gamma))\n",
    "plt.plot(x, y)\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_position(('data', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.exp(-(x-mu)/gamma)\n",
    "pdf = temp / (gamma * (1 + temp)**2)\n",
    "plt.plot(x, pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 0, 0]).reshape(3,1)\n",
    "y = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "np.concatenate((y, x), axis=1)\n",
    "np.ones(3)[:, np.newaxis]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    # print(data)\n",
    "    return data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticReressionClassifier:\n",
    "    def __init__(self, max_iter=200, learning_rate=0.01):\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    def data_matrix(self, X):\n",
    "        data_mat = np.ones((len(X), 1))\n",
    "        return np.concatenate((data_mat, X), axis=1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # label = np.mat(y)\n",
    "        data_mat = self.data_matrix(X)  # m*n\n",
    "        self.weights = np.zeros((len(data_mat[0]), 1), dtype=np.float32)\n",
    "\n",
    "        for iter_ in range(self.max_iter):\n",
    "            for i in range(len(X)):\n",
    "                result = self.sigmoid(np.dot(data_mat[i], self.weights))\n",
    "                error = y[i] - result\n",
    "                self.weights += self.learning_rate * error * np.transpose(\n",
    "                    [data_mat[i]])\n",
    "        print('LogisticRegression Model(learning_rate={},max_iter={})'.format(\n",
    "            self.learning_rate, self.max_iter))\n",
    "\n",
    "    def predict(self, x):\n",
    "        # x: (n_sample, n_feature) \n",
    "        x = self.data_matrix(x)\n",
    "        result = np.dot(x, self.weights)\n",
    "        return np.where(result>=0, 1, 0)\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        X_test = self.data_matrix(X_test)\n",
    "        for x, y in zip(X_test, y_test):\n",
    "            result = np.dot(x, self.weights)\n",
    "            if (result > 0 and y == 1) or (result < 0 and y == 0):\n",
    "                right += 1\n",
    "        return right / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticReressionClassifier()\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.predict([[4.5, 3.1], [5.1, 2.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ponits = np.arange(4, 8)\n",
    "y_ = -(lr_clf.weights[1]*x_ponits + lr_clf.weights[0])/lr_clf.weights[2]\n",
    "plt.plot(x_ponits, y_)\n",
    "\n",
    "#lr_clf.show_graph()\n",
    "plt.scatter(X[:50,0],X[:50,1], label='0')\n",
    "plt.scatter(X[50:,0],X[50:,1], label='1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### scikit-learn实例\n",
    "\n",
    "#### sklearn.linear_model.LogisticRegression\n",
    "\n",
    "solver参数决定了我们对逻辑回归损失函数的优化方法，有四种算法可以选择，分别是：\n",
    "- a) liblinear：使用了开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数。默认\n",
    "- b) lbfgs：拟牛顿法的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。\n",
    "- c) newton-cg：也是牛顿法家族的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。\n",
    "- d) sag：即随机平均梯度下降，是梯度下降法的变种，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候。\n",
    "- e) saga: 是 sag 的一类变体，它支持非平滑（non-smooth）的 L1 正则选项 penalty=\"l1\" 。因此对于稀疏多项式 logistic 回归 ，往往选用该求解器。saga求解器是唯一支持弹性网络正则选项的求解器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.coef_, clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ponits = np.arange(4, 8)\n",
    "y_ = -(clf.coef_[0][0]*x_ponits + clf.intercept_)/clf.coef_[0][1]\n",
    "plt.plot(x_ponits, y_)\n",
    "\n",
    "plt.plot(X[:50, 0], X[:50, 1], 'bo', color='blue', label='0')\n",
    "plt.plot(X[50:, 0], X[50:, 1], 'bo', color='orange', label='1')\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大熵模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**例6.2 python符号推导实现**  \n",
    "一个约束条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "\n",
    "# 1 constrains\n",
    "P1, P2, P3, P4, P5, w0, w1, w2 = symbols(\"P1, P2, P3, P4, P5, w0, w1, w2\", real=True)\n",
    "L = P1 * log(P1) + P2 * log(P2) + P3 * log(P3) + P4 * log(P4) + P5 * log(P5) + \\\n",
    "    w0 * (P1 + P2 + P3 + P4 + P5 - 1)   # 拉格朗日函数\n",
    "# 拉格朗日函数对原变量P求导,并令导数=0 解方程得到P\n",
    "P1_e = (solve(diff(L, P1), P1))[0]  # 解是list, 用参数表示原变量\n",
    "P2_e = (solve(diff(L, P2), P2))[0]\n",
    "P3_e = (solve(diff(L, P3), P3))[0]\n",
    "P4_e = (solve(diff(L, P4), P4))[0]\n",
    "P5_e = (solve(diff(L, P5), P5))[0]\n",
    "P1_e, P2_e, P3_e, P4_e, P5_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = L.subs({P1: P1_e, P2: P2_e, P3: P3_e, P4: P4_e, P5: P5_e})  # 用参数取代原变量带入 L\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = (solve([diff(L, w0)], [w0]))[0]  # 对参数w0 求导 解方程\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = [P1_e.subs({w0: w[0]}),\n",
    "     P2_e.subs({w0: w[0]}),\n",
    "     P3_e.subs({w0: w[0]}),\n",
    "     P4_e.subs({w0: w[0]}),\n",
    "     P5_e.subs({w0: w[0]})]\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个约束条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1, P2, P3, P4, P5, w0, w1, w2 = symbols(\"P1, P2, P3, P4, P5, w0, w1, w2\", real=True)\n",
    "L = P1 * log(P1) + P2 * log(P2) + P3 * log(P3) + P4 * log(P4) + P5 * log(P5) + \\\n",
    "    w0 * (P1 + P2 + P3 + P4 + P5 - 1) + w1 * (P1 + P2 - 3/10)   # 拉格朗日函数\n",
    "P1_e = (solve(L.diff(P1), P1))[0]\n",
    "P2_e = (solve(L.diff(P2), P2))[0]\n",
    "P3_e = (solve(L.diff(P3), P3))[0]\n",
    "P4_e = (solve(L.diff(P4), P4))[0]\n",
    "P5_e = (solve(L.diff(P5), P5))[0]\n",
    "L = L.subs({P1: P1_e, P2: P2_e, P3: P3_e, P4: P4_e, P5: P5_e})  # 用参数取代原变量带入 L\n",
    "w = (solve([diff(L, w0), L.diff(w1)], [w0, w1]))[0]  # 对参数w0 求导 解方程\n",
    "P = [P1_e.subs({w0: w[0], w1:w[1]}),\n",
    "     P2_e.subs({w0: w[0], w1:w[1]}),\n",
    "     P3_e.subs({w0: w[0], w1:w[1]}),\n",
    "     P4_e.subs({w0: w[0], w1:w[1]}),\n",
    "     P5_e.subs({w0: w[0], w1:w[1]})]\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'1':2, '2': 2}\n",
    "d.get('1', 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxEntropy:\n",
    "    def __init__(self, EPS=0.005):\n",
    "        self._samples = []\n",
    "        self._Y = set()  # 标签集合，相当去去重后的y\n",
    "        self._numXY = {}  # key为(x,y)，value为出现次数 如('sunny', 'no'): 3,\n",
    "        self._N = 0  # 样本数\n",
    "        self._Ep_ = []  # 样本分布的特征期望值\n",
    "        self._xyID = {}  # key记录(x,y),value记录id号\n",
    "        self._n = 0  # 特征键值(x,y)的个数\n",
    "        self._C = 0  # 最大特征数\n",
    "        self._IDxy = {}  # key为(x,y)，value为对应的id号\n",
    "        self._w = []\n",
    "        self._EPS = EPS  # 收敛条件\n",
    "        self._lastw = []  # 上一次w参数值\n",
    "\n",
    "    def loadData(self, dataset):\n",
    "        self._samples = deepcopy(dataset)\n",
    "        for items in self._samples:\n",
    "            y = items[0]\n",
    "            X = items[1:]\n",
    "            self._Y.add(y)  # 集合中y若已存在则会自动忽略\n",
    "            for x in X:  # 将x中特征全部分离开  ('sunny', 'no'): 3, ('FALSE', 'no'): 2,\n",
    "                self._numXY[(x, y)] = self._numXY.get((x, y), 0) + 1\n",
    "#                 if (x, y) in self._numXY:\n",
    "#                     self._numXY[(x, y)] += 1\n",
    "#                 else:\n",
    "#                     self._numXY[(x, y)] = 1\n",
    "\n",
    "        self._N = len(self._samples)\n",
    "        self._n = len(self._numXY)\n",
    "        self._C = max([len(sample) - 1 for sample in self._samples])\n",
    "        self._w = [0] * self._n\n",
    "        self._lastw = self._w[:]\n",
    "\n",
    "        self._Ep_ = [0] * self._n\n",
    "        for i, xy in enumerate(self._numXY):  # 计算特征函数fi关于经验分布的期望\n",
    "            self._Ep_[i] = self._numXY[xy] / self._N   # v(x, y) / N\n",
    "            self._xyID[xy] = i  # {(x, y): id号}\n",
    "            self._IDxy[i] = xy  # {id号: (x, y)}\n",
    "\n",
    "    def _Zx(self, X):  # 计算每个Z(x)值\n",
    "        zx = 0\n",
    "        # z_w(x) = \\sum_y exp(\\sum w_i * f_i)  f_i(x, y)可以是任意实值\n",
    "        for y in self._Y:\n",
    "            ss = 0\n",
    "            for x in X:\n",
    "                if (x, y) in self._numXY:\n",
    "                    ss += self._w[self._xyID[(x, y)]]\n",
    "            zx += math.exp(ss)\n",
    "        return zx\n",
    "\n",
    "    def _model_pyx(self, y, X):  # 计算每个P(y|x)\n",
    "        zx = self._Zx(X)\n",
    "        ss = 0\n",
    "        for x in X:\n",
    "            if (x, y) in self._numXY:\n",
    "                ss += self._w[self._xyID[(x, y)]]\n",
    "        pyx = math.exp(ss) / zx\n",
    "        return pyx\n",
    "\n",
    "    def _model_ep(self, index):  # 计算特征函数fi关于模型的期望\n",
    "        x, y = self._IDxy[index]\n",
    "        ep = 0\n",
    "        for sample in self._samples:\n",
    "            if x not in sample:\n",
    "                continue\n",
    "            pyx = self._model_pyx(y, sample)\n",
    "            ep += pyx / self._N\n",
    "        return ep\n",
    "\n",
    "    def _convergence(self):  # 判断是否全部收敛\n",
    "        for last, now in zip(self._lastw, self._w):\n",
    "            if abs(last - now) >= self._EPS:\n",
    "                return False\n",
    "        return Truefrom sklearn.preprocessing import OneHotE\n",
    "\n",
    "    def predict(self, X):  # 计算预测概率\n",
    "        Z = self._Zx(X)\n",
    "        result = {}\n",
    "        for y in self._Y:\n",
    "            ss = 0\n",
    "            for x in X:\n",
    "                if (x, y) in self._numXY:\n",
    "                    ss += self._w[self._xyID[(x, y)]]\n",
    "            pyx = math.exp(ss) / Z\n",
    "            result[y] = pyx\n",
    "        return result\n",
    "\n",
    "    def train(self, maxiter=1000):  # 训练数据\n",
    "        for loop in range(maxiter):  # 最大训练次数\n",
    "            print(\"iter:%d\" % loop)\n",
    "            self._lastw = self._w[:]\n",
    "            for i in range(self._n):\n",
    "                ep = self._model_ep(i)  # 计算第i个特征的模型期望\n",
    "                self._w[i] += math.log(self._Ep_[i] / ep) / self._C  # 更新参数\n",
    "            print(\"w:\", self._w)\n",
    "            if self._convergence():  # 判断是否收敛\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [['no', 'sunny', 'hot', 'high', 'FALSE'],\n",
    "           ['no', 'sunny', 'hot', 'high', 'TRUE'],\n",
    "           ['yes', 'overcast', 'hot', 'high', 'FALSE'],\n",
    "           ['yes', 'rainy', 'mild', 'high', 'FALSE'],\n",
    "           ['yes', 'rainy', 'cool', 'normal', 'FALSE'],\n",
    "           ['no', 'rainy', 'cool', 'normal', 'TRUE'],\n",
    "           ['yes', 'overcast', 'cool', 'normal', 'TRUE'],\n",
    "           ['no', 'sunny', 'mild', 'high', 'FALSE'],\n",
    "           ['yes', 'sunny', 'cool', 'normal', 'FALSE'],\n",
    "           ['yes', 'rainy', 'mild', 'normal', 'FALSE'],\n",
    "           ['yes', 'sunny', 'mild', 'normal', 'TRUE'],\n",
    "           ['yes', 'overcast', 'mild', 'high', 'TRUE'],\n",
    "           ['yes', 'overcast', 'hot', 'normal', 'FALSE'],\n",
    "           ['no', 'rainy', 'mild', 'high', 'TRUE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxent = MaxEntropy()\n",
    "x = ['overcast', 'mild', 'high', 'FALSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxent.loadData(dataset)\n",
    "# maxent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sunny', 'no'): 3,\n",
       " ('hot', 'no'): 2,\n",
       " ('high', 'no'): 4,\n",
       " ('FALSE', 'no'): 2,\n",
       " ('TRUE', 'no'): 3,\n",
       " ('overcast', 'yes'): 4,\n",
       " ('hot', 'yes'): 2,\n",
       " ('high', 'yes'): 3,\n",
       " ('FALSE', 'yes'): 6,\n",
       " ('rainy', 'yes'): 3,\n",
       " ('mild', 'yes'): 4,\n",
       " ('cool', 'yes'): 3,\n",
       " ('normal', 'yes'): 6,\n",
       " ('rainy', 'no'): 2,\n",
       " ('cool', 'no'): 1,\n",
       " ('normal', 'no'): 1,\n",
       " ('TRUE', 'yes'): 3,\n",
       " ('mild', 'no'): 2,\n",
       " ('sunny', 'yes'): 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxent._numXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predict:', maxent.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "参考代码：https://github.com/wzyonggege/statistical-learning-method\n",
    "\n",
    "中文注释制作：机器学习初学者\n",
    "\n",
    "微信公众号：ID:ai-start-com\n",
    "\n",
    "配置环境：python 3.5+\n",
    "\n",
    "代码全部测试通过。\n",
    "![gongzhong](../gongzhong.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
