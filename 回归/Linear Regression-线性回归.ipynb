{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 广义线性模型 Generalized Linear Models\n",
    "---\n",
    "本章主要讲述一些用于回归的方法，其中目标值 y 是输入变量 x 的线性组合。 数学概念表示为：如果$\\hat{y}$是预测值，那么有：\n",
    "\n",
    "$\\hat{y}(w, x) = w^{(0)} + w^{(1)} x^{(1)} + ... + w^{(p)} x^{(p)}$\n",
    "\n",
    "在整个模块中，我们定义向量 $w = (w_1,..., w_p)$ 作为`coef_`(coefficient, 回归系数)，定义 $w_0$ 作为 `intercept_`截距.\n",
    "线性模型虽简单, 却有丰富的变化.考虑单调可微函数$g(\\cdot)$\n",
    "($g(\\cdot)$连续且充分光滑), 令\n",
    "\n",
    "$$y = g^{-1}(w^Tx+b)$$\n",
    "这样得到的模型称为`广义线性模型`,函数$g(\\cdot)$称为`联系函数`(link function). 对数线性回归(Logistic Regression)是$g(\\cdot)=ln(\\cdot)$时的特例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "---\n",
    "给定数据集 $D = \\{(x_1, y_1), (x_2, y_2), \\cdots, (x_n, y_n)\\}$, 其中$x_i=(x_i^{(1)}, x_i^{(2)}, \\cdots, x_i^{(d)}), y_i \\in \\mathbb{R}$. 线性回归(linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记.\n",
    "$$f(x_i) = wx_i, 使得f(x_i)\\simeq y_i$$\n",
    "\n",
    "对于离散属性, 若属性值之间存在`序`(order)关系, 可通过连续化将其转为连续值; 若属性值间不存在序关系,假定有k个属性值, 则通常将其转为k维向量(OneHotEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 普通最小二乘法 Ordinary Least Squares\n",
    "---\n",
    "LinearRegression 拟合一个带有系数$w = (w^{(0)}, ...,w^{(p)})$的线性模型，使得数据集实际观测数据和预测数据（估计值）之间的残差平方和(对应了常用的欧几里得距离Euclidean distance)最小。其数学表达式为:\n",
    "$$\\underset{w}{min} {|| X w - y||_2}^2$$\n",
    "求解w使$E_{w} = \\sum_{i=1}^{p}(w^Tx_i-y_i)^2$(loss function)最小化的过程, 称为线性回归模型的最小二乘`参数估计`(parameter estimation). $E_{w}$是关于$w$的凸函数, 可以令其对$w$并令导数为0, 得到$w$的最优解的闭式(closed-form)解.\n",
    "\n",
    "用矩阵形式可以写成$E_{w} = (y-Xw)^T(y-Xw)$, 对$w$求导得到:\n",
    "$\\frac {\\partial E_w}{\\partial w} = 2X^T(Xw-y)$, 令其为0得到$\\hat w = (X^TX)^{-1}X^Ty$\n",
    "\n",
    "需要对矩阵求逆，因此这个方程只在逆矩阵存在的时候适用，我们在程序代码中对此作出判断。 判断矩阵是否可逆的一个可选方案是:\n",
    "\n",
    "判断矩阵的行列式是否为 0，若为0，矩阵就不存在逆矩阵，不为0的话，矩阵才存在逆矩阵。\n",
    "\n",
    "[矩阵求导参考1](https://blog.csdn.net/daaikuaichuan/article/details/80620518)\n",
    "\n",
    "[矩阵求导参考2](http://blog.csdn.net/nomadlx53/article/details/50849941)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习实战 例子1\n",
    "___\n",
    "数据格式\n",
    "```\n",
    "x0       x1       y\n",
    "1.000000\t0.067732\t3.176513\n",
    "1.000000\t0.427810\t3.816464\n",
    "1.000000\t0.995731\t4.550095\n",
    "1.000000\t0.738336\t4.256571\n",
    "1.000000\t0.981083\t4.560815\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "np.set_printoptions(threshold=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.      , 0.067732, 3.176513],\n",
       "       [1.      , 0.42781 , 3.816464],\n",
       "       [1.      , 0.995731, 4.550095],\n",
       "       ...,\n",
       "       [1.      , 0.070095, 3.213817],\n",
       "       [1.      , 0.52707 , 3.952681],\n",
       "       [1.      , 0.116163, 3.129283]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('data.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(data[:, 0]==1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.067732],\n",
       "       [0.42781 ],\n",
       "       [0.995731],\n",
       "       ...,\n",
       "       [0.070095],\n",
       "       [0.52707 ],\n",
       "       [0.116163]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取X 和 y\n",
    "X, y = data[:, [1]], data[:, [2]]\n",
    "X  # 保持 X 为 n_sample * n_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[3.176513, 3.816464, 4.550095, ..., 3.213817, 3.952681, 3.129283]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = np.mat(y).ravel()\n",
    "y1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.      , 0.067732],\n",
       "       [1.      , 0.42781 ],\n",
       "       [1.      , 0.995731],\n",
       "       ...,\n",
       "       [1.      , 0.070095],\n",
       "       [1.      , 0.52707 ],\n",
       "       [1.      , 0.116163]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(X):\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((ones, X), axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def least_squares(X, y):\n",
    "        A = X.T * X\n",
    "        if np.linalg.det(A) == 0.0:\n",
    "            print('...')\n",
    "        print(A.I.shape)\n",
    "        w = A.I * X.T * y\n",
    "        return w\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = self.transform(deepcopy(X))\n",
    "        print(X.shape)\n",
    "        X = np.mat(X)\n",
    "        y = np.mat(y)\n",
    "        weights = self.least_squares(X, y)  # n_feature * 1\n",
    "        self.intercept_ = weights[0, 0]\n",
    "        self.coef_ = np.array(weights[1:, 0]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x54fa5f8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.69532264]), 3.0077432426975914)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
