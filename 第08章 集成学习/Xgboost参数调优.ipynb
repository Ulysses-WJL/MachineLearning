{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597886957275",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost参数调优的一般方法\n",
    "\n",
    "调参步骤：\n",
    "- 1，选择较高的学习速率（learning rate）。一般情况下，学习速率的值为0.1.但是，对于不同的问题，理想的学习速率有时候会在0.05~0.3之间波动。选择对应于此学习速率的理想决策树数量。Xgboost有一个很有用的函数“cv”，这个函数可以在每一次迭代中使用交叉验证，并返回理想的决策树数量。\n",
    "- 2，对于给定的学习速率和决策树数量，进行决策树特定参数调优（max_depth , min_child_weight , gamma , subsample,colsample_bytree）在确定一棵树的过程中，我们可以选择不同的参数。\n",
    "- 3，Xgboost的正则化参数的调优。（lambda , alpha）。这些参数可以降低模型的复杂度，从而提高模型的表现。\n",
    "- 4, 降低学习速率，确定理想参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步：确定学习速率和tree_based参数调优的估计器数目\n",
    "\n",
    "为了确定Boosting参数，我们要先给其他参数一个初始值。咱们先按照如下方法取值：\n",
    "\n",
    "- 1，max_depth = 5：这个参数的取值最好在3-10之间，我选的起始值为5，但是你可以选择其他的值。起始值在4-6之间都是不错的选择。\n",
    "- 2，min_child_weight = 1 ：这里选择了一个比较小的值，因为这是一个极不平衡的分类问题。因此，某些叶子节点下的值会比较小。\n",
    "- 3，gamma = 0 :起始值也可以选择其它比较小的值，在0.1到0.2之间就可以，这个参数后继也是要调整的。\n",
    "- 4，subsample,colsample_bytree = 0.8  这个是最常见的初始值了。典型值的范围在0.5-0.9之间。\n",
    "- 5，scale_pos_weight =1 这个值时因为类别十分不平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二步：max_depth和min_weight参数调优\n",
    "\n",
    "我们先对这两个参数调优，是因为他们对最终结果有很大的影响。首先，我们先大范围地粗略参数，然后再小范围的微调\n",
    "\n",
    "网格搜索scoring = 'roc_auc' 只支持二分类，多分类需要修改scoring（默认支持多分类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mInit signature:\u001b[0m\n\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0miid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m     \nExhaustive search over specified parameter values for an estimator.\n\nImportant members are fit, predict.\n\nGridSearchCV implements a \"fit\" and a \"score\" method.\nIt also implements \"predict\", \"predict_proba\", \"decision_function\",\n\"transform\" and \"inverse_transform\" if they are implemented in the\nestimator used.\n\nThe parameters of the estimator used to apply these methods are optimized\nby cross-validated grid-search over a parameter grid.\n\nRead more in the :ref:`User Guide <grid_search>`.\n\nParameters\n----------\nestimator : estimator object.\n    This is assumed to implement the scikit-learn estimator interface.\n    Either estimator needs to provide a ``score`` function,\n    or ``scoring`` must be passed.\n\nparam_grid : dict or list of dictionaries\n    Dictionary with parameters names (`str`) as keys and lists of\n    parameter settings to try as values, or a list of such\n    dictionaries, in which case the grids spanned by each dictionary\n    in the list are explored. This enables searching over any sequence\n    of parameter settings.\n\nscoring : str, callable, list/tuple or dict, default=None\n    A single str (see :ref:`scoring_parameter`) or a callable\n    (see :ref:`scoring`) to evaluate the predictions on the test set.\n\n    For evaluating multiple metrics, either give a list of (unique) strings\n    or a dict with names as keys and callables as values.\n\n    NOTE that when using custom scorers, each scorer should return a single\n    value. Metric functions returning a list/array of values can be wrapped\n    into multiple scorers that return one value each.\n\n    See :ref:`multimetric_grid_search` for an example.\n\n    If None, the estimator's score method is used.\n\nn_jobs : int, default=None\n    Number of jobs to run in parallel.\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\n    .. versionchanged:: v0.20\n       `n_jobs` default changed from 1 to None\n\npre_dispatch : int, or str, default=n_jobs\n    Controls the number of jobs that get dispatched during parallel\n    execution. Reducing this number can be useful to avoid an\n    explosion of memory consumption when more jobs get dispatched\n    than CPUs can process. This parameter can be:\n\n        - None, in which case all the jobs are immediately\n          created and spawned. Use this for lightweight and\n          fast-running jobs, to avoid delays due to on-demand\n          spawning of the jobs\n\n        - An int, giving the exact number of total jobs that are\n          spawned\n\n        - A str, giving an expression as a function of n_jobs,\n          as in '2*n_jobs'\n\niid : bool, default=False\n    If True, return the average score across folds, weighted by the number\n    of samples in each test set. In this case, the data is assumed to be\n    identically distributed across the folds, and the loss minimized is\n    the total loss per sample, and not the mean loss across the folds.\n\n    .. deprecated:: 0.22\n        Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n\ncv : int, cross-validation generator or an iterable, default=None\n    Determines the cross-validation splitting strategy.\n    Possible inputs for cv are:\n\n    - None, to use the default 5-fold cross validation,\n    - integer, to specify the number of folds in a `(Stratified)KFold`,\n    - :term:`CV splitter`,\n    - An iterable yielding (train, test) splits as arrays of indices.\n\n    For integer/None inputs, if the estimator is a classifier and ``y`` is\n    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n    other cases, :class:`KFold` is used.\n\n    Refer :ref:`User Guide <cross_validation>` for the various\n    cross-validation strategies that can be used here.\n\n    .. versionchanged:: 0.22\n        ``cv`` default value if None changed from 3-fold to 5-fold.\n\nrefit : bool, str, or callable, default=True\n    Refit an estimator using the best found parameters on the whole\n    dataset.\n\n    For multiple metric evaluation, this needs to be a `str` denoting the\n    scorer that would be used to find the best parameters for refitting\n    the estimator at the end.\n\n    Where there are considerations other than maximum score in\n    choosing a best estimator, ``refit`` can be set to a function which\n    returns the selected ``best_index_`` given ``cv_results_``. In that\n    case, the ``best_estimator_`` and ``best_params_`` will be set\n    according to the returned ``best_index_`` while the ``best_score_``\n    attribute will not be available.\n\n    The refitted estimator is made available at the ``best_estimator_``\n    attribute and permits using ``predict`` directly on this\n    ``GridSearchCV`` instance.\n\n    Also for multiple metric evaluation, the attributes ``best_index_``,\n    ``best_score_`` and ``best_params_`` will only be available if\n    ``refit`` is set and all of them will be determined w.r.t this specific\n    scorer.\n\n    See ``scoring`` parameter to know more about multiple metric\n    evaluation.\n\n    .. versionchanged:: 0.20\n        Support for callable added.\n\nverbose : integer\n    Controls the verbosity: the higher, the more messages.\n\nerror_score : 'raise' or numeric, default=np.nan\n    Value to assign to the score if an error occurs in estimator fitting.\n    If set to 'raise', the error is raised. If a numeric value is given,\n    FitFailedWarning is raised. This parameter does not affect the refit\n    step, which will always raise the error.\n\nreturn_train_score : bool, default=False\n    If ``False``, the ``cv_results_`` attribute will not include training\n    scores.\n    Computing training scores is used to get insights on how different\n    parameter settings impact the overfitting/underfitting trade-off.\n    However computing the scores on the training set can be computationally\n    expensive and is not strictly required to select the parameters that\n    yield the best generalization performance.\n\n    .. versionadded:: 0.19\n\n    .. versionchanged:: 0.21\n        Default value was changed from ``True`` to ``False``\n\n\nExamples\n--------\n>>> from sklearn import svm, datasets\n>>> from sklearn.model_selection import GridSearchCV\n>>> iris = datasets.load_iris()\n>>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n>>> svc = svm.SVC()\n>>> clf = GridSearchCV(svc, parameters)\n>>> clf.fit(iris.data, iris.target)\nGridSearchCV(estimator=SVC(),\n             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n>>> sorted(clf.cv_results_.keys())\n['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n 'param_C', 'param_kernel', 'params',...\n 'rank_test_score', 'split0_test_score',...\n 'split2_test_score', ...\n 'std_fit_time', 'std_score_time', 'std_test_score']\n\nAttributes\n----------\ncv_results_ : dict of numpy (masked) ndarrays\n    A dict with keys as column headers and values as columns, that can be\n    imported into a pandas ``DataFrame``.\n\n    For instance the below given table\n\n    +------------+-----------+------------+-----------------+---+---------+\n    |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n    +============+===========+============+=================+===+=========+\n    |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n    +------------+-----------+------------+-----------------+---+---------+\n    |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n    +------------+-----------+------------+-----------------+---+---------+\n    |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n    +------------+-----------+------------+-----------------+---+---------+\n    |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n    +------------+-----------+------------+-----------------+---+---------+\n\n    will be represented by a ``cv_results_`` dict of::\n\n        {\n        'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n                                     mask = [False False False False]...)\n        'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n                                    mask = [ True  True False False]...),\n        'param_degree': masked_array(data = [2.0 3.0 -- --],\n                                     mask = [False False  True  True]...),\n        'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n        'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n        'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n        'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n        'rank_test_score'    : [2, 4, 3, 1],\n        'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n        'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n        'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n        'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n        'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n        'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n        'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n        'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n        'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n        }\n\n    NOTE\n\n    The key ``'params'`` is used to store a list of parameter\n    settings dicts for all the parameter candidates.\n\n    The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n    ``std_score_time`` are all in seconds.\n\n    For multi-metric evaluation, the scores for all the scorers are\n    available in the ``cv_results_`` dict at the keys ending with that\n    scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n    above. ('split0_test_precision', 'mean_train_precision' etc.)\n\nbest_estimator_ : estimator\n    Estimator that was chosen by the search, i.e. estimator\n    which gave highest score (or smallest loss if specified)\n    on the left out data. Not available if ``refit=False``.\n\n    See ``refit`` parameter for more information on allowed values.\n\nbest_score_ : float\n    Mean cross-validated score of the best_estimator\n\n    For multi-metric evaluation, this is present only if ``refit`` is\n    specified.\n\n    This attribute is not available if ``refit`` is a function.\n\nbest_params_ : dict\n    Parameter setting that gave the best results on the hold out data.\n\n    For multi-metric evaluation, this is present only if ``refit`` is\n    specified.\n\nbest_index_ : int\n    The index (of the ``cv_results_`` arrays) which corresponds to the best\n    candidate parameter setting.\n\n    The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n    the parameter setting for the best model, that gives the highest\n    mean score (``search.best_score_``).\n\n    For multi-metric evaluation, this is present only if ``refit`` is\n    specified.\n\nscorer_ : function or a dict\n    Scorer function used on the held out data to choose the best\n    parameters for the model.\n\n    For multi-metric evaluation, this attribute holds the validated\n    ``scoring`` dict which maps the scorer key to the scorer callable.\n\nn_splits_ : int\n    The number of cross-validation splits (folds/iterations).\n\nrefit_time_ : float\n    Seconds used for refitting the best model on the whole dataset.\n\n    This is present only if ``refit`` is not False.\n\n    .. versionadded:: 0.20\n\nNotes\n-----\nThe parameters selected are those that maximize the score of the left out\ndata, unless an explicit score is passed in which case it is used instead.\n\nIf `n_jobs` was set to a value higher than one, the data is copied for each\npoint in the grid (and not `n_jobs` times). This is done for efficiency\nreasons if individual jobs take very little time, but may raise errors if\nthe dataset is large and not enough memory is available.  A workaround in\nthis case is to set `pre_dispatch`. Then, the memory is copied only\n`pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\nn_jobs`.\n\nSee Also\n---------\n:class:`ParameterGrid`:\n    generates all the combinations of a hyperparameter grid.\n\n:func:`sklearn.model_selection.train_test_split`:\n    utility function to split the data into a development set usable\n    for fitting a GridSearchCV instance and an evaluation set for\n    its final evaluation.\n\n:func:`sklearn.metrics.make_scorer`:\n    Make a scorer from a performance metric or loss function.\n\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\n\u001b[0;31mType:\u001b[0m           ABCMeta\n\u001b[0;31mSubclasses:\u001b[0m     \n"
    }
   ],
   "source": [
    "GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "# param_test2 = {\n",
    "#  'max_depth':[4,5,6],\n",
    "#  'min_child_weight':[4,5,6]\n",
    "# }\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=140, max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27\n",
    "    ),\n",
    "    param_grid = param_test1,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=5\n",
    ")\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_,gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三步：gamma参数调优\n",
    "在已经调整好其他参数的基础上，我们可以进行gamma参数的调优了。Gamma参数取值范围很大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(\n",
    "    estimator = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=140,\n",
    "        max_depth=4,\n",
    "        min_child_weight=6,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27),\n",
    "    param_grid = param_test3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=5)\n",
    "gsearch3.fit(train[predictors],train[target])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四步：调整subsample 和 colsample_bytree参数\n",
    "\n",
    "尝试不同的subsample 和 colsample_bytree 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(\n",
    "    estimator = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=177,\n",
    "        max_depth=3,\n",
    "        min_child_weight=4,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27),\n",
    "    param_grid = param_test4,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=5)\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五步：正则化参数调优\n",
    "\n",
    "由于gamma函数提供了一种更加有效的降低过拟合的方法，大部分人很少会用到这个参数，但是我们可以尝试用一下这个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六步：降低学习速率\n",
    "\n",
    "最后，我们使用较低的学习速率，以及使用更多的决策树，我们可以用Xgboost中CV函数来进行这一步工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost输出特征重要性以及筛选特征\n",
    "## 1，梯度提升算法是如何计算特征重要性的？\n",
    "　　使用梯度提升算法的好处是在提升树被创建后，可以相对直接地得到每个属性的重要性得分。一般来说，重要性分数，衡量了特征在模型中的提升决策树构建中的价值。一个属性越多的被用来在模型中构建决策树，它的重要性就相对越高。\n",
    "\n",
    "　　属性重要性是通过对数据集中的每个属性进行计算，并进行排序得到。在单个决策树中通过每个属性分裂点改进性能度量的量来计算属性重要性。由节点负责加权和记录次数，也就是说一个属性对分裂点改进性能度量越大（越靠近根节点），权值越大；被越多提升树所选择，属性越重要。性能度量可以是选择分裂节点的Gini纯度，也可以是其他度量函数。\n",
    "\n",
    "　　最终将一个属性在所有提升树中的结果进行加权求和后然后平均，得到重要性得分。\n",
    "\n",
    "## 3，根据Xgboost特征重要性得分进行特征选择\n",
    "\n",
    "特征重要性得分，可以用于在scikit-learn中进行特征选择。通过SelectFromModel类实现，该类采用模型并将数据集转换为具有选定特征的子集。这个类可以采取预先训练的模型，例如在整个数据集上训练的模型。然后，它可以阈值来决定选择哪些特征。当在SelectFromModel实例上调用transform()方法时，该阈值被用于在训练集和测试集上一致性选择相同特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.02098431 0.08922921 0.5056452  0.38414133]\nAccuracy:92.00%\nThresh=0.021, n=4, Accuracy: 92.00%\nThresh=0.089, n=3, Accuracy: 92.00%\nThresh=0.384, n=2, Accuracy: 94.00%\nThresh=0.506, n=1, Accuracy: 90.00%\n"
    }
   ],
   "source": [
    "# plot feature importance manually\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import load_iris\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    " \n",
    "# load data\n",
    "dataset = load_iris()\n",
    "# split data into X and y\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    " \n",
    "# split data into train and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=7)\n",
    " \n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# feature importance\n",
    "print(model.feature_importances_)\n",
    " \n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy*100.0))\n",
    " \n",
    "#fit model using each importance as a threshold\n",
    "thresholds = np.sort(model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(model,threshold=thresh,prefit=True )\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    # train model\n",
    "    selection_model = XGBClassifier()\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test,predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}