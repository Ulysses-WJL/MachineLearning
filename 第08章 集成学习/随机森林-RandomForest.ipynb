{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多决策树 - 随机森林 - 随机决策\n",
    "对决策树的一个常见批评是，一旦在回答问题后对训练集进行划分，就不可能重新考虑这个决策。例如，如果我们将男性和女性分开，那么每个后续问题都只涉及男性或女性，而且该方法不能考虑其他类型的问题（例如，年龄不到一岁，不论性别如何）。**随机森林**尝试在每个步骤中引入一定程度的**随机化**，创建备选树并将它们组合来获得最终预测。考虑几个回答相同问题的分类器的这些类型的算法，被称为**集成方法**.   \n",
    "随机森林建议基于训练实例的子集（**带放回随机选择**）来构建决策树，但是在特征集的每个集合中使用少量随机的特征。这种树生长过程重复几次，产生一组分类器。在预测时，给定一个实例的每个成型的树都会像决策树一样预测其目标类。大多数树所投票的类（即树中预测最多的类）是集成分类器所建议的类。  \n",
    "随机森林只是许多树，建立在数据的不同随机子集（带放回抽样）上，并对于每个分裂，使用特征的不同随机子集（无放回抽样）。 这使得树彼此不同，并使它们过拟合不同的方面。 然后，他们的预测被平均，产生更平稳的估计，更少过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "声呐信号分析 [来源](https://github.com/apachecn/AiLearning/blob/master/docs/ml/7.%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%92%8CAdaBoost.md#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True, precision=4, threshold=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path) as f:\n",
    "        data = []\n",
    "        for line in f.readlines():\n",
    "            if not line:\n",
    "                continue\n",
    "            line_data = []\n",
    "            for str_ in line.split(','):\n",
    "                str_ = str_.strip()\n",
    "                if str_.isdigit():\n",
    "                    line_data.append(float(str_))\n",
    "                else:\n",
    "                    line_data.append(str_)\n",
    "            data.append(line_data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(load_data('sonar-all-data.txt'))\n",
    "X, y = data[:, :-1].astype(float), data[:, -1]\n",
    "labels, indices_u = np.unique(y, return_inverse=True)\n",
    "y_ = np.where(indices_u == 0, -1, indices_u)\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义节点类 CART 二叉树\n",
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature=None, value=None):\n",
    "        self.root = root  # 当前节点是叶节点了\n",
    "        self.label = label  # 节点的分类\n",
    "        # self.feature_name = feature_name  # 节点划分子集使用的特征名\n",
    "        self.feature = feature   # 当前节点 划分子集使用的特征编号\n",
    "        self.tree = {}  # 子节点\n",
    "        self.value = value  # 分割值\n",
    "\n",
    "    def __repr__(self): \n",
    "        result = {\n",
    "            'label': self.label,\n",
    "            'feature': self.feature,\n",
    "            'value': self.value,\n",
    "            'tree': self.tree\n",
    "        }\n",
    "        if not self.label:\n",
    "            result.pop('label')\n",
    "        if not self.tree:\n",
    "            result.pop('tree')\n",
    "        if not self.feature:\n",
    "            result.pop('feature')\n",
    "        if self.value is None:\n",
    "            result.pop('value')   \n",
    "        return '{}'.format(result)\n",
    "\n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "\n",
    "    def predict(self, X):\n",
    "        # X 单个特征样本\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        if X[self.feature] >= self.value :\n",
    "            return self.tree['left'].predict(X)\n",
    "        else:\n",
    "            return self.tree['right'].predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self, epsilon=0.1, sample_least=5):\n",
    "        self.epsilon = epsilon  # 基尼指数阈值\n",
    "        self.sample_least = sample_least\n",
    "        self._tree = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini_(y1, y2):\n",
    "        # 获取当前样本集 的gini指数\n",
    "        ginis = []\n",
    "        \n",
    "        for y in (y1, y2):\n",
    "            # Gini(D) = 1- \\sum (|C_k|/|D|)^2\n",
    "            labels, counts = np.unique(y, return_counts=True)\n",
    "            gini = 1- np.sum((counts / np.sum(counts)) ** 2)\n",
    "            ginis.append(gini)\n",
    "        # Gini(D, A) = |D1| / |D| * gini(D1) + |D2| / |D| * gini(D2)\n",
    "        A = np.array([len(y1), len(y2)])\n",
    "        # print(ginis, A)\n",
    "        gini_A = (ginis * (A / A.sum())).sum()\n",
    "        return gini_A\n",
    "    \n",
    "    @staticmethod\n",
    "    def data_split(X, feature, value):\n",
    "        # 根据特征和value 分割数据 返回序号\n",
    "        data_set = X[:, feature]\n",
    "        left , right = [], []\n",
    "        for i in range(len(data_set)):\n",
    "            if data_set[i] >= value:\n",
    "                left.append(i)\n",
    "            else:\n",
    "                right.append(i)\n",
    "        return left, right\n",
    "    \n",
    "    def choose_best_value(self, data, y, feature):\n",
    "        # 返回最佳分割点和相应的gini指数\n",
    "        # 选定特征A, A的不同划分取值a 下的gini指数\n",
    "        value_split_list = np.sort(data[:, feature])\n",
    "        value_split = (value_split_list[1:] + value_split_list[:-1]) / 2\n",
    "        gini_one_feature = []\n",
    "        \n",
    "        for value in value_split:\n",
    "            # 每个划分点计算 基尼指数\n",
    "            left, right = self.data_split(data, feature, value)\n",
    "            gini = self.gini_(y[left], y[right])\n",
    "            gini_one_feature.append(gini)\n",
    "        # 得到最小的gini\n",
    "        min_index = np.argmin(gini_one_feature)\n",
    "        return value_split[min_index], gini_one_feature[min_index] \n",
    "\n",
    "    def choose_best_feature(self, X, y, features):\n",
    "        # 寻找最好的 分割特征和分割值\n",
    "        temp = np.zeros((len(features), 3))\n",
    "        for i, feature in enumerate(features):\n",
    "            value, gini = self.choose_best_value(X, y, feature)\n",
    "            temp[i] = [gini, feature, value]\n",
    "        best = np.argmin(temp[:, 0])\n",
    "        return temp[best]\n",
    "    \n",
    "    def build_tree(self, X, y, features):\n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "        u, counts = np.unique(y, return_counts=True)\n",
    "        # 1, 样本个数小于预订阈值, 多数表决\n",
    "        if len(X) < self.sample_least:\n",
    "            return Node(root=True, label=u[counts.argmax()])\n",
    "        \n",
    "        # 2, 若A为空，没有特征继续进行划分了, 则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T\n",
    "        if len(features) == 0:\n",
    "            return Node(root=True, label=u[counts.argmax()])\n",
    "        \n",
    "        # 3. 计算 最佳的特征 分割点 gini\n",
    "        gini, feature, value = self.choose_best_feature(X, y, features)\n",
    "        # 3个一同存储的, 会变成float类型\n",
    "        feature = int(feature)\n",
    "        \n",
    "        # 4 gini指数小于某一值\n",
    "        if gini < self.epsilon:\n",
    "            return Node(root=True, label=u[counts.argmax()], value=value)\n",
    "        \n",
    "        # 5 构建结点\n",
    "        node_tree = Node(root=False, feature=feature, value=value)\n",
    "        features_copy = features.copy()  # 纯数字list的copy\n",
    "        features_copy.remove(feature)\n",
    "        # 左>=  右<\n",
    "        # 6 递归生成树\n",
    "        left, right = self.data_split(X, feature, value)\n",
    "        # print(len(left), len(right), X.shape, y.shape)\n",
    "        left_tree = self.build_tree(X[left], y[left], features_copy)\n",
    "        node_tree.add_node('left', left_tree)\n",
    "        right_tree = self.build_tree(X[right], y[right], features_copy)\n",
    "        node_tree.add_node('right', right_tree)\n",
    "        \n",
    "        return node_tree\n",
    "        \n",
    "    def fit(self, X, y, features):\n",
    "        print('选择的特征', features)\n",
    "        self._tree = self.build_tree(X, y, features)\n",
    "        return self._tree\n",
    "            \n",
    "    def predict(self, X):\n",
    "        ret = np.zeros(X.shape[0])\n",
    "        for i, sample in enumerate(X):\n",
    "            ret[i] = (self._tree.predict(sample))\n",
    "        return ret\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.sum(y_pred == y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_tree = CART()\n",
    "feature_all = list(range(X.shape[1]))\n",
    "cart_tree.fit(X, indices_u, feature_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_tree.score(X, indices_u)  # X 的正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RamdomForest:\n",
    "    def __init__(self, T=21, random_state=0, feature_nums=6):\n",
    "        self.T = T  #  Bagging 方法生成T棵 DT\n",
    "        np.random.seed(random_state)\n",
    "        self.feature_nums = feature_nums  # 选定多少个特征构建决策树\n",
    "        self.trees = []\n",
    "        self.self_validation = 0.0\n",
    "        \n",
    "    @staticmethod\n",
    "    def bagging(n_sample, tree_num):\n",
    "        # 样本数据随机化\n",
    "        indices = np.random.randint(0, n_sample, size=(tree_num, n_sample))\n",
    "        oobs = []\n",
    "        for sample in indices:\n",
    "            oobs.append(np.setdiff1d(range(n_sample), sample))\n",
    "        return indices, oobs\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_feature(tree_num, n_feature, feature_nums):\n",
    "        # 每棵树都从M个特征中选取m个\n",
    "        feature_array = np.zeros((tree_num, feature_nums))\n",
    "        for i in range(tree_num):\n",
    "            feature_index = np.arange(n_feature)\n",
    "            np.random.shuffle(feature_index)\n",
    "            feature_selected = feature_index[:feature_nums]\n",
    "            feature_array[i,:] = feature_selected\n",
    "        return feature_array.astype(int)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_sample, n_feature = X.shape\n",
    "        indices, oobs = self.bagging(n_sample, self.T)\n",
    "        features = self.random_feature(self.T, n_feature, self.feature_nums)\n",
    "        X_samples, y_samples = X[indices, :], y[indices]\n",
    "        \n",
    "        for i in range(self.T):\n",
    "            tree = CART()\n",
    "            tree.fit(X_samples[i, :], y_samples[i], list(features[i]))  # 转成list 方便操作\n",
    "            self.trees.append(tree)\n",
    "        \n",
    "        y_pred = []\n",
    "        for i in range(n_sample):\n",
    "            y_pred_i = []\n",
    "            for j in range(self.T): \n",
    "                # 如果(X_n, y_n)是某棵树的oob, 则使用这棵树判断此样本\n",
    "                if i in oobs[j]:  # [1, 2 ,5, ...]\n",
    "                    y_pred_i.append(self.trees[j].predict(X[[i]]))\n",
    "            # 取平均 计算当前样本预测值 \n",
    "            y_i = np.array(y_pred_i).ravel().mean()\n",
    "            y_pred.append(1 if y_i >= 0 else -1)\n",
    "        # 所有样本的平均表现\n",
    "        self.self_validation = np.sum(y_pred == y) / n_sample\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros((self.T, X.shape[0]))\n",
    "        for i in range(self.T):\n",
    "            y_pred[i] = self.trees[i].predict(X)\n",
    "        y = np.where(np.average(y_pred, axis=0)>0, 1, -1)\n",
    "        return y\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.sum(y==y_pred)/ len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RamdomForest(random_state=12345)\n",
    "rf.fit(X, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.self_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X, y_)  # 比单一决策树好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用sklearn解决**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=21, random_state=12345, n_jobs=-1, oob_score=True)\n",
    "rf.fit(X, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看oob得分\n",
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sk-learn 官方User Guide的例子 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=15)\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[数据科学和人工智能技术笔记 十三、树和森林](https://github.com/apachecn/ds-ai-tech-notes/blob/master/13.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用随机森林\n",
    "clf = RandomForestClassifier(random_state=12345, n_jobs=-1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征的重要性**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算特征重要性  越接近于1 表示越重要\n",
    "importances = clf.feature_importances_  # 所有重要性得分加起来为 100%\n",
    "importances  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整个数据集上的特征重要性分布\n",
    "plt.bar(range(X.shape[1]), importances)\n",
    "plt.title('Feature Importamces')\n",
    "plt.xticks(range(X.shape[1]), iris.feature_names, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用随机森林的特征选择**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用4个特征进行分类的 准确率\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个选择器对象，\n",
    "# 该对象将使用随机森林分类器来标识重要性大于 0.15的特征\n",
    "sfm = SelectFromModel(clf, threshold=0.15)\n",
    "sfm.fit(X_train, y_train)\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)\n",
    "X_important_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm.get_support(indices=True)  # 所选择的特征编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_names = np.array(iris.feature_names)[sfm.get_support()]\n",
    "important_names  # 最重要的2个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用最重要的特征 训练随机森林\n",
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf_important.fit(X_important_train, y_train)\n",
    "# 使用2个特征 的模型准确率\n",
    "y_pred = clf_important.predict(X_important_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在随机森林中处理不平衡类别**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过移除前 40 个观测，生成高度不平衡的类别\n",
    "X = X[30:, ]\n",
    "y = y[30:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中类自动加权，与它们在数据中出现的频率成反比  \n",
    "$$w_j = \\frac {n}{kn_j}$$\n",
    "$w_j$是$j$类的权重, $n$是总观测数, $n_j$是类$j$的观测数, $k$为类的总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0, n_jobs=-1, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
