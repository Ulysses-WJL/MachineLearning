{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4章 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．朴素贝叶斯法是典型的生成学习方法。生成方法由训练数据学习联合概率分布\n",
    "$P(X,Y)$，然后求得后验概率分布$P(Y|X)$。具体来说，利用训练数据学习$P(X|Y)$和$P(Y)$的估计，得到联合概率分布：\n",
    "\n",
    "$$P(X,Y)＝P(Y)P(X|Y)$$\n",
    "\n",
    "概率估计方法可以是极大似然估计或贝叶斯估计。\n",
    "\n",
    "2．朴素贝叶斯法的基本假设是条件独立性，\n",
    "\n",
    "$$\\begin{aligned} P(X&=x | Y=c_{k} )=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} | Y=c_{k}\\right) \\\\ &=\\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right) \\end{aligned}$$\n",
    "\n",
    "\n",
    "这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。\n",
    "\n",
    "3．朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测。\n",
    "\n",
    "$$P(Y | X)=\\frac{P(X, Y)}{P(X)}=\\frac{P(Y) P(X | Y)}{\\sum_{Y} P(Y) P(X | Y)}$$\n",
    " \n",
    "将输入$x$分到后验概率最大的类$y$。\n",
    "\n",
    "$$y=\\arg \\max _{c_{k}} P\\left(Y=c_{k}\\right) \\prod_{j=1}^{n} P\\left(X_{j}=x^{(j)} | Y=c_{k}\\right)$$\n",
    "\n",
    "后验概率最大等价于0-1损失函数时的期望风险最小化。\n",
    "\n",
    "4．朴素贝叶斯法的参数估计(parameter estimation): 估计类条件概率的一种常用策略就是先假定其具有某种确定的概率分布形式, 再基于训练样本对概率分布的参数进行估计. \n",
    "   - 极大似然法, 极大似然估计(Maximum Likehood Estimation, MLE):  \n",
    "   先验概率$P(Y=c_k)$的极大似然估计是:\n",
    "   $$P(Y=c_k) = \\frac {\\sum_{i=1}^N I(y_i=c_k) }{N}, \\quad k=1, 2, \\cdots, K$$\n",
    "   设第j个特征$x^{(j)}$的可取值集合为$\\{a_{j1}, a_{j1}, \\cdots, a_{jS_j}\\}$, 条件概率$P(X^{(j)}=a_{jl}|Y=c_k)$的极大似然估计是:\n",
    "   $$P(X^{(j)}=a_{jl}|Y=c_k) = \\frac {\\sum_{i=1}^{N} I(x^{(j)}=a_{jl}, y_i=c_k)}{\\sum_{i=1}^{N}I(y_i = c_k)}$$\n",
    "   $$j = 1, 2, \\cdots, n; \\quad l=1, 2, \\cdots, S_j; \\quad k=1, 2, \\cdots, K$$\n",
    "   $𝑆𝑗$是第$j$个特征可取的值的数量.\n",
    "   - 贝叶斯估计: 极大似然估计可能会出现所要的概率值为0的情况. 可以使用贝叶斯估计, 条件概率的贝叶斯估计:\n",
    "   $$P_\\lambda(X^{(j)}=a_{jl}|Y=c_k) = \\frac {\\sum_{i=1}^{N} I(x^{(j)}=a_{jl}, y_i=c_k) + \\lambda}{\\sum_{i=1}^{N}I(y_i = c_k) + S_j \\lambda}$$\n",
    "   式中$\\lambda \\geq 0$, 常取$\\lambda = 1$, 这时称为拉普拉斯平滑(Laplacian smoothing).先验概率的贝叶斯估计:\n",
    "   $$P(Y=c_k) = \\frac {\\sum_{i=1}^N I(y_i=c_k) + \\lambda}{N + K\\lambda}, \\quad k=1, 2, \\cdots, K$$\n",
    "模型：\n",
    "\n",
    "- 高斯模型\n",
    "- 多项式模型\n",
    "- 伯努利模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "np.set_printoptions(precision=4, threshold=15,suppress=True)\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "# iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, ..., 1, 0, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.2, 2.8, 4.8, 1.8]), 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7993, 0.3899, 1.6904, 0.742 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7993392332899363"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "\n",
    "## GaussianNB 高斯朴素贝叶斯\n",
    "\n",
    "特征的可能性被假设为高斯\n",
    "\n",
    "概率质量函数(Probability Mass Function, PMF)：\n",
    "$$P(x_i | y_k)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_{yk}}}exp(-\\frac{(x_i-\\mu_{yk})^2}{2\\sigma^2_{yk}})$$\n",
    "概率密度函数(Probability Density Function, PDF)\n",
    "$$f(x;\\mu,\\sigma)=\\frac{1}{\\sigma\\sqrt{2\\pi}} \\, \\exp \\left( -\\frac{(x- \\mu)^2}{2\\sigma^2} \\right)$$\n",
    "数学期望(mean)：$\\mu$\n",
    "\n",
    "方差：$\\sigma^2=\\frac{\\sum(X-\\mu)^2}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设4个特征都服从高斯分布且独立同分布, 使用训练集计算y=0,1和2时的(均值, 方差),条件概率相乘得到\n",
    "# 测试数据带入概率分布函数,计算3种概率,取最大的\n",
    "class NaiveBayes_1:\n",
    "    def __init__(self):\n",
    "        self.model = {}  # {类别0:(mean, std), ...}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        labels, indices = np.unique(y, return_inverse=True)\n",
    "        for label in labels:\n",
    "            mean = np.mean(X[indices==label], axis=0)\n",
    "            var = np.var(X[indices==label], axis=0)\n",
    "            self.model[label] = [mean, var]\n",
    "            # {分类1:[均值1, 方差1]; 分类2:[]}\n",
    "            \n",
    "    def gaussian_probability(self, x, mean, var):\n",
    "        # 计算高斯分布的概率\n",
    "        # x: 2D array-like (n_samples, n_fatures)\n",
    "        p = 1 / np.sqrt(2*var * np.pi) * np.exp(-np.square(x-mean) / (2*var))\n",
    "        # return  np.sum(np.log(p), axis=1) # (n_samples, 1)  取对数 再相加\n",
    "        return np.prod(p, axis=1)  # iid\n",
    "    \n",
    "    def predict(self, x):\n",
    "        temp = []\n",
    "        labels = np.array(list(self.model.keys()))\n",
    "        probs = self.predict_proba(x)\n",
    "        return labels[np.argmax(probs, axis=1)]\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        temp = []\n",
    "        labels = np.array(list(self.model.keys()))\n",
    "        for (mean, var) in self.model.values():\n",
    "            p = self.gaussian_probability(x, mean, var)\n",
    "            temp.append(p)\n",
    "        probs = np.stack(temp, axis=1) # (n_samples, n_labels)\n",
    "        return probs  \n",
    "        \n",
    "    def score(self, X_test, y_test):\n",
    "        return np.sum(self.predict(X_test) == y_test) / len(X_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([5.0727, 3.5182, 1.4788, 0.2485]),\n",
       "  array([0.1244, 0.1603, 0.0314, 0.0092])],\n",
       " 1: [array([5.9844, 2.8   , 4.3094, 1.3469]),\n",
       "  array([0.2819, 0.09  , 0.2677, 0.05  ])],\n",
       " 2: [array([6.5825, 2.9475, 5.555 , 2.0025]),\n",
       "  array([0.4134, 0.0885, 0.2815, 0.0722])]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NaiveBayes_1()\n",
    "model.fit(X_train, y_train)\n",
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[4.4,  3.2,  1.3,  0.2], [5.4,  2.7,  4.3,  1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.1036, 0.1882],\n",
       "       [0.4151, 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.0003],\n",
       "       ...,\n",
       "       [0.    , 0.3824, 0.    ],\n",
       "       [3.1193, 0.    , 0.    ],\n",
       "       [0.0097, 0.    , 0.    ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)  # 未归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    # 数学期望\n",
    "    @staticmethod\n",
    "    def mean(X):\n",
    "        return sum(X) / float(len(X))\n",
    "\n",
    "    # 标准差（方差）\n",
    "    def stdev(self, X):\n",
    "        avg = self.mean(X)\n",
    "        return math.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X)))\n",
    "\n",
    "    # 概率密度函数\n",
    "    def gaussian_probability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) /\n",
    "                              (2 * math.pow(stdev, 2))))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "    # 处理X_train\n",
    "    def summarize(self, train_data):\n",
    "        summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]\n",
    "        return summaries\n",
    "\n",
    "    # 分类别求出数学期望和标准差\n",
    "    def fit(self, X, y):\n",
    "        labels = list(set(y))\n",
    "        data = {label: [] for label in labels}\n",
    "        for f, label in zip(X, y):\n",
    "            data[label].append(f)\n",
    "        self.model = {\n",
    "            label: self.summarize(value)\n",
    "            for label, value in data.items()\n",
    "        }\n",
    "        return 'gaussianNB train done!'\n",
    "\n",
    "    # 计算概率\n",
    "    def calculate_probabilities(self, input_data):\n",
    "        # summaries:{0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]}\n",
    "        # input_data:[1.1, 2.2]\n",
    "        probabilities = {}\n",
    "        for label, value in self.model.items():\n",
    "            probabilities[label] = 1\n",
    "            for i in range(len(value)):\n",
    "                mean, stdev = value[i]\n",
    "                probabilities[label] *= self.gaussian_probability(\n",
    "                    input_data[i], mean, stdev)\n",
    "        return probabilities\n",
    "\n",
    "    # 类别\n",
    "    def predict(self, X_test):\n",
    "        # {0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26}\n",
    "        label = sorted(\n",
    "            self.calculate_probabilities(X_test).items(),\n",
    "            key=lambda x: x[-1])[-1][0]\n",
    "        return label\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            label = self.predict(X)\n",
    "            if label == y:\n",
    "                right += 1\n",
    "\n",
    "        return right / float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gaussianNB train done!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(5.072727272727273, 0.3527147764109446),\n",
       "  (3.518181818181818, 0.4003442045211395),\n",
       "  (1.478787878787879, 0.17711077813578732),\n",
       "  (0.24848484848484853, 0.09573072120564434)],\n",
       " 1: [(5.984375, 0.5309833889821789),\n",
       "  (2.7999999999999994, 0.3),\n",
       "  (4.309375, 0.5174211141565447),\n",
       "  (1.346875, 0.22358496008229176)],\n",
       " 2: [(6.5825000000000005, 0.6429959175609127),\n",
       "  (2.9475, 0.2974789908548165),\n",
       "  (5.554999999999999, 0.5305421755148219),\n",
       "  (2.0025, 0.2687819748420642)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([4.4,  3.2,  1.3,  0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### scikit-learn实例\n",
    "**高斯朴素贝叶斯分类器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.    , 0.    , 0.    ],\n",
       "       [0.    , 0.9998, 0.0002]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([[4.4,  3.2,  1.3,  0.2], [5.4,  2.7,  4.3,  1.2]])  # 原始预测概率未校准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.3057, 0.6943],\n",
       "       [1.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 1.    ],\n",
       "       ...,\n",
       "       [0.    , 1.    , 0.    ],\n",
       "       [1.    , 0.    , 0.    ],\n",
       "       [1.    , 0.    , 0.    ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "带有每个类别的先验概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB(priors=[0.25, 0.25, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[4.4,  3.2,  1.3,  0.2], [5.4,  2.7,  4.3,  1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**校准预测概率**\n",
    "\n",
    "注意：来自高斯朴素贝叶斯的原始预测概率（使用predict_proba输出）未校准。 也就是说，他们不应该是可信的。 如果我们想要创建有用的预测概率，我们将需要使用等渗回归(isotonic regression)或相关方法来校准它们。\n",
    "\n",
    "类别概率是机器学习模型中常见且有用的部分。 在`scikit-learn`中，大多数学习算法允许我们使用`predict_proba`来查看成员的类别预测概率。 例如，如果我们想要仅预测某个类，如果模型预测它们是该类的概率超过 90%，则这非常有用。 然而，一些模型，包括朴素贝叶斯分类器输出的概率，不基于现实世界。 也就是说，`predict_proba`可能预测，观测有 0.70 的机会成为某一类，而实际情况是它是 0.10 或 0.99。 特别是在朴素贝叶斯中，虽然不同目标类别的预测概率的排名是有效的，但是原始预测概率倾向于接近 0 和 1 的极值。\n",
    "\n",
    "为了获得有意义的预测概率，我们需要进行所谓的校准。 在 `scikit-learn` 中，我们可以使用`CalibratedClassifierCV`类，使用 `k-fold` 交叉验证创建校准良好的预测概率。 在`CalibratedClassifierCV`中，训练集用于训练模型，测试集用于校准预测概率。返回的预测概率是 k 折的平均值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CalibratedClassifierCV(base_estimator=None, method='sigmoid', cv='warn')\n",
    "```\n",
    "Probability calibration with isotonic regression or sigmoid.\n",
    "Parameters\n",
    "----------\n",
    "base_estimator : instance BaseEstimator\n",
    "   需要校准的classifier \n",
    "method : 'sigmoid' or 'isotonic'\n",
    "cv : integer, cross-validation generator, iterable or \"prefit\", optional\n",
    "    Determines the cross-validation splitting strategy.\n",
    "    Possible inputs for cv are:\n",
    "\n",
    "    - None, to use the default 3-fold cross-validation,\n",
    "    - integer, to specify the number of folds.\n",
    "    - :term:`CV splitter`,\n",
    "    - An iterable yielding (train, test) splits as arrays of indices.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=GaussianNB(), cv=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf_sigmoid = CalibratedClassifierCV(clf, cv=3, method='sigmoid')\n",
    "clf_sigmoid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sigmoid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9005, 0.0453, 0.0542],\n",
       "       [0.0268, 0.9149, 0.0583]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_observation = [[4.4,  3.2,  1.3,  0.2], [5.4,  2.7,  4.3,  1.2]]\n",
    "# 查看校准概率\n",
    "clf_sigmod.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**伯努利朴素贝叶斯**  \n",
    "伯努利朴素贝叶斯分类器假设我们的所有特征都是二元的，它们仅有两个值（例如，已经是独热编码的标称分类特征）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "X = np.random.randint(2, size=(100, 3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建二元目标向量\n",
    "y = np.random.randint(2, size=(100, 1)).ravel()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建伯努利朴素贝叶斯对象，带有每个类别的先验概率\n",
    "clf = BernoulliNB(class_prior=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [[1, 1, 1], [1, 1, 0], [1, 0, 0], [0, 0, 0], [0, 1, 0], [1, 0, 1], [0, 0, 1], [0, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB(class_prior=[0.25, 0.5])\n",
    "model = clf.fit(X, y)\n",
    "model.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
