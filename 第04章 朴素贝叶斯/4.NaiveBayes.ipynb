{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬4ç«  æœ´ç´ è´å¶æ–¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ï¼æœ´ç´ è´å¶æ–¯æ³•æ˜¯å…¸å‹çš„ç”Ÿæˆå­¦ä¹ æ–¹æ³•ã€‚ç”Ÿæˆæ–¹æ³•ç”±è®­ç»ƒæ•°æ®å­¦ä¹ è”åˆæ¦‚ç‡åˆ†å¸ƒ\n",
    "$P(X,Y)$ï¼Œç„¶åæ±‚å¾—åéªŒæ¦‚ç‡åˆ†å¸ƒ$P(Y|X)$ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨è®­ç»ƒæ•°æ®å­¦ä¹ $P(X|Y)$å’Œ$P(Y)$çš„ä¼°è®¡ï¼Œå¾—åˆ°è”åˆæ¦‚ç‡åˆ†å¸ƒï¼š\n",
    "\n",
    "$$P(X,Y)ï¼P(Y)P(X|Y)$$\n",
    "\n",
    "æ¦‚ç‡ä¼°è®¡æ–¹æ³•å¯ä»¥æ˜¯æå¤§ä¼¼ç„¶ä¼°è®¡æˆ–è´å¶æ–¯ä¼°è®¡ã€‚\n",
    "\n",
    "2ï¼æœ´ç´ è´å¶æ–¯æ³•çš„åŸºæœ¬å‡è®¾æ˜¯æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œ\n",
    "\n",
    "$$\\begin{aligned} P(X&=x | Y=c_{k} )=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} | Y=c_{k}\\right) \\\\ &=\\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right) \\end{aligned}$$\n",
    "\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªè¾ƒå¼ºçš„å‡è®¾ã€‚ç”±äºè¿™ä¸€å‡è®¾ï¼Œæ¨¡å‹åŒ…å«çš„æ¡ä»¶æ¦‚ç‡çš„æ•°é‡å¤§ä¸ºå‡å°‘ï¼Œæœ´ç´ è´å¶æ–¯æ³•çš„å­¦ä¹ ä¸é¢„æµ‹å¤§ä¸ºç®€åŒ–ã€‚å› è€Œæœ´ç´ è´å¶æ–¯æ³•é«˜æ•ˆï¼Œä¸”æ˜“äºå®ç°ã€‚å…¶ç¼ºç‚¹æ˜¯åˆ†ç±»çš„æ€§èƒ½ä¸ä¸€å®šå¾ˆé«˜ã€‚\n",
    "\n",
    "3ï¼æœ´ç´ è´å¶æ–¯æ³•åˆ©ç”¨è´å¶æ–¯å®šç†ä¸å­¦åˆ°çš„è”åˆæ¦‚ç‡æ¨¡å‹è¿›è¡Œåˆ†ç±»é¢„æµ‹ã€‚\n",
    "\n",
    "$$P(Y | X)=\\frac{P(X, Y)}{P(X)}=\\frac{P(Y) P(X | Y)}{\\sum_{Y} P(Y) P(X | Y)}$$\n",
    " \n",
    "å°†è¾“å…¥$x$åˆ†åˆ°åéªŒæ¦‚ç‡æœ€å¤§çš„ç±»$y$ã€‚\n",
    "\n",
    "$$y=\\arg \\max _{c_{k}} P\\left(Y=c_{k}\\right) \\prod_{j=1}^{n} P\\left(X_{j}=x^{(j)} | Y=c_{k}\\right)$$\n",
    "\n",
    "åéªŒæ¦‚ç‡æœ€å¤§ç­‰ä»·äº0-1æŸå¤±å‡½æ•°æ—¶çš„æœŸæœ›é£é™©æœ€å°åŒ–ã€‚\n",
    "\n",
    "4ï¼æœ´ç´ è´å¶æ–¯æ³•çš„å‚æ•°ä¼°è®¡(parameter estimation): ä¼°è®¡ç±»æ¡ä»¶æ¦‚ç‡çš„ä¸€ç§å¸¸ç”¨ç­–ç•¥å°±æ˜¯å…ˆå‡å®šå…¶å…·æœ‰æŸç§ç¡®å®šçš„æ¦‚ç‡åˆ†å¸ƒå½¢å¼, å†åŸºäºè®­ç»ƒæ ·æœ¬å¯¹æ¦‚ç‡åˆ†å¸ƒçš„å‚æ•°è¿›è¡Œä¼°è®¡. \n",
    "   - æå¤§ä¼¼ç„¶æ³•, æå¤§ä¼¼ç„¶ä¼°è®¡(Maximum Likehood Estimation, MLE):  \n",
    "   å…ˆéªŒæ¦‚ç‡$P(Y=c_k)$çš„æå¤§ä¼¼ç„¶ä¼°è®¡æ˜¯:\n",
    "   $$P(Y=c_k) = \\frac {\\sum{i=1}N I(y_i=c_k) }{N}, \\quad k=1, 2, \\cdots, K$$\n",
    "   è®¾ç¬¬jä¸ªç‰¹å¾$x^{(j)}$çš„å¯å–å€¼é›†åˆä¸º$\\{a_{j1}, a_{j1}, \\cdots, a_{jS_j}\\}$, æ¡ä»¶æ¦‚ç‡$P(X^{(j)}=a_{jl}|Y=c_k)$çš„æå¤§ä¼¼ç„¶ä¼°è®¡æ˜¯:\n",
    "   $$P(X^{(j)}=a_{jl}|Y=c_k) = \\frac {\\sum_{i=1}^{N} I(x^{(j)}=a_{jl}, y_i=c_k)}{\\sum_{i=1}^{N}I(y_i = c_k)}$$\n",
    "   $$j = 1, 2, \\cdots, n; \\quad l=1, 2, \\cdots, S_j; \\quad k=1, 2, \\cdots, K$$\n",
    "   $ğ‘†ğ‘—$æ˜¯ç¬¬$j$ä¸ªç‰¹å¾å¯å–çš„å€¼çš„æ•°é‡.\n",
    "   - è´å¶æ–¯ä¼°è®¡: æå¤§ä¼¼ç„¶ä¼°è®¡å¯èƒ½ä¼šå‡ºç°æ‰€è¦çš„æ¦‚ç‡å€¼ä¸º0çš„æƒ…å†µ. å¯ä»¥ä½¿ç”¨è´å¶æ–¯ä¼°è®¡, æ¡ä»¶æ¦‚ç‡çš„è´å¶æ–¯ä¼°è®¡:\n",
    "   $$P_\\lambda(X^{(j)}=a_{jl}|Y=c_k) = \\frac {\\sum_{i=1}^{N} I(x^{(j)}=a_{jl}, y_i=c_k) + \\lambda}{\\sum_{i=1}^{N}I(y_i = c_k) + S_j \\lambda}$$\n",
    "   å¼ä¸­$\\lambda \\geq 0$, å¸¸å–$\\lambda = 1$, è¿™æ—¶ç§°ä¸ºæ‹‰æ™®æ‹‰æ–¯å¹³æ»‘(Laplacian smoothing).å…ˆéªŒæ¦‚ç‡çš„è´å¶æ–¯ä¼°è®¡:\n",
    "   $$P(Y=c_k) = \\frac {\\sum{i=1}N I(y_i=c_k) + \\lambda}{N + K\\lambda}, \\quad k=1, 2, \\cdots, K$$\n",
    "æ¨¡å‹ï¼š\n",
    "\n",
    "- é«˜æ–¯æ¨¡å‹\n",
    "- å¤šé¡¹å¼æ¨¡å‹\n",
    "- ä¼¯åŠªåˆ©æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "np.set_printoptions(precision=4, threshold=15,suppress=True)\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(X_test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‚è€ƒï¼šhttps://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "\n",
    "## GaussianNB é«˜æ–¯æœ´ç´ è´å¶æ–¯\n",
    "\n",
    "ç‰¹å¾çš„å¯èƒ½æ€§è¢«å‡è®¾ä¸ºé«˜æ–¯\n",
    "\n",
    "æ¦‚ç‡è´¨é‡å‡½æ•°(Probability Mass Function, PMF)ï¼š\n",
    "$$P(x_i | y_k)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_{yk}}}exp(-\\frac{(x_i-\\mu_{yk})^2}{2\\sigma^2_{yk}})$$\n",
    "æ¦‚ç‡å¯†åº¦å‡½æ•°(Probability Density Function, PDF)\n",
    "$$f(x;\\mu,\\sigma)=\\frac{1}{\\sigma\\sqrt{2\\pi}} \\, \\exp \\left( -\\frac{(x- \\mu)^2}{2\\sigma^2} \\right)$$\n",
    "æ•°å­¦æœŸæœ›(mean)ï¼š$\\mu$\n",
    "\n",
    "æ–¹å·®ï¼š$\\sigma^2=\\frac{\\sum(X-\\mu)^2}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡è®¾4ä¸ªç‰¹å¾éƒ½æœä»é«˜æ–¯åˆ†å¸ƒä¸”ç‹¬ç«‹åŒåˆ†å¸ƒ, ä½¿ç”¨è®­ç»ƒé›†è®¡ç®—y=0,1å’Œ2æ—¶çš„(å‡å€¼, æ–¹å·®),æ¡ä»¶æ¦‚ç‡ç›¸ä¹˜å¾—åˆ°\n",
    "# æµ‹è¯•æ•°æ®å¸¦å…¥æ¦‚ç‡åˆ†å¸ƒå‡½æ•°,è®¡ç®—3ç§æ¦‚ç‡,å–æœ€å¤§çš„\n",
    "class NaiveBayes_1:\n",
    "    def __init__(self):\n",
    "        self.model = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        labels, indices = np.unique(y, return_inverse=True)\n",
    "        for label in labels:\n",
    "            mean = np.mean(X[indices==label], axis=0)\n",
    "            var = np.var(X[indices==label], axis=0)\n",
    "            self.model[label] = [mean, var]\n",
    "            # {åˆ†ç±»1:[å‡å€¼1, æ–¹å·®1]; åˆ†ç±»2:[]}\n",
    "            \n",
    "    def gaussian_probability(self, x, mean, var):\n",
    "        # è®¡ç®—é«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡\n",
    "        # x: 2D array-like (n_samples, n_fatures)\n",
    "        p = 1 / np.sqrt(2*var * np.pi) * np.exp(-np.square(x-mean) / (2*var))\n",
    "        # return  np.sum(np.log(p), axis=1) # (n_samples, 1)  å–å¯¹æ•° å†ç›¸åŠ \n",
    "        return np.prod(p, axis=1)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        temp = []\n",
    "        labels = np.array(list(self.model.keys()))\n",
    "        probs = self.predict_proba(x)\n",
    "        return labels[np.argmax(probs, axis=1)]\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        temp = []\n",
    "        labels = np.array(list(self.model.keys()))\n",
    "        for (mean, var) in self.model.values():\n",
    "            p = self.gaussian_probability(x, mean, var)\n",
    "            temp.append(p)\n",
    "        probs = np.stack(temp, axis=1) # (n_samples, n_labels)\n",
    "        return probs  \n",
    "        \n",
    "    def score(self, X_test, y_test):\n",
    "        return np.sum(self.predict(X_test) == y_test) / len(X_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes_1()\n",
    "model.fit(X_train, y_train)\n",
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[4.4,  3.2,  1.3,  0.2], [5.4,  2.7,  4.3,  1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    # æ•°å­¦æœŸæœ›\n",
    "    @staticmethod\n",
    "    def mean(X):\n",
    "        return sum(X) / float(len(X))\n",
    "\n",
    "    # æ ‡å‡†å·®ï¼ˆæ–¹å·®ï¼‰\n",
    "    def stdev(self, X):\n",
    "        avg = self.mean(X)\n",
    "        return math.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X)))\n",
    "\n",
    "    # æ¦‚ç‡å¯†åº¦å‡½æ•°\n",
    "    def gaussian_probability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) /\n",
    "                              (2 * math.pow(stdev, 2))))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "    # å¤„ç†X_train\n",
    "    def summarize(self, train_data):\n",
    "        summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]\n",
    "        return summaries\n",
    "\n",
    "    # åˆ†ç±»åˆ«æ±‚å‡ºæ•°å­¦æœŸæœ›å’Œæ ‡å‡†å·®\n",
    "    def fit(self, X, y):\n",
    "        labels = list(set(y))\n",
    "        data = {label: [] for label in labels}\n",
    "        for f, label in zip(X, y):\n",
    "            data[label].append(f)\n",
    "        self.model = {\n",
    "            label: self.summarize(value)\n",
    "            for label, value in data.items()\n",
    "        }\n",
    "        return 'gaussianNB train done!'\n",
    "\n",
    "    # è®¡ç®—æ¦‚ç‡\n",
    "    def calculate_probabilities(self, input_data):\n",
    "        # summaries:{0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]}\n",
    "        # input_data:[1.1, 2.2]\n",
    "        probabilities = {}\n",
    "        for label, value in self.model.items():\n",
    "            probabilities[label] = 1\n",
    "            for i in range(len(value)):\n",
    "                mean, stdev = value[i]\n",
    "                probabilities[label] *= self.gaussian_probability(\n",
    "                    input_data[i], mean, stdev)\n",
    "        return probabilities\n",
    "\n",
    "    # ç±»åˆ«\n",
    "    def predict(self, X_test):\n",
    "        # {0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26}\n",
    "        label = sorted(\n",
    "            self.calculate_probabilities(X_test).items(),\n",
    "            key=lambda x: x[-1])[-1][0]\n",
    "        return label\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            label = self.predict(X)\n",
    "            if label == y:\n",
    "                right += 1\n",
    "\n",
    "        return right / float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict([4.4,  3.2,  1.3,  0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### scikit-learnå®ä¾‹\n",
    "**é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([[4.4,  3.2,  1.3,  0.2], [5.4,  2.7,  4.3,  1.2]])  # åŸå§‹é¢„æµ‹æ¦‚ç‡æœªæ ¡å‡†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¸¦æœ‰æ¯ä¸ªç±»åˆ«çš„å…ˆéªŒæ¦‚ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB(priors=[0.25, 0.25, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[4.4,  3.2,  1.3,  0.2], [5.4,  2.7,  4.3,  1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ ¡å‡†é¢„æµ‹æ¦‚ç‡**\n",
    "\n",
    "æ³¨æ„ï¼šæ¥è‡ªé«˜æ–¯æœ´ç´ è´å¶æ–¯çš„åŸå§‹é¢„æµ‹æ¦‚ç‡ï¼ˆä½¿ç”¨predict_probaè¾“å‡ºï¼‰æœªæ ¡å‡†ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œä»–ä»¬ä¸åº”è¯¥æ˜¯å¯ä¿¡çš„ã€‚ å¦‚æœæˆ‘ä»¬æƒ³è¦åˆ›å»ºæœ‰ç”¨çš„é¢„æµ‹æ¦‚ç‡ï¼Œæˆ‘ä»¬å°†éœ€è¦ä½¿ç”¨ç­‰æ¸—å›å½’(isotonic regression)æˆ–ç›¸å…³æ–¹æ³•æ¥æ ¡å‡†å®ƒä»¬ã€‚\n",
    "\n",
    "ç±»åˆ«æ¦‚ç‡æ˜¯æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­å¸¸è§ä¸”æœ‰ç”¨çš„éƒ¨åˆ†ã€‚ åœ¨`scikit-learn`ä¸­ï¼Œå¤§å¤šæ•°å­¦ä¹ ç®—æ³•å…è®¸æˆ‘ä»¬ä½¿ç”¨`predict_proba`æ¥æŸ¥çœ‹æˆå‘˜çš„ç±»åˆ«é¢„æµ‹æ¦‚ç‡ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦ä»…é¢„æµ‹æŸä¸ªç±»ï¼Œå¦‚æœæ¨¡å‹é¢„æµ‹å®ƒä»¬æ˜¯è¯¥ç±»çš„æ¦‚ç‡è¶…è¿‡ 90%ï¼Œåˆ™è¿™éå¸¸æœ‰ç”¨ã€‚ ç„¶è€Œï¼Œä¸€äº›æ¨¡å‹ï¼ŒåŒ…æ‹¬æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è¾“å‡ºçš„æ¦‚ç‡ï¼Œä¸åŸºäºç°å®ä¸–ç•Œã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œ`predict_proba`å¯èƒ½é¢„æµ‹ï¼Œè§‚æµ‹æœ‰ 0.70 çš„æœºä¼šæˆä¸ºæŸä¸€ç±»ï¼Œè€Œå®é™…æƒ…å†µæ˜¯å®ƒæ˜¯ 0.10 æˆ– 0.99ã€‚ ç‰¹åˆ«æ˜¯åœ¨æœ´ç´ è´å¶æ–¯ä¸­ï¼Œè™½ç„¶ä¸åŒç›®æ ‡ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡çš„æ’åæ˜¯æœ‰æ•ˆçš„ï¼Œä½†æ˜¯åŸå§‹é¢„æµ‹æ¦‚ç‡å€¾å‘äºæ¥è¿‘ 0 å’Œ 1 çš„æå€¼ã€‚\n",
    "\n",
    "ä¸ºäº†è·å¾—æœ‰æ„ä¹‰çš„é¢„æµ‹æ¦‚ç‡ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œæ‰€è°“çš„æ ¡å‡†ã€‚ åœ¨ `scikit-learn` ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`CalibratedClassifierCV`ç±»ï¼Œä½¿ç”¨ `k-fold` äº¤å‰éªŒè¯åˆ›å»ºæ ¡å‡†è‰¯å¥½çš„é¢„æµ‹æ¦‚ç‡ã€‚ åœ¨`CalibratedClassifierCV`ä¸­ï¼Œè®­ç»ƒé›†ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œæµ‹è¯•é›†ç”¨äºæ ¡å‡†é¢„æµ‹æ¦‚ç‡ã€‚è¿”å›çš„é¢„æµ‹æ¦‚ç‡æ˜¯ k æŠ˜çš„å¹³å‡å€¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CalibratedClassifierCV(base_estimator=None, method='sigmoid', cv='warn')\n",
    "```\n",
    "Probability calibration with isotonic regression or sigmoid.\n",
    "Parameters\n",
    "----------\n",
    "base_estimator : instance BaseEstimator\n",
    "   éœ€è¦æ ¡å‡†çš„classifier \n",
    "method : 'sigmoid' or 'isotonic'\n",
    "cv : integer, cross-validation generator, iterable or \"prefit\", optional\n",
    "    Determines the cross-validation splitting strategy.\n",
    "    Possible inputs for cv are:\n",
    "\n",
    "    - None, to use the default 3-fold cross-validation,\n",
    "    - integer, to specify the number of folds.\n",
    "    - :term:`CV splitter`,\n",
    "    - An iterable yielding (train, test) splits as arrays of indices.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "# ä½¿ç”¨ sigmoid æ ¡å‡†åˆ›å»ºæ ¡å‡†çš„äº¤å‰éªŒè¯\n",
    "clf = GaussianNB()\n",
    "clf_sigmod = CalibratedClassifierCV(clf, cv=2, method='sigmoid')\n",
    "clf_sigmod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_observation = [[4.4,  3.2,  1.3,  0.2], [5.4,  2.7,  4.3,  1.2]]\n",
    "# æŸ¥çœ‹æ ¡å‡†æ¦‚ç‡\n",
    "clf_sigmod.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯**  \n",
    "ä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨å‡è®¾æˆ‘ä»¬çš„æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯äºŒå…ƒçš„ï¼Œå®ƒä»¬ä»…æœ‰ä¸¤ä¸ªå€¼ï¼ˆä¾‹å¦‚ï¼Œå·²ç»æ˜¯ç‹¬çƒ­ç¼–ç çš„æ ‡ç§°åˆ†ç±»ç‰¹å¾ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# åˆ›å»º å¸¦3ä¸ªäºŒå…ƒç‰¹å¾çš„æ•°æ®  \n",
    "X = np.random.randint(2, size=(100, 3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºäºŒå…ƒç›®æ ‡å‘é‡\n",
    "y = np.random.randint(2, size=(100, 1)).ravel()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯å¯¹è±¡ï¼Œå¸¦æœ‰æ¯ä¸ªç±»åˆ«çš„å…ˆéªŒæ¦‚ç‡\n",
    "clf = BernoulliNB(class_prior=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [[1, 1, 1], [1, 1, 0], [1, 0, 0], [0, 0, 0], [0, 1, 0], [1, 0, 1], [0, 0, 1], [0, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BernoulliNB(class_prior=[0.25, 0.5])\n",
    "model = clf.fit(X, y)\n",
    "model.predict(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
