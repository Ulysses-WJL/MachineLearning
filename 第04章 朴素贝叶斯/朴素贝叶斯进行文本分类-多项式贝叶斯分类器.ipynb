{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4, threshold=15,suppress=True)\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**多项式朴素贝叶斯分类器**  \n",
    "多项式分布(Multinomial Distribution)是二项式分布的推广。二项式做n次伯努利实验，规定了每次试验的结果只有两个，如果现在还是做n次试验，只不过每次试验的结果可以有多m个，且m个结果发生的概率互斥且和为1，则发生其中一个结果X次的概率就是多项式分布。  \n",
    "\n",
    "多项式朴素贝叶斯的工作方式类似于高斯朴素贝叶斯，但假设这些特征是多项式分布的。 在实践中，这意味着当我们具有离散数据（例如，电影评级范围为 1 到 5）时，通常使用该分类器。\n",
    "\n",
    "分布参数由每类 y 的 $\\theta_y = (\\theta_{y_1},\\ldots,\\theta_{y_n})$ 向量决定， 式中 n 是特征的数量(对于文本分类，是词汇量的大小) $\\theta_{y_i}$ 是样本中属于类 y 中特征 i 概率 $P(x_i \\mid y)$ 。\n",
    "\n",
    "参数 $\\theta_y$ 使用平滑过的最大似然估计法来估计，即相对频率计数:\n",
    "\n",
    "$$\\hat{\\theta}{y_i} = \\frac{ N{y_i} + \\alpha}{N_y + \\alpha n}$$\n",
    "\n",
    "式中$N_{y_i} = \\sum_{x \\in T} x_i$是 训练集T中特征i在类y中出现的次数，$N_{y} = \\sum_{i=1}^{|T|} N_{y_i}$ 是类 y 中出现所有特征的计数总和。\n",
    "\n",
    "先验平滑因子 $\\alpha \\ge 0$ 为在学习样本中没有出现的特征而设计，以防在将来的计算中出现0概率输出。 把 $\\alpha = 1$ 被称为拉普拉斯平滑(Lapalce smoothing)，而 $\\alpha < 1$ 被称为Lidstone平滑方法(Lidstone smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯的文本分类\n",
    "---\n",
    "使用朴素贝叶斯进行文本分类；我们将有一组带有相应类别的文本文档，我们将训练一个朴素贝叶斯算法，来学习预测新的没见过的实例的类别。这项简单的任务有许多实际应用；可能是最知名和广泛使用的**垃圾邮件过滤**。在本节中，我们将尝试使用可以从 scikit-learn 中检索的数据集，对新闻组消息进行分类。该数据集包括来自 20 个不同主题的大约 19,000 条新闻组信息，从政治和宗教到体育和科学。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # 文本特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups(subset='all')  # 导入所有实例 [‘train’ or ‘test’, ‘all’, optional]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回的数据bunch  \n",
    "* bunch.data: list, length [n_samples]\n",
    "* bunch.target: array, shape [n_samples]\n",
    "* bunch.filenames: list, length [n_samples]\n",
    "* bunch.DESCR: a description of the dataset.\n",
    "* bunch.target_names: a list of categories of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
