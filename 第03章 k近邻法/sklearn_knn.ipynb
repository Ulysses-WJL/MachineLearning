{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, threshold=15,suppress=True)\n",
    "pd.options.display.max_rows = 20\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the Nearest Neighbors**\n",
    "\n",
    "For the simple task of finding the nearest neighbors between two sets of data, the unsupervised algorithms within\n",
    "sklearn.neighbors can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "X = np.array([[-1., -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)  # 训练集\n",
    "nbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NearestNeighbors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbrs.kneighbors?\n",
    "```\n",
    "Signature: nbrs.kneighbors(X=None, n_neighbors=None, return_distance=True)\n",
    "Docstring:\n",
    "Finds the K-neighbors of a point.\n",
    "Returns indices of and distances to the neighbors of each point.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
    "    The query point or points.\n",
    "    If not provided, neighbors of each indexed point are returned.\n",
    "    In this case, the query point is not considered its own neighbor.\n",
    "\n",
    "n_neighbors : int\n",
    "    Number of neighbors to get (default is the value\n",
    "    passed to the constructor).\n",
    "\n",
    "return_distance : boolean, optional. Defaults to True.\n",
    "    If False, distances will not be returned\n",
    "\n",
    "Returns\n",
    "-------\n",
    "dist : array\n",
    "    Array representing the lengths to points, only present if\n",
    "    return_distance=True\n",
    "\n",
    "ind : array\n",
    "    Indices of the nearest points in the population matrix.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "In the following example, we construct a NeighborsClassifier\n",
    "class from an array representing our data set and ask who's\n",
    "the closest point to [1,1,1]\n",
    "\n",
    ">>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
    ">>> from sklearn.neighbors import NearestNeighbors\n",
    ">>> neigh = NearestNeighbors(n_neighbors=1)\n",
    ">>> neigh.fit(samples) # doctest: +ELLIPSIS\n",
    "NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n",
    ">>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\n",
    "(array([[0.5]]), array([[2]]))\n",
    "\n",
    "As you can see, it returns [[0.5]], and [[2]], which means that the\n",
    "element is at distance 0.5 and is the third element of samples\n",
    "(indexes start at 0). You can also query for multiple points:\n",
    "\n",
    ">>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
    ">>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\n",
    "array([[1],\n",
    "       [2]]...)\n",
    "File:      d:\\python3.7\\lib\\site-packages\\sklearn\\neighbors\\base.py\n",
    "Type:      method\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nbrs.kneighbors(X)  # 查询集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances  # (dis1, dis2)最近的2个点的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices  # 最近的2个点的index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the query set matches the training set, the nearest neighbor of each point is the point itself, at a distance ofzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs.kneighbors_graph(X).toarray()\n",
    "# produce a sparse graph(稀疏图) showing the connections between neighboring points:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KDTree and BallTree Classes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "kdt = KDTree(X, leaf_size=30, metric='euclidean')  # 欧式距离  叶节点\n",
    "kdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kdt.query(X, k=2, return_distance=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "- n_neighbors: 临近点个数\n",
    "- p: 距离度量 Power parameter for the Minkowski metric 默认2\n",
    "- algorithm: 近邻算法，可选{'auto', 'ball_tree', 'kd_tree', 'brute'}\n",
    " * 'auto': 根据传递给`fit`方法的数据自行推断使用的算法\n",
    " * 'brute': 暴力求解 复杂度$O(DN^2)$\n",
    " * 'kd_tree': 使用KDTree, 对于小于20的D,$O(DlogN)$;对于较大的D接近$O(DN)$\n",
    " * 'ball_tree': 使用BallTree, 复杂度$O(DlogN)$\n",
    "- weights: 确定近邻的权重\n",
    " * 'uniform': 均匀分布. 所有邻近点的权重是一致的\n",
    " * 'dustance': 与距离成反比. 距离近的点的权重更大\n",
    " * [callbale]: a user-defined function which accepts an array of distances, and returns an\n",
    "    array of the same shape containing the weights.\n",
    "- leaf_size: Leaf size passed to BallTree or KDTree. 对于小数据集 (n小于30), log(N)相当于N, 暴力算法比基于树的算法更加有效, 控制了查询切换到暴力计算样本数量. 默认30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用鸢尾花数据进行分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from figures import plot_2d_separator\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data # [:100, :2]\n",
    "Y = iris.target # [:100]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建标准化器 4个特征都进行处理\n",
    "X_std1 = normalize(X[:, :2], 'l2')\n",
    "X_std1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std2 = normalize(X[:, 2:], 'l2')\n",
    "X_std2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_std = np.concatenate((X_std1, X_std2), axis=1)\n",
    "standardizer = StandardScaler().fit(X)\n",
    "X_std = standardizer.transform(X)\n",
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_std, Y, test_size=0.2)  # 将样本分为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5, weights='distance').fit(X_train, Y_train)\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, Y_test)  # 使用测试集测试正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_node = [4.9, 3. , 1.4, 0.2]\n",
    "node = standardizer.transform([test_node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[Y_train == 0, 0], X_train[Y_train == 0, 1], s=40, label='0')\n",
    "plt.scatter(X_train[Y_train == 1, 0], X_train[Y_train == 1, 1], s=40, label='1', marker='s')  # 方型\n",
    "plt.xlabel(\"first feature\")\n",
    "plt.ylabel(\"second feature\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
