{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10章 隐马尔可夫模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态的序列，再由各个状态随机生成一个观测而产生观测的序列的过程。\n",
    "\n",
    "隐马尔可夫模型由初始状态概率向$\\pi$、状态转移概率矩阵$A$和观测概率矩阵$B$决定。因此，隐马尔可夫模型可以写成$\\lambda=(A, B, \\pi)$。\n",
    "\n",
    "隐马尔可夫模型是一个生成模型，表示状态序列和观测序列的联合分布，但是状态序列是隐藏的，不可观测的。\n",
    "\n",
    "隐马尔可夫模型可以用于标注，这时状态对应着标记。标注问题是给定观测序列预测其对应的标记序列。\n",
    "\n",
    "2．概率计算问题。给定模型$\\lambda=(A, B, \\pi)$和观测序列$O＝(o_1，o_2,…,o_T)$，计算在模型$\\lambda$下观测序列$O$出现的概率$P(O|\\lambda)$。前向-后向算法是通过递推地计算前向-后向概率可以高效地进行隐马尔可夫模型的概率计算。\n",
    " \n",
    "3．学习问题。已知观测序列$O＝(o_1，o_2,…,o_T)$，估计模型$\\lambda=(A, B, \\pi)$参数，使得在该模型下观测序列概率$P(O|\\lambda)$最大。即用极大似然估计的方法估计参数。Baum-Welch算法，也就是EM算法可以高效地对隐马尔可夫模型进行训练。它是一种非监督学习算法。\n",
    "\n",
    "4．预测问题。已知模型$\\lambda=(A, B, \\pi)$和观测序列$O＝(o_1，o_2,…,o_T)$，求对给定观测序列条件概率$P(I|O)$最大的状态序列$I＝(i_1，i_2,…,i_T)$。维特比算法应用动态规划高效地求解最优路径，即概率最大的状态序列。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 马尔可夫链\n",
    "## 马尔可夫(Markov)过程及其概率分布\n",
    "**马尔可夫性**或**无后效性**: 过程(或系统)在时刻$t_0$所处状态为已知条件下, 过程在时刻$t>t_0$所处状态的条件分布与过程在时刻$t_0$之前所处的状态无关. 通俗地说, 就是在已知过程\"现在\"的条件下, 其\"将来\"不依赖于\"过去\".\n",
    "\n",
    "设随机过程$\\{X(t), t \\in T\\}$的状态空间为$I$. 如果对时间$t$的任意$n$个数值$t_1<t_2< \\cdots< t_n, n\\geq3, t_i \\in T $, 在条件$X(t_i)=x_i, x_i \\in I, i=1,2, \\cdots, n-1$下, $X(t_n)$的条件分布函数恰等于在条件$X(t_{n-1})=x_{n-1}$下$X(t_n)$的条件分布函数, 即\n",
    "$$\n",
    "P\\{X(t_n) \\leq x_n| X(t_1)=x_1, X(t_2)=x_2, \\cdots, X(t_{n-1})=x_{n-1}\\} \\\\\n",
    "= P\\{X(t_{n}) \\leq x_{n}|X(t_{n-1})=x_{n-1}\\}, x_n \\in \\mathcal R\n",
    "$$\n",
    "或写成\n",
    "$$F_{t_n|t_1\\cdots t_{n-1}}(x_n,t_n|x_1, x_2, \\cdots, x_{n-1};t_1, t_2, \\cdots, t_{n-1}) \n",
    "= F_{t_n|t_{n-1}}(x_n, t_n|x_{n-1},t_{n-1})\n",
    "$$\n",
    "则称过程$\\{X(t), t\\in T\\}$具有马尔可夫性或无后效性, 并称此过程为**马尔可夫过程**\n",
    "\n",
    "时间和状态都是**离散**的马尔可夫过程称为**马尔可夫链**, 简称马氏链, 记为$\\{X_n=X(n), n=0, 1, 2, \\cdots\\}$, 它可以看作在时间集$T_1 = \\{0, 1, 2, \\cdots\\}$上对离散状态的马尔可夫过程相继观察的结果.记链的状态空间为$I=\\{a_1, a_2, \\cdots\\}, a_i \\in R$, 马尔可夫性常用条件分布律来表示, 即对任意的正整数$n,r$和$0\\leq t_1 < t_2<\\cdots<t_r<t_m; t_i,m,m+n \\in T_1$, 有\n",
    "$$P\\{X_{m+n}= a_j|X_{t_1}=a_{1}, X_{t_2}=a_{2}, \\cdots X_{t_r}=a_{r}, X_{m}=a_{i}\\} \\\\\n",
    "= P\\{X_{m+n}=a_j |X_m=a_i\\}\n",
    "$$\n",
    "记上式右端为$P_{ij}(m, m+n)$, 称条件概率\n",
    "$$P_{ij}(m, m+n) = P\\{X_{m+n}=a_j | X_m=a_i\\}$$\n",
    "为马尔科夫链在时刻$m$处于状态$a_i$条件下, 在时刻$m+n$转移到状态$a_j$的**转移概率**.  \n",
    "由于链在时刻$m$从任何一个状态$a_i$出发, 到另一时刻$m+n$, 必然转移到$a_1, a_2, \\cdots$诸状态中的某一个,所以\n",
    "$$\\sum_{j}P_{ij}(m, m+n) = 1, \\quad i=1, 2, \\cdots.$$\n",
    "由转移概率组成的矩阵$P(m, m+n) = (P_{ij}(m, m+n))$称为马氏链的**转移概率矩阵**, 每一行之和等于1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当转移概率$P_{ij}(m, m+n)$只与$i,j$及时间间距$n$有关时, 把它记为$P_{ij}(n)$, 即\n",
    "$$P_{ij}(m, m+n) = P_{ij}(n)$$\n",
    "并称此转移概率具有**平稳性**. 同时也称此链是**齐次**的或**齐时**的. 在齐次情形下, 上述定义的转移概率可以写成\n",
    "$$P_{ij}(n) = P\\{X_{m+n}=a_j|X_m=a_i\\}$$\n",
    "称为马氏链的**n步转移概率**, $P(n)=(P_{ij}(n))$为**n步转移概率矩阵**. 其中特别重要的就是一步转移概率\n",
    "$$p_{ij}=P_{ij}(1)=P\\{X_{m+1}=a_j|X_m=a_i\\}$$\n",
    "和他们组成的一步转移概率矩阵\n",
    "$$\\begin{bmatrix}p_{11} & p_{12} & \\cdots & p_{1j} & \\cdots \\\\\n",
    "p_{21} & p_{22} & \\cdots & p_{2j} & \\cdots \\\\\n",
    "\\vdots & \\vdots& &\\vdots \\\\\n",
    "p_{i1} & p_{i2} & \\cdots & p_{ij} & \\cdots \\\\\n",
    "\\vdots & \\vdots& &\\vdots \\\\\n",
    "\\end{bmatrix} = P(1)$$\n",
    "记作$P.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隐马尔可夫模型(hidden Markov model, HMM)\n",
    "隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态的序列(状态序列, state sequence)，再由各个状态随机生成一个观测而产生观测的序列(观测序列, observation sequence)的过程。序列的每一个位置又可以看作是一个时刻.\n",
    "设$Q$为所有可能的状态集合, $V$是所有可能的观测集合:\n",
    "$$Q=\\{q_1, q_2, \\cdots, q_N\\}, \\quad V=\\{v_1, v_2, \\cdots, v_M\\}$$\n",
    "其中, $N$是可能的状态数, $M$是可能的观测数.  \n",
    "$I$是长度$T$的状态序列, $O$是对应的观测序列:\n",
    "$$I=(i_1, i_2, \\cdots, i_T), \\quad O=(o_1, o_2, \\cdots, o_T)$$\n",
    "$A$是(一步)状态转移概率矩阵:\n",
    "$$A=[a_{ij}]_{N\\times N}$$\n",
    "$$a_{ij}=P(i_{t+1}=q_j|i_t=q_i), \\quad i=1, 2, \\cdots, N; \\quad j=1, 2, \\cdots, N$$\n",
    "与上述$P_{ij}(1)$含义相同.\n",
    "$B$是观测概率矩阵:\n",
    "$$B=[b_j(k)]_{N\\times M}$$\n",
    "其中,\n",
    "$$b_j(k)=P(o_t=v_k|i_t=q_j), \\quad k=1, 2, \\cdots, M; \\quad j=1, 2, \\cdots, N$$\n",
    "是在时刻$t$处于状态$q_i$条件下生成观测$v_k$的概率.\n",
    "$\\pi$是初始状态概率向量:\n",
    "$$\\pi = (\\pi_i)$$\n",
    "其中,\n",
    "$$\\pi_i = P(i_1 = q_i), \\quad i=1, 2, \\cdots, N$$\n",
    "是初始时刻$t=1$处于状态$q_i$的概率.\n",
    "\n",
    "隐马尔可夫模型由初始状态概率向$\\pi$、状态转移概率矩阵$A$和观测概率矩阵$B$决定。因此，隐马尔可夫模型可以写成\n",
    "$$\\lambda=(A, B, \\pi)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例1 股市模型\n",
    "def markov_market(init, transfer, n):\n",
    "    # 股市 bull 0 , bear 1 , stagnant 2 \n",
    "    # 初始状态\n",
    "    init_array = init\n",
    "    # 一步状态转移矩阵\n",
    "    transfer_array = transfer\n",
    "    temp = init_array\n",
    "    for i in range(n):\n",
    "        res = np.dot(temp, transfer_array)\n",
    "        print(f'{i}\\t{res}')\n",
    "        temp = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer = np.array([[0.9, 0.075, 0.025],\n",
    "                   [0.15, 0.8, 0.05],\n",
    "                   [0.25, 0.25, 0.5]])\n",
    "init = np.array([0.1, 0.2, 0.7])\n",
    "markov_market(init, transfer, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_market(np.array([0.3, 0.3, 0.4]), transfer, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到初始状态$a_1$发生变化, 但两者都在第18次时候, 收敛到$[0.624, 0.312, 0.0625]$. 不管初始状态是什么样子, 只要状态转移矩阵不变, 当$n\\rightarrow \\infty$时, 最终状态始终会收敛到一个固定值."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 状态转移矩阵的n次幂\n",
    "def matrix_power(matrix, n):\n",
    "    temp = matrix\n",
    "    for i in range(n):\n",
    "        res = np.dot(temp, matrix)\n",
    "        print(f'{i}\\t{res}')\n",
    "        temp = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_power(transfer, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着幂的次数的增加, 结果开始收敛, 每一行都为$[0.624, 0.312, 0.0625]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkov:\n",
    "    def forward(self, Q, V, A, B, O, PI):  # 使用前向算法\n",
    "        N = len(Q)  #可能存在的状态数量\n",
    "        M = len(O)  # 观测序列的大小\n",
    "        alphas = np.zeros((N, M))  # alpha值\n",
    "        T = M  # 有几个时刻，有几个观测序列，就有几个时刻\n",
    "        for t in range(T):  # 遍历每一时刻，算出alpha值\n",
    "            indexOfO = V.index(O[t])  # 找出序列对应的索引\n",
    "            for i in range(N):\n",
    "                if t == 0:  # 计算初值\n",
    "                    alphas[i][t] = PI[t][i] * B[i][indexOfO]  # P176（10.15）\n",
    "                    print(\n",
    "                        'alpha1(%d)=p%db%db(o1)=%f' % (i, i, i, alphas[i][t]))\n",
    "                else:\n",
    "                    alphas[i][t] = np.dot(\n",
    "                        [alpha[t - 1] for alpha in alphas],\n",
    "                        [a[i] for a in A]) * B[i][indexOfO]  # 对应P176（10.16）\n",
    "                    print('alpha%d(%d)=[sigma alpha%d(i)ai%d]b%d(o%d)=%f' %\n",
    "                          (t, i, t - 1, i, i, t, alphas[i][t]))\n",
    "                    # print(alphas)\n",
    "        P = np.sum([alpha[M - 1] for alpha in alphas])  # P176(10.17)\n",
    "        # alpha11 = pi[0][0] * B[0][0]    #代表a1(1)\n",
    "        # alpha12 = pi[0][1] * B[1][0]    #代表a1(2)\n",
    "        # alpha13 = pi[0][2] * B[2][0]    #代表a1(3)\n",
    "\n",
    "    def backward(self, Q, V, A, B, O, PI):  # 后向算法\n",
    "        N = len(Q)  # 可能存在的状态数量\n",
    "        M = len(O)  # 观测序列的大小\n",
    "        betas = np.ones((N, M))  # beta\n",
    "        for i in range(N):\n",
    "            print('beta%d(%d)=1' % (M, i))\n",
    "        for t in range(M - 2, -1, -1):\n",
    "            indexOfO = V.index(O[t + 1])  # 找出序列对应的索引\n",
    "            for i in range(N):\n",
    "                betas[i][t] = np.dot(\n",
    "                    np.multiply(A[i], [b[indexOfO] for b in B]),\n",
    "                    [beta[t + 1] for beta in betas])\n",
    "                realT = t + 1\n",
    "                realI = i + 1\n",
    "                print(\n",
    "                    'beta%d(%d)=[sigma a%djbj(o%d)]beta%d(j)=(' %\n",
    "                    (realT, realI, realI, realT + 1, realT + 1),\n",
    "                    end='')\n",
    "                for j in range(N):\n",
    "                    print(\n",
    "                        \"%.2f*%.2f*%.2f+\" % (A[i][j], B[j][indexOfO],\n",
    "                                             betas[j][t + 1]),\n",
    "                        end='')\n",
    "                print(\"0)=%.3f\" % betas[i][t])\n",
    "        # print(betas)\n",
    "        indexOfO = V.index(O[0])\n",
    "        P = np.dot(\n",
    "            np.multiply(PI, [b[indexOfO] for b in B]),\n",
    "            [beta[0] for beta in betas])\n",
    "        print(\"P(O|lambda)=\", end=\"\")\n",
    "        for i in range(N):\n",
    "            print(\n",
    "                \"%.1f*%.1f*%.5f+\" % (PI[0][i], B[i][indexOfO], betas[i][0]),\n",
    "                end=\"\")\n",
    "        print(\"0=%f\" % P)\n",
    "\n",
    "    def viterbi(self, Q, V, A, B, O, PI):\n",
    "        N = len(Q)  #可能存在的状态数量\n",
    "        M = len(O)  # 观测序列的大小\n",
    "        deltas = np.zeros((N, M))\n",
    "        psis = np.zeros((N, M))\n",
    "        I = np.zeros((1, M))\n",
    "        for t in range(M):\n",
    "            realT = t + 1\n",
    "            indexOfO = V.index(O[t])  # 找出序列对应的索引\n",
    "            for i in range(N):\n",
    "                realI = i + 1\n",
    "                if t == 0:\n",
    "                    deltas[i][t] = PI[0][i] * B[i][indexOfO]\n",
    "                    psis[i][t] = 0\n",
    "                    print('delta1(%d)=pi%d * b%d(o1)=%.2f * %.2f=%.2f' %\n",
    "                          (realI, realI, realI, PI[0][i], B[i][indexOfO],\n",
    "                           deltas[i][t]))\n",
    "                    print('psis1(%d)=0' % (realI))\n",
    "                else:\n",
    "                    deltas[i][t] = np.max(\n",
    "                        np.multiply([delta[t - 1] for delta in deltas],\n",
    "                                    [a[i] for a in A])) * B[i][indexOfO]\n",
    "                    print(\n",
    "                        'delta%d(%d)=max[delta%d(j)aj%d]b%d(o%d)=%.2f*%.2f=%.5f'\n",
    "                        % (realT, realI, realT - 1, realI, realI, realT,\n",
    "                           np.max(\n",
    "                               np.multiply([delta[t - 1] for delta in deltas],\n",
    "                                           [a[i] for a in A])), B[i][indexOfO],\n",
    "                           deltas[i][t]))\n",
    "                    psis[i][t] = np.argmax(\n",
    "                        np.multiply(\n",
    "                            [delta[t - 1] for delta in deltas],\n",
    "                            [a[i]\n",
    "                             for a in A])) + 1  #由于其返回的是索引，因此应+1才能和正常的下标值相符合。\n",
    "                    print('psis%d(%d)=argmax[delta%d(j)aj%d]=%d' %\n",
    "                          (realT, realI, realT - 1, realI, psis[i][t]))\n",
    "        print(deltas)\n",
    "        print(psis)\n",
    "        I[0][M - 1] = np.argmax([delta[M - 1] for delta in deltas\n",
    "                                 ]) + 1  #由于其返回的是索引，因此应+1才能和正常的下标值相符合。\n",
    "        print('i%d=argmax[deltaT(i)]=%d' % (M, I[0][M - 1]))\n",
    "        for t in range(M - 2, -1, -1):\n",
    "            I[0][t] = psis[int(I[0][t + 1]) - 1][t + 1]\n",
    "            print('i%d=psis%d(i%d)=%d' % (t + 1, t + 2, t + 2, I[0][t]))\n",
    "        print(\"状态序列I：\", I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#习题10.1\n",
    "Q = [1, 2, 3]\n",
    "V = ['红', '白']\n",
    "A = [[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]]\n",
    "B = [[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]]\n",
    "# O = ['红', '白', '红', '红', '白', '红', '白', '白']\n",
    "O = ['红', '白', '红', '白']    #习题10.1的例子\n",
    "PI = [[0.2, 0.4, 0.4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMM = HiddenMarkov()\n",
    "# HMM.forward(Q, V, A, B, O, PI)\n",
    "# HMM.backward(Q, V, A, B, O, PI)\n",
    "HMM.viterbi(Q, V, A, B, O, PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = [1, 2, 3]\n",
    "V = ['红', '白']\n",
    "A = [[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]]\n",
    "B = [[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]]\n",
    "O = ['红', '白', '红', '红', '白', '红', '白', '白']\n",
    "PI = [[0.2, 0.3, 0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMM.forward(Q, V, A, B, O, PI)\n",
    "HMM.backward(Q, V, A, B, O, PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "参考代码：https://blog.csdn.net/tudaodiaozhale\n",
    "\n",
    "中文注释制作：机器学习初学者\n",
    "\n",
    "微信公众号：ID:ai-start-com\n",
    "\n",
    "配置环境：python 3.5+\n",
    "\n",
    "代码全部测试通过。\n",
    "![gongzhong](../gongzhong.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
