{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多决策树 - 随机森林 - 随机决策\n",
    "对决策树的一个常见批评是，一旦在回答问题后对训练集进行划分，就不可能重新考虑这个决策。例如，如果我们将男性和女性分开，那么每个后续问题都只涉及男性或女性，而且该方法不能考虑其他类型的问题（例如，年龄不到一岁，不论性别如何）。**随机森林**尝试在每个步骤中引入一定程度的**随机化**，创建备选树并将它们组合来获得最终预测。考虑几个回答相同问题的分类器的这些类型的算法，被称为**集成方法**.   \n",
    "随机森林建议基于训练实例的子集（**带放回随机选择**）来构建决策树，但是在特征集的每个集合中使用少量随机的特征。这种树生长过程重复几次，产生一组分类器。在预测时，给定一个实例的每个成型的树都会像决策树一样预测其目标类。大多数树所投票的类（即树中预测最多的类）是集成分类器所建议的类。  \n",
    "随机森林只是许多树，建立在数据的不同随机子集（带放回抽样）上，并对于每个分裂，使用特征的不同随机子集（无放回抽样）。 这使得树彼此不同，并使它们过拟合不同的方面。 然后，他们的预测被平均，产生更平稳的估计，更少过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sk-learn 官方User Guide的例子 \n",
    "DecisionTreeClassifier 是能够在数据集上执行多分类的类,与其他分类器一样，DecisionTreeClassifier 采用输入两个数组：数组X，用 [n_samples, n_features] 的方式来存放训练样本。整数值数组Y，用 [n_samples] 来保存训练样本的类标签:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=15)\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt_clf, iris.data, iris.target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过训练，我们可以使用 export_graphviz 导出器以 Graphviz 格式导出决策树."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(dt_clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n",
    "# graph.render(\"iris\", format='png')  保存成其他格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export_graphviz 还支持各种美化，包括通过他们的类着色节点（或回归值），如果需要，还能使用显式变量和类名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(dt_clf, out_file=None,\n",
    "                        feature_names=iris.feature_names,\n",
    "                        class_names=iris.target_names,\n",
    "                        filled=True, rounded=True,\n",
    "                        special_characters=True  # 忽略特殊字符\n",
    "                        )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[实用技巧](https://github.com/apachecn/sklearn-doc-zh/blob/master/docs/0.21.3/11.md#1105-%E5%AE%9E%E9%99%85%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[数据科学和人工智能技术笔记 十三、树和森林](https://github.com/apachecn/ds-ai-tech-notes/blob/master/13.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用随机森林\n",
    "clf = RandomForestClassifier(random_state=12345, n_jobs=-1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征的重要性**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算特征重要性  越接近于1 表示越重要\n",
    "importances = clf.feature_importances_  # 所有重要性得分加起来为 100%\n",
    "importances  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整个数据集上的特征重要性分布\n",
    "plt.bar(range(X.shape[1]), importances)\n",
    "plt.title('Feature Importamces')\n",
    "plt.xticks(range(X.shape[1]), iris.feature_names, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用随机森林的特征选择**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用4个特征进行分类的 准确率\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个选择器对象，\n",
    "# 该对象将使用随机森林分类器来标识重要性大于 0.15的特征\n",
    "sfm = SelectFromModel(clf, threshold=0.15)\n",
    "sfm.fit(X_train, y_train)\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)\n",
    "X_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_names = np.array(iris.feature_names)[sfm.get_support()]\n",
    "important_names  # 最重要的2个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用最重要的特征 训练随机森林\n",
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf_important.fit(X_important_train, y_train)\n",
    "# 使用2个特征 的模型准确率\n",
    "y_pred = clf_important.predict(X_important_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在随机森林中处理不平衡类别**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过移除前 40 个观测，生成高度不平衡的类别\n",
    "X = X[30:, ]\n",
    "y = y[30:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中类自动加权，与它们在数据中出现的频率成反比  \n",
    "$$w_j = \\frac {n}{kn_j}$$\n",
    "$w_j$是$j$类的权重, $n$是总观测数, $n_j$是类$j$的观测数, $k$为类的总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0, n_jobs=-1, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [sklearn-cookbook 例子](https://github.com/apachecn/sklearn-cookbook-zh/blob/master/4.md#41-%E4%BD%BF%E7%94%A8%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E7%9A%84%E5%88%86%E7%B1%BB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成n-class(默认2个)的样本\n",
    "# 3特征 其中0冗余 0重复\n",
    "X, y = datasets.make_classification(n_samples=1000, n_features=3, n_redundant=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dt.predict(X)\n",
    "np.mean(preds == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max_depth** 决策树最大深度, 决定了分支的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 200\n",
    "X, y = datasets.make_classification(1000, n_features=n_features, n_informative=5)  # 有用的特征数5个\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "accuracies = [] # 保存正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同的最大深度 的影响\n",
    "for x in range(1, n_features+1):\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=x)\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    score = dt_clf.score(X_test, y_test)\n",
    "    accuracies.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(accuracies) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化处理\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, n_features+1), accuracies)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上在较低最大深度处得到了漂亮的准确率."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "plt.plot(range(1, n_features+1)[:N], accuracies[:N])\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**调整决策树模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_classification(1000, n_features=20, n_informative=3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "def dt_max_depth(*args, **kwargs):\n",
    "    dt = DecisionTreeClassifier(*args, **kwargs)\n",
    "    dt.fit(X_train, y_train)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_dt(dt):\n",
    "    dot_data = export_graphviz(dt, out_file=None)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dt(dt_max_depth())  # 10层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 降低最大深度\n",
    "view_dt(dt_max_depth(max_depth=5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用信息增益(熵)进行分割\n",
    "view_dt(dt_max_depth(max_depth=5, criterion='entropy', min_samples_leaf=10))   # 叶结点最小样本数10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  用决策树解释泰坦尼克号假设\n",
    "[sklearn 学习指南](https://github.com/apachecn/misc-docs-zh/blob/master/docs/learning-sklearn/ch02.md#%E7%94%A8%E5%86%B3%E7%AD%96%E6%A0%91%E8%A7%A3%E9%87%8A%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E5%81%87%E8%AE%BE)\n",
    "\n",
    "属性列表为：Ordinal（序号），Class（等级），Survived（是否幸存，0=no，1=yes），Name（名称），Age（年龄），Port of Embarkation（登船港口），Home/Destination（家/目的地），Room（房间），Ticket（票号），Boat（救生艇）和Sex（性别）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理数据   \n",
    "选择 pclass age sex 这3种数据进行划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X , titanic_y = data.iloc[:, [1, 4, -1]], data.iloc[:, 2]\n",
    "features = titanic_X.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**处理缺失值**\n",
    "\n",
    "将年龄的缺失值用所有人员年龄的平均值进行替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X = titanic_X.fillna(titanic_X.mean())\n",
    "X = titanic_X.values  # pandas -> array\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = titanic_y.values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**类别特征编码**  \n",
    "将标签值转为0..K-1的整数\n",
    "```\n",
    "class sklearn.preprocessing.LabelEncoder\n",
    "    Encode labels with value between 0 and nclasses\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.LabelEncoder()\n",
    "X[:, -1] = enc.fit_transform(X[:, -1])  # 直接对 性别 这一列进行转换\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.classes_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 pclass 进行这样处理,会有3个结果 0, 1, 2.这种转换隐式地引入了类之间的顺序, 但实际却是无序的.  \n",
    "另外一种将标称型特征转换为能够被scikit-learn中模型使用的编码是one-of-K， 又称为**独热码**或dummy encoding。  \n",
    "这种编码类型已经在类`OneHotEncoder`中实现。该类把每一个具有n_categories个可能取值的categorical特征变换为长度为n_categories的二进制特征向量，里面只有一个地方是1，其余位置都是0.  \n",
    "1st 2nd 3rd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将整数特征 变 独热码\n",
    "enc_pclass = preprocessing.OneHotEncoder()\n",
    "enc_pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pclass = enc_pclass.fit_transform(X[:,0][:, np.newaxis]).toarray()\n",
    "new_pclass  # 将pclass列 n个数据变成 n个特征向量, 每个向量中只有一个为1 其余为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((new_pclass, X[:, 1:]), axis=1)  # 最终得到的数据\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pclass.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pclass.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = np.append(enc_pclass.categories_[0], np.array(features[1:]))\n",
    "new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=5)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(dt, out_file=None, feature_names=new_features)\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(X, y, clf):\n",
    "    y_pred = dt.predict(X)\n",
    "    print(f\"Accuracy: {metrics.accuracy_score(y, y_pred):.3f}\")  #  精确度得分\n",
    "    print('Classification report: ')\n",
    "    print(metrics.classification_report(y, y_pred))  # 具体的分类指标\n",
    "    print(\"Confussion matrix\")\n",
    "    \"\"\" 从混淆矩阵的迹除以总和来计算准确度\n",
    "    TN(真阴)  FP(假阳)\n",
    "    FN(假阴)  TP(真阳)\n",
    "    \"\"\"\n",
    "    print(metrics.confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_performance(X_train, y_train, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_performance(X_test, y_test, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**留一交叉验证(LeaveOneOut, LOO)**  \n",
    "每个学习集都是通过除了一个样本以外的所有样本创建的，测试集是被留下的样本。 因此，对于 n 个样本，我们有 n 个不同的训练集和 n 个不同的测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.stats import sem   # 计算平均值的标准误差\n",
    "def loo_cv(X, y, clf):\n",
    "    scores = np.zeros(X.shape[0])\n",
    "    loo = LeaveOneOut()\n",
    "    # test_index 长度为1\n",
    "    for train_index, test_index in loo.split(X):  # [1, 2, 3,...] [0]\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        scores[test_index] = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(f\"Mean score: {np.mean(scores):.3f}(+/-{sem(scores):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_cv(X_train, y_train, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "留一法交叉验证的主要优点是它允许训练的数据几乎与我们可用的数据一样多，因此它特别适用于数据稀缺的情况。其主要问题是，就计算时间而言，为每个实例训练不同的分类器可能是非常昂贵的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=10, random_state=33, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.n_features_  # The number of features when fit is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_performance(X_train, y_train, rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_performance(X_test, y_test, rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_cv(X_train, y_train, rf_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林的结果实际上更糟。毕竟，引入随机化似乎不是一个好主意，因为特征数量太少。然而，对于具有更多特征的更大数据集，随机森林是一种非常快速，简单且流行的方法，可以提高准确率，保留决策树的优点"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
