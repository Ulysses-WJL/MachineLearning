{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．分类决策树模型是表示基于特征对实例进行分类的树形结构。决策树可以转换成一个**if-then**规则的集合，也可以看作是定义在特征空间划分上的类的条件概率分布。\n",
    "\n",
    "2．决策树学习旨在构建一个与训练数据拟合很好，并且复杂度小的决策树。因为从可能的决策树中直接选取最优决策树是NP完全问题。现实中采用启发式方法学习次优的决策树。\n",
    "\n",
    "决策树学习算法包括3部分：特征选择、树的生成和树的剪枝。常用的算法有ID3、\n",
    "C4.5和CART。\n",
    "\n",
    "3．特征选择的目的在于选取对训练数据能够分类的特征。特征选择的关键是其准则。常用的准则如下：\n",
    "\n",
    "（1）样本集合$D$对特征$A$的信息增益（ID3）\n",
    "\n",
    "互信息(mutual information)\n",
    "$$g(D, A)=H(D)-H(D|A)$$\n",
    "   熵(entropy):\n",
    "   $$H(p) = -\\sum_{i=1}^{n}p_ilogp_i$$\n",
    "$$H(D)=-\\sum_{k=1}^{K} \\frac{\\left|C_{k}\\right|}{|D|} \\log _{2} \\frac{\\left|C_{k}\\right|}{|D|}$$\n",
    "\n",
    "   条件熵(conditional entropy):\n",
    "$$H(Y|X) = \\sum_{i=1}^{n}p_iH(Y|X=x_i)$$\n",
    "这里, $p_i = P(X=x_i), i=1, 2, \\cdots, n$\n",
    "$$H(D | A)=\\sum_{i=1}^{n} \\frac{\\left|D_{i}\\right|}{|D|} H\\left(D_{i}\\right)$$\n",
    "当熵和条件熵中的概率由数据统计得到时, 所对应的熵和条件熵被称为经验熵(empirical entropy)和经验条件熵(empirical conditional entropy)\n",
    "\n",
    "其中，$H(D)$是数据集$D$的熵，$H(D_i)$是数据集$D_i$的熵，$H(D|A)$是数据集$D$对特征$A$的条件熵。\t$D_i$是$D$中特征$A$取第$i$个值的样本子集，$C_k$是$D$中属于第$k$类的样本子集。$n$是特征$A$取 值的个数，$K$是类的个数。\n",
    "\n",
    "（2）样本集合$D$对特征$A$的信息增益比（C4.5）\n",
    "\n",
    "\n",
    "$$g_{R}(D, A)=\\frac{g(D, A)}{H_A(D)}$$\n",
    "\n",
    "\n",
    "其中，$g(D,A)$是信息增益，$H_A(D) = -\\sum_{i=1}^{n} \\frac{\\left|C_{i}\\right|}{|D|} \\log _{2} \\frac{\\left|C_{i}\\right|}{|D|}$是数据集$D$关于特征A的值的熵。\n",
    "\n",
    "（3）样本集合$D$的基尼指数（CART）\n",
    "\n",
    "$$\\operatorname{Gini}(D)=1-\\sum_{k=1}^{K}\\left(\\frac{\\left|C_{k}\\right|}{|D|}\\right)^{2}$$\n",
    "\n",
    "特征$A$条件下集合$D$的基尼指数(Gini index)：\n",
    "\n",
    " $$\\operatorname{Gini}(D, A)=\\frac{\\left|D_{1}\\right|}{|D|} \\operatorname{Gini}\\left(D_{1}\\right)+\\frac{\\left|D_{2}\\right|}{|D|} \\operatorname{Gini}\\left(D_{2}\\right)$$\n",
    " \n",
    "4．决策树的生成。通常使用信息增益最大、信息增益比最大或基尼指数最小作为特征选择的准则。决策树的生成往往通过计算信息增益或其他指标，从根结点开始，递归地产生决策树。这相当于用信息增益或其他准则不断地选取局部最优的特征，或将训练集分割为能够基本正确分类的子集。\n",
    "\n",
    "5．决策树的剪枝(pruning)。由于生成的决策树存在过拟合问题，需要对它进行剪枝，以简化学到的决策树。决策树的剪枝，往往从已生成的树上剪掉一些叶结点或叶结点以上的子树，并将其父结点或根结点作为新的叶结点，从而简化生成的决策树(后减枝). 决策树学习的损失函数定义为:\n",
    "$$C_\\alpha(T) = C(T) + \\alpha|T| = \\sum_{t=1}^{|T|}N_tH_t(T) + \\alpha|T|$$\n",
    "\n",
    "式中$C(T)$表示模型对训练数据的预测误差, $|T|$为树的叶节点个数, 表示模型的复杂度, $\\alpha \\geq 0$控制两者之间的关系.  \n",
    "$H_t(T)$为叶节点t的经验熵:\n",
    "$$H_t(T) = -\\sum_k \\frac {N_{tk}}{N_t} log\\frac {N_{tk}}{N_t}$$\n",
    "$N_t$表示叶节点t的样本数量, $N_{tk}$表示其中第k类样本点的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连续值与缺失值处理\n",
    "### 连续值处理\n",
    "如特征取值为连续值, 不能直接根据连续属性的可取值对结点进行划分.使用连续属性离散化技术, 最简单的方略是使用**二分法(bi-partition)**, 这正是$C4.5$决策树算法采用的机制.\n",
    "假定属性A上有n个不同取值, 从小到大为$\\{a^1, a^2, \\dots, a^n\\}$, 可以得到包含n-1个划分元素的集合:\n",
    "$$T_a = \\{ \\frac {a^i + a^{i+1}}{2}\\mid 1 \\leq i \\leq n-1\\}$$\n",
    "\n",
    "### 缺失值处理\n",
    "- 属性缺失的情况下进行划分属性选择: 使用无缺失的数据计算信息增益, 在乘以一个比例$\\rho = \\frac {无缺失样本数}{样本总数}$\n",
    "- 给定划分属性, 样本在该属性上的值缺失: 将取值缺失的样本同时划入所有子结点, 样本取值权值按无缺失值样本占该属性取值样本数的比例进行调整. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import math\n",
    "from math import log\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 书上题目5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 书上题目5.1\n",
    "def create_data():\n",
    "    datasets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(datasets, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    年龄 有工作 有自己的房子 信贷情况 类别\n0   青年   否      否   一般  否\n1   青年   否      否    好  否\n2   青年   是      否    好  是\n3   青年   是      是   一般  是\n4   青年   否      否   一般  否\n5   中年   否      否   一般  否\n6   中年   否      否    好  否\n7   中年   是      是    好  是\n8   中年   否      是  非常好  是\n9   中年   否      是  非常好  是\n10  老年   否      是  非常好  是\n11  老年   否      是    好  是\n12  老年   是      否    好  是\n13  老年   是      否  非常好  是\n14  老年   否      否   一般  否",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>年龄</th>\n      <th>有工作</th>\n      <th>有自己的房子</th>\n      <th>信贷情况</th>\n      <th>类别</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>青年</td>\n      <td>否</td>\n      <td>否</td>\n      <td>一般</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>青年</td>\n      <td>否</td>\n      <td>否</td>\n      <td>好</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>青年</td>\n      <td>是</td>\n      <td>否</td>\n      <td>好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>青年</td>\n      <td>是</td>\n      <td>是</td>\n      <td>一般</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>青年</td>\n      <td>否</td>\n      <td>否</td>\n      <td>一般</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>中年</td>\n      <td>否</td>\n      <td>否</td>\n      <td>一般</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>中年</td>\n      <td>否</td>\n      <td>否</td>\n      <td>好</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>中年</td>\n      <td>是</td>\n      <td>是</td>\n      <td>好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>中年</td>\n      <td>否</td>\n      <td>是</td>\n      <td>非常好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>中年</td>\n      <td>否</td>\n      <td>是</td>\n      <td>非常好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>老年</td>\n      <td>否</td>\n      <td>是</td>\n      <td>非常好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>老年</td>\n      <td>否</td>\n      <td>是</td>\n      <td>好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>老年</td>\n      <td>是</td>\n      <td>否</td>\n      <td>好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>老年</td>\n      <td>是</td>\n      <td>否</td>\n      <td>非常好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>老年</td>\n      <td>否</td>\n      <td>否</td>\n      <td>一般</td>\n      <td>否</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['是', '否'], dtype='object')"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train_data.iloc[:, -1].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    年龄 有工作 信贷情况 类别\n0   青年   否   一般  否\n1   青年   否    好  否\n2   青年   是    好  是\n3   青年   是   一般  是\n4   青年   否   一般  否\n5   中年   否   一般  否\n6   中年   否    好  否\n7   中年   是    好  是\n8   中年   否  非常好  是\n9   中年   否  非常好  是\n10  老年   否  非常好  是\n11  老年   否    好  是\n12  老年   是    好  是\n13  老年   是  非常好  是\n14  老年   否   一般  否",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>年龄</th>\n      <th>有工作</th>\n      <th>信贷情况</th>\n      <th>类别</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>青年</td>\n      <td>否</td>\n      <td>一般</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>青年</td>\n      <td>否</td>\n      <td>好</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>青年</td>\n      <td>是</td>\n      <td>好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>青年</td>\n      <td>是</td>\n      <td>一般</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>青年</td>\n      <td>否</td>\n      <td>一般</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>中年</td>\n      <td>否</td>\n      <td>一般</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>中年</td>\n      <td>否</td>\n      <td>好</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>中年</td>\n      <td>是</td>\n      <td>好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>中年</td>\n      <td>否</td>\n      <td>非常好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>中年</td>\n      <td>否</td>\n      <td>非常好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>老年</td>\n      <td>否</td>\n      <td>非常好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>老年</td>\n      <td>否</td>\n      <td>好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>老年</td>\n      <td>是</td>\n      <td>好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>老年</td>\n      <td>是</td>\n      <td>非常好</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>老年</td>\n      <td>否</td>\n      <td>一般</td>\n      <td>否</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_data.drop(['有自己的房子'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 熵\n",
    "def calc_ent(datasets):\n",
    "    data_length = len(datasets)\n",
    "    label_count = {}\n",
    "    for i in range(data_length):\n",
    "        label = datasets[i][-1]\n",
    "#         if label not in label_count:\n",
    "#             label_count[label] = 0\n",
    "        label_count[label] = label_count.get(label, 0) + 1\n",
    "    ent = -sum([(p / data_length) * log(p / data_length, 2)\n",
    "                for p in label_count.values()])\n",
    "    return ent\n",
    "# def entropy(y):\n",
    "#     \"\"\"\n",
    "#     Entropy of a label sequence\n",
    "#     \"\"\"\n",
    "#     hist = np.bincount(y)\n",
    "#     ps = hist / np.sum(hist)\n",
    "#     return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "\n",
    "# 经验条件熵\n",
    "def cond_ent(datasets, axis=0):\n",
    "    # axis 代表选择哪个特征\n",
    "    data_length = len(datasets)\n",
    "    feature_sets = {}\n",
    "    for i in range(data_length):\n",
    "        feature = datasets[i][axis]\n",
    "        if feature not in feature_sets:\n",
    "            feature_sets[feature] = []  #  {'青年': [(数据1), (数据2)], ...}\n",
    "        feature_sets[feature].append(datasets[i])  # 按特征axis的取值划分datasets\n",
    "    cond_ent = sum(\n",
    "        [(len(p) / data_length) * calc_ent(p) for p in feature_sets.values()])\n",
    "    return cond_ent\n",
    "\n",
    "\n",
    "# 信息增益\n",
    "def info_gain(ent, cond_ent):\n",
    "    return ent - cond_ent\n",
    "\n",
    "\n",
    "def info_gain_train(datasets):\n",
    "    count = len(datasets[0]) - 1\n",
    "    ent = calc_ent(datasets)\n",
    "#     ent = entropy(datasets)\n",
    "    best_feature = []\n",
    "    for c in range(count):\n",
    "        c_info_gain = info_gain(ent, cond_ent(datasets, axis=c))\n",
    "        best_feature.append((c, c_info_gain))\n",
    "        print('特征({}) - info_gain - {:.3f}'.format(labels[c], c_info_gain))\n",
    "    # 比较大小\n",
    "    best_ = max(best_feature, key=lambda x: x[-1])\n",
    "    return '特征({})的信息增益最大，选择为根节点特征'.format(labels[best_[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "特征(年龄) - info_gain - 0.083\n特征(有工作) - info_gain - 0.324\n特征(有自己的房子) - info_gain - 0.420\n特征(信贷情况) - info_gain - 0.363\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'特征(有自己的房子)的信息增益最大，选择为根节点特征'"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "info_gain_train(np.array(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, leaf=False, label=None, feature=None, parent_feature_value=None):\n",
    "        self.leaf = leaf  # 当前节点是否为叶节点\n",
    "        self.label = label  # 叶节点的分类\n",
    "        self.feature = feature  # 当前节点 划分子集使用的特征编号\n",
    "        self.parent_feature_value = parent_feature_value  # 当前节点关于 父节点使用的特征的取值\n",
    "        self.sub_nodes = {}  # 子节点\n",
    "    \n",
    "    def predict(self, features):\n",
    "        if self.leaf:\n",
    "            return self.label\n",
    "        return self.sub_nodes[features[self.feature]].predict(features)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "利用ID3算法生成决策树，例5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义节点类 二叉树\n",
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root  # 当前节点是叶节点了\n",
    "        self.label = label  # 节点的分类\n",
    "        self.feature_name = feature_name  # 节点划分子集使用的特征名\n",
    "        self.feature = feature   # 当前节点 划分子集使用的特征编号\n",
    "        self.tree = {}  # 子节点\n",
    "\n",
    "    def __repr__(self): \n",
    "        result = {\n",
    "            'label': self.label,\n",
    "            'feature': self.feature_name,\n",
    "            'tree': self.tree\n",
    "        }\n",
    "        if not self.label:\n",
    "            result.pop('label')\n",
    "        if not self.tree:\n",
    "            result.pop('tree')\n",
    "        if not self.feature_name:\n",
    "            result.pop('feature')\n",
    "        return '{}'.format(result)\n",
    "\n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "\n",
    "    def predict(self, features):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features) # 向子节点进行查找\n",
    "\n",
    "\n",
    "class DTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon  # 信息增益阈值eta\n",
    "        self._tree = {}\n",
    "\n",
    "    # 熵\n",
    "    @staticmethod\n",
    "    def calc_ent(datasets):\n",
    "        data_length = len(datasets)\n",
    "        label_count = {}\n",
    "        for i in range(data_length):\n",
    "            label = datasets[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        ent = -sum([(p / data_length) * log(p / data_length, 2)\n",
    "                    for p in label_count.values()])\n",
    "        return ent\n",
    "\n",
    "    # 经验条件熵\n",
    "    def cond_ent(self, datasets, axis=0):\n",
    "        data_length = len(datasets)\n",
    "        feature_sets = {}\n",
    "        for i in range(data_length):\n",
    "            feature = datasets[i][axis]\n",
    "            if feature not in feature_sets:\n",
    "                feature_sets[feature] = []\n",
    "            feature_sets[feature].append(datasets[i])\n",
    "        cond_ent = sum([(len(p) / data_length) * self.calc_ent(p)\n",
    "                        for p in feature_sets.values()])\n",
    "        return cond_ent\n",
    "\n",
    "    # 信息增益\n",
    "    @staticmethod\n",
    "    def info_gain(ent, cond_ent):\n",
    "        return ent - cond_ent\n",
    "\n",
    "    def info_gain_train(self, datasets):\n",
    "        count = len(datasets[0]) - 1\n",
    "        ent = self.calc_ent(datasets)\n",
    "        best_feature = []\n",
    "        for c in range(count):\n",
    "            c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "        # 比较大小\n",
    "        best_ = max(best_feature, key=lambda x: x[-1])\n",
    "        return best_  # (特征, 信息增益)\n",
    "\n",
    "    def train(self, train_data):\n",
    "        \"\"\"\n",
    "        input:数据集D(DataFrame格式)，特征集A，阈值eta\n",
    "        output:决策树T\n",
    "        \"\"\"\n",
    "        y_train, features =  train_data.iloc[:,-1], train_data.columns[:-1]\n",
    "        # 1,若D中实例属于同一类Ck，则T为单节点树，并将类Ck作为结点的类标记，返回T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root=True, label=y_train.iloc[0])\n",
    "\n",
    "        # 2, 若A为空，没有特征继续进行划分了, 则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T\n",
    "        if len(features) == 0:\n",
    "            return Node(\n",
    "                root=True,\n",
    "                label=y_train.value_counts().sort_values(\n",
    "                    ascending=False).index[0])\n",
    "\n",
    "        # 3,计算最大信息增益 同5.1,Ag为信息增益最大的特征\n",
    "        max_feature, max_info_gain = self.info_gain_train(np.array(train_data))\n",
    "        max_feature_name = features[max_feature]\n",
    "\n",
    "        # 4,Ag的信息增益小于阈值eta,则置T为单节点树，并将D中是实例数最大的类Ck作为该节点的类标记，返回T\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(\n",
    "                root=True,\n",
    "                label=y_train.value_counts().sort_values(\n",
    "                    ascending=False).index[0])\n",
    "\n",
    "        # 5,构建Ag子集\n",
    "        node_tree = Node(\n",
    "            root=False, feature_name=max_feature_name, feature=max_feature)\n",
    "\n",
    "        feature_list = train_data[max_feature_name].value_counts().index  # 列的名称\n",
    "        for f in feature_list:\n",
    "            # 子集要去掉父节点使用的特征列 A-Ag\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] ==\n",
    "                                          f].drop([max_feature_name], axis=1)\n",
    "\n",
    "            # 6, 递归生成树\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "\n",
    "        # pprint.pprint(node_tree.tree)\n",
    "        return node_tree\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self._tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()\n",
    "data_df = pd.DataFrame(datasets, columns=labels)\n",
    "dt = DTree()\n",
    "tree = dt.fit(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'feature': '有自己的房子', 'tree': {'否': {'feature': '有工作', 'tree': {'否': {'label': '否'}, '是': {'label': '是'}}}, '是': {'label': '是'}}}\n"
    }
   ],
   "source": [
    "pprint.pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'否'"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "dt.predict(['老年', '否', '否', '一般'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART 分类树 \n",
    "---\n",
    "无剪枝, 具体实例可见 集成方法-随机森林-声呐信号分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义节点类 CART 二叉树\n",
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature=None, value=None):\n",
    "        self.root = root  # 当前节点是叶节点了\n",
    "        self.label = label  # 节点的分类\n",
    "        # self.feature_name = feature_name  # 节点划分子集使用的特征名\n",
    "        self.feature = feature   # 当前节点 划分子集使用的特征编号\n",
    "        self.tree = {}  # 子节点\n",
    "        self.value = value  # 分割值\n",
    "\n",
    "    def __repr__(self): \n",
    "        result = {\n",
    "            'label': self.label,\n",
    "            'feature': self.feature,\n",
    "            'value': self.value,\n",
    "            'tree': self.tree\n",
    "        }\n",
    "        if not self.label:\n",
    "            result.pop('label')\n",
    "        if not self.tree:\n",
    "            result.pop('tree')\n",
    "        if not self.feature:\n",
    "            result.pop('feature')\n",
    "        if self.value is None:\n",
    "            result.pop('value')   \n",
    "        return '{}'.format(result)\n",
    "\n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "\n",
    "    def predict(self, X):\n",
    "        # X 单个特征样本\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        if X[self.feature] >= self.value :\n",
    "            return self.tree['left'].predict(X)\n",
    "        else:\n",
    "            return self.tree['right'].predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "a = np.arange(9).reshape(3, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([False,  True,  True])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "a[:, 2] > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self, epsilon=0.1, sample_least=5):\n",
    "        self.epsilon = epsilon  # 基尼指数阈值\n",
    "        self.sample_least = sample_least\n",
    "        self._tree = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini_(y1, y2):\n",
    "        # 获取当前样本集 的gini指数\n",
    "        ginis = []\n",
    "        \n",
    "        for y in (y1, y2):\n",
    "            # Gini(D) = 1- \\sum (|C_k|/|D|)^2\n",
    "            labels, counts = np.unique(y, return_counts=True)\n",
    "            gini = 1- np.sum((counts / np.sum(counts)) ** 2)\n",
    "            ginis.append(gini)\n",
    "        # Gini(D, A) = |D1| / |D| * gini(D1) + |D2| / |D| * gini(D2)\n",
    "        A = np.array([len(y1), len(y2)])\n",
    "        # print(ginis, A)\n",
    "        gini_A = (ginis * (A / A.sum())).sum()\n",
    "        return gini_A\n",
    "    \n",
    "    @staticmethod\n",
    "    def data_split(X, feature, value):\n",
    "        # 根据特征和value 分割数据 返回序号\n",
    "        data_set = X[:, feature]\n",
    "        left = data_set >= value\n",
    "        right = ~left\n",
    "        return left, right\n",
    "        # left , right = [], []\n",
    "        # for i in range(len(data_set)):\n",
    "        #     if data_set[i] >= value:\n",
    "        #         left.append(i)\n",
    "        #     else:\n",
    "        #         right.append(i)\n",
    "        # return left, right\n",
    "    \n",
    "    def choose_best_value(self, data, y, feature):\n",
    "        # 返回最佳分割点和相应的gini指数\n",
    "        # 选定特征A, A的不同划分取值a 下的gini指数\n",
    "        value_split_list = np.sort(data[:, feature])\n",
    "        value_split = (value_split_list[1:] + value_split_list[:-1]) / 2\n",
    "        gini_one_feature = []\n",
    "        \n",
    "        for value in value_split:\n",
    "            # 每个划分点计算 基尼指数\n",
    "            left, right = self.data_split(data, feature, value)\n",
    "            gini = self.gini_(y[left], y[right])\n",
    "            gini_one_feature.append(gini)\n",
    "        # 得到最小的gini\n",
    "        min_index = np.argmin(gini_one_feature)\n",
    "        return value_split[min_index], gini_one_feature[min_index] \n",
    "\n",
    "    def choose_best_feature(self, X, y, features):\n",
    "        # 寻找最好的 分割特征和分割值\n",
    "        temp = np.zeros((len(features), 3))\n",
    "        for i, feature in enumerate(features):\n",
    "            value, gini = self.choose_best_value(X, y, feature)\n",
    "            temp[i] = [gini, feature, value]\n",
    "        best = np.argmin(temp[:, 0])\n",
    "        return temp[best]\n",
    "    \n",
    "    def build_tree(self, X, y, features):\n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "        u, counts = np.unique(y, return_counts=True)\n",
    "        # 1, 样本个数小于预订阈值, 多数表决\n",
    "        if len(X) < self.sample_least:\n",
    "            return Node(root=True, label=u[counts.argmax()])\n",
    "        \n",
    "        # 2, 若A为空，没有特征继续进行划分了, 则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T\n",
    "        if len(features) == 0:\n",
    "            return Node(root=True, label=u[counts.argmax()])\n",
    "        \n",
    "        # 3. 计算 最佳的特征 分割点 gini\n",
    "        gini, feature, value = self.choose_best_feature(X, y, features)\n",
    "        # 3个一同存储的, 会变成float类型\n",
    "        feature = int(feature)\n",
    "        \n",
    "        # 4 gini指数小于某一值\n",
    "        if gini < self.epsilon:\n",
    "            return Node(root=True, label=u[counts.argmax()], value=value)\n",
    "        \n",
    "        # 5 构建结点\n",
    "        node_tree = Node(root=False, feature=feature, value=value)\n",
    "        features_copy = features.copy()  # 纯数字list的copy\n",
    "        features_copy.remove(feature)\n",
    "        # 左>=  右<\n",
    "        # 6 递归生成树\n",
    "        left, right = self.data_split(X, feature, value)\n",
    "        # print(len(left), len(right), X.shape, y.shape)\n",
    "        left_tree = self.build_tree(X[left], y[left], features_copy)\n",
    "        node_tree.add_node('left', left_tree)\n",
    "        right_tree = self.build_tree(X[right], y[right], features_copy)\n",
    "        node_tree.add_node('right', right_tree)\n",
    "        \n",
    "        return node_tree\n",
    "        \n",
    "    def fit(self, X, y, features):\n",
    "        self._tree = self.build_tree(X, y, features)\n",
    "        return self._tree\n",
    "            \n",
    "    def predict(self, X):\n",
    "        ret = []\n",
    "        for sample in X:\n",
    "            ret.append(self._tree.predict(sample))\n",
    "        return ret\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.sum(y_pred == y) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = [\n",
    "        'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "    ]\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    # print(data)\n",
    "    return data[:, :2], data[:, -1]\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeClassifier()"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()  # 默认gini  基尼系数   CART\n",
    "# DecisionTreeClassifier 既能用于二分类（其中标签为[-1,1]）也能用于多分类（其中标签为[0,…,k-1]）\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8666666666666667"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "dt_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'digraph Tree {\\nnode [shape=box] ;\\n0 [label=\"X[2] <= 2.45\\\\ngini = 0.664\\\\nsamples = 105\\\\nvalue = [36, 31, 38]\"] ;\\n1 [label=\"gini = 0.0\\\\nsamples = 36\\\\nvalue = [36, 0, 0]\"] ;\\n0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\\n2 [label=\"X[2] <= 4.85\\\\ngini = 0.495\\\\nsamples = 69\\\\nvalue = [0, 31, 38]\"] ;\\n0 -> 2 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\\n3 [label=\"X[0] <= 5.0\\\\ngini = 0.061\\\\nsamples = 32\\\\nvalue = [0, 31, 1]\"] ;\\n2 -> 3 ;\\n4 [label=\"X[3] <= 1.35\\\\ngini = 0.5\\\\nsamples = 2\\\\nvalue = [0, 1, 1]\"] ;\\n3 -> 4 ;\\n5 [label=\"gini = 0.0\\\\nsamples = 1\\\\nvalue = [0, 1, 0]\"] ;\\n4 -> 5 ;\\n6 [label=\"gini = 0.0\\\\nsamples = 1\\\\nvalue = [0, 0, 1]\"] ;\\n4 -> 6 ;\\n7 [label=\"gini = 0.0\\\\nsamples = 30\\\\nvalue = [0, 30, 0]\"] ;\\n3 -> 7 ;\\n8 [label=\"gini = 0.0\\\\nsamples = 37\\\\nvalue = [0, 0, 37]\"] ;\\n2 -> 8 ;\\n}'"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# 使用 export_graphviz 导出器以 Graphviz 格式导出决策树\n",
    "tree_pic = export_graphviz(dt_clf, out_file=\"mytree\")\n",
    "with open('mytree') as f:\n",
    "    dot_graph = f.read()\n",
    "dot_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<graphviz.files.Source at 0x7f9386b73590>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"453pt\" height=\"477pt\"\n viewBox=\"0.00 0.00 452.50 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-473 448.5,-473 448.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"292.5,-469 134.5,-469 134.5,-401 292.5,-401 292.5,-469\"/>\n<text text-anchor=\"middle\" x=\"213.5\" y=\"-453.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 2.45</text>\n<text text-anchor=\"middle\" x=\"213.5\" y=\"-438.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.664</text>\n<text text-anchor=\"middle\" x=\"213.5\" y=\"-423.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 105</text>\n<text text-anchor=\"middle\" x=\"213.5\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [36, 31, 38]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"202.5,-357.5 62.5,-357.5 62.5,-304.5 202.5,-304.5 202.5,-357.5\"/>\n<text text-anchor=\"middle\" x=\"132.5\" y=\"-342.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"132.5\" y=\"-327.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 36</text>\n<text text-anchor=\"middle\" x=\"132.5\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [36, 0, 0]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M186.9776,-400.9465C178.1413,-389.6012 168.2932,-376.9567 159.4266,-365.5724\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"162.0783,-363.281 153.1723,-357.5422 156.5556,-367.5823 162.0783,-363.281\"/>\n<text text-anchor=\"middle\" x=\"150.0879\" y=\"-378.6512\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"370,-365 221,-365 221,-297 370,-297 370,-365\"/>\n<text text-anchor=\"middle\" x=\"295.5\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 4.85</text>\n<text text-anchor=\"middle\" x=\"295.5\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.495</text>\n<text text-anchor=\"middle\" x=\"295.5\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 69</text>\n<text text-anchor=\"middle\" x=\"295.5\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 31, 38]</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M240.3499,-400.9465C247.3583,-392.0578 254.9955,-382.3716 262.291,-373.1188\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"265.1467,-375.1498 268.5898,-365.13 259.6498,-370.8157 265.1467,-375.1498\"/>\n<text text-anchor=\"middle\" x=\"271.5263\" y=\"-386.2569\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"286.5,-261 146.5,-261 146.5,-193 286.5,-193 286.5,-261\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 5.0</text>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.061</text>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 32</text>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 31, 1]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M269.6324,-296.9465C262.8804,-288.0578 255.5226,-278.3716 248.4941,-269.1188\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"251.2617,-266.976 242.4257,-261.13 245.6875,-271.2102 251.2617,-266.976\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"444.5,-253.5 304.5,-253.5 304.5,-200.5 444.5,-200.5 444.5,-253.5\"/>\n<text text-anchor=\"middle\" x=\"374.5\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"374.5\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 37</text>\n<text text-anchor=\"middle\" x=\"374.5\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 37]</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.3676,-296.9465C329.9857,-285.6012 339.5906,-272.9567 348.2383,-261.5724\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"351.0763,-263.6224 354.3382,-253.5422 345.5021,-259.3882 351.0763,-263.6224\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"205,-157 74,-157 74,-89 205,-89 205,-157\"/>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 1.35</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 1]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M191.2873,-192.9465C184.7727,-184.1475 177.6795,-174.5672 170.8918,-165.3993\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.5327,-163.0843 164.7693,-157.13 167.9069,-167.2496 173.5327,-163.0843\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"363.5,-149.5 223.5,-149.5 223.5,-96.5 363.5,-96.5 363.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"293.5\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"293.5\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 30</text>\n<text text-anchor=\"middle\" x=\"293.5\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 30, 0]</text>\n</g>\n<!-- 3&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>3&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M241.7127,-192.9465C250.0311,-181.7113 259.2927,-169.2021 267.6574,-157.9043\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"270.7111,-159.6618 273.8486,-149.5422 265.0852,-155.4965 270.7111,-159.6618\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"131,-53 0,-53 0,0 131,0 131,-53\"/>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 0]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M113.4104,-88.9777C106.5289,-80.0039 99.0944,-70.3089 92.1822,-61.295\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.8744,-59.0541 86.0118,-53.2485 89.3196,-63.3137 94.8744,-59.0541\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"280,-53 149,-53 149,0 280,0 280,-53\"/>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 1]</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M165.9422,-88.9777C172.9167,-80.0039 180.4516,-70.3089 187.4573,-61.295\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.3379,-63.292 193.711,-53.2485 184.8109,-58.9964 190.3379,-63.292\"/>\n</g>\n</g>\n</svg>\n"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'iris.png'"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "dot_data  = export_graphviz(dt_clf, out_file=None)  # 生成.dot数据\n",
    "graph = graphviz.Source(dot_data)  # 转为graph\n",
    "graph.render('iris', format='png', view=True)  # 生成其他类型 默认会生成pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "参考代码：https://github.com/wzyonggege/statistical-learning-method\n",
    "\n",
    "中文注释制作：机器学习初学者\n",
    "\n",
    "微信公众号：ID:ai-start-com\n",
    "\n",
    "配置环境：python 3.5+\n",
    "\n",
    "代码全部测试通过。\n",
    "![gongzhong](../gongzhong.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}