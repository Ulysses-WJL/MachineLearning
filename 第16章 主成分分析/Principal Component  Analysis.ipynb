{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析PCA\n",
    "---\n",
    "主成分分析是一种常用的无监督学习方法, 这一方法利用正交变换把由**线性相关**变量表示的观测数据转换为少数几个由**线性无关**变量表示的数据, 线性无关的变量称为**主成分**.主成分的个数通常小于原始变量的个数, 所以主成分分析属于**降维**方法\n",
    "> 所谓线性相关的$x_1$和$x_2$就是说知道$x_1$的值的情况下，$x_2$的预测不是完全随机的\n",
    "\n",
    "## 总体主成分分析\n",
    "### 基本想法\n",
    "数据的变量之间可能存在相关性, 以致增加分析的难度.于是, 考虑由少数不相关的变量(新变量), 用来表示数据, 并且要求能保留数据中的大部分信息.\n",
    "1. 对数据进行规范化: 不同变量可能有不同的量纲，直接求主成分有时会产生不合理的结果。常对各个随机变量实施规范化，使其均值为0，方差为1。\n",
    "1. 正交变换: 将原来线性相关变量表示的数据,通过正交变换成若干个线性无关的新变量表示的数据. 新变量是可能的正交变换中变量的**方差的和**(信息保存)最大的\n",
    "\n",
    "### 定义\n",
    "假设m维变量$\\boldsymbol x = (x_1, x_2, \\cdots, x_m)^T$, 其均值向量\n",
    "$$\\boldsymbol\\mu = E(\\boldsymbol x) = (\\mu_1, \\mu_2, \\cdots, \\mu_m)$$\n",
    "协方差矩阵\n",
    "$$\\Sigma = cov(\\boldsymbol x, \\boldsymbol x) = E[(\\boldsymbol x - \\boldsymbol \\mu)(\\boldsymbol x - \\boldsymbol \\mu)^T]$$\n",
    "将$\\boldsymbol x$线性变换到$\\boldsymbol y = (y_1, y_2, \\cdots, y_m)^T$\n",
    "$$y_i = \\alpha_i^T \\boldsymbol x = \\alpha_{1i} x_1 + \\alpha_{2i} x_2 + \\cdots + \\alpha_{mi} x_m $$\n",
    "其中$\\alpha_i^T = (\\alpha_{1i}, \\alpha_{2i}, \\cdots, \\alpha_{mi}) \\quad i=1, 2, \\cdots, m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
