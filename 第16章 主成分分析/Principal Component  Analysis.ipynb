{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析PCA\n",
    "---\n",
    "主成分分析是一种常用的无监督学习方法, 这一方法利用正交变换把由**线性相关**变量表示的观测数据转换为少数几个由**线性无关**变量表示的数据, 线性无关的变量称为**主成分**.主成分的个数通常小于原始变量的个数, 所以主成分分析属于**降维**方法\n",
    "> 所谓线性相关的$x_1$和$x_2$就是说知道$x_1$的值的情况下，$x_2$的预测不是完全随机的\n",
    "\n",
    "## 总体主成分分析\n",
    "### 基本想法\n",
    "数据的变量之间可能存在相关性, 以致增加分析的难度.于是, 考虑由少数不相关的变量(新变量), 用来表示数据, 并且要求能保留数据中的大部分信息.\n",
    "1. 对数据进行规范化: 不同变量可能有不同的量纲，直接求主成分有时会产生不合理的结果。常对各个随机变量实施规范化，使其均值为0，方差为1。\n",
    "1. 正交变换: 将原来线性相关变量表示的数据,通过正交变换成若干个线性无关的新变量表示的数据. 新变量是可能的正交变换中变量的**方差的和**(信息保存)最大的\n",
    "\n",
    "### 定义\n",
    "假设m维变量$\\boldsymbol x = (x_1, x_2, \\cdots, x_m)^T$, 其均值向量\n",
    "$$\\boldsymbol\\mu = E(\\boldsymbol x) = (\\mu_1, \\mu_2, \\cdots, \\mu_m)$$\n",
    "协方差矩阵\n",
    "$$\\Sigma = cov(\\boldsymbol x, \\boldsymbol x) = E[(\\boldsymbol x - \\boldsymbol \\mu)(\\boldsymbol x - \\boldsymbol \\mu)^T]$$\n",
    "将$\\boldsymbol x$线性变换到$\\boldsymbol y = (y_1, y_2, \\cdots, y_m)^T$\n",
    "$$y_i = \\alpha_i^T \\boldsymbol x = \\alpha_{1i} x_1 + \\alpha_{2i} x_2 + \\cdots + \\alpha_{mi} x_m $$\n",
    "其中$\\alpha_i^T = (\\alpha_{1i}, \\alpha_{2i}, \\cdots, \\alpha_{mi}) \\quad i=1, 2, \\cdots, m$\n",
    "\n",
    "由随机变量的性质可知,\n",
    "$$E(y_i) = \\alpha_i^T\\boldsymbol x,  \\\\ \n",
    "var(y_i) = \\alpha_i^T\\Sigma\\alpha_i, \\\\\n",
    "cov(y_i, y_j) = \\alpha_i^T\\Sigma\\alpha_j, \\\\\n",
    "$$\n",
    "总体主成分定义: 给定一个 $y_i$的线性变换, 如果他们满足条件\n",
    "1. 系数向量$\\alpha_i^T$是单位向量, 即$\\alpha_i^T \\alpha_i = 1$(正交变换), \n",
    "1. 变量$y_i$与变量$y_j$互不相关, 即$cov(y_i, y_j) = 0$,\n",
    "1. 变量$y_1$是$\\boldsymbol x$的所有线性变换中方差最大的(第一主成分), $y_2$是与$y_1$不相关的x的所有线性变换中方差最大的(第二主成分), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主要性质\n",
    "1. $x$的第k主成分的方差是$$var(y_k) = \\alpha_k^T\\Sigma\\alpha_k = \\lambda_k$$,即协方差矩阵$\\Sigma$的第k个特征值\n",
    "1. y = A^Tx , A为正交矩阵($A^T = A^{-1}$)\n",
    "$$A = \\begin{bmatrix}\\alpha_{11}& \\alpha_{12}& \\cdots& \\alpha_{1m} \\\\\n",
    "\\alpha_{21}& \\alpha_{22}& \\cdots& \\alpha_{2m} \\\\\n",
    "\\vdots& \\vdots&  & \\vdots \\\\\n",
    "\\alpha_{m1}& \\alpha_{m2}& \\cdots& \\alpha_{mm}\n",
    "\\end{bmatrix}$$\n",
    "1. 总体主成分y的协方差矩阵为对角矩阵$$\\mathrm{cov}(\\boldsymbol{y})=\\Lambda=\\mathrm{diag}(\\lambda_1,\\lambda_2,\\cdots,\\lambda_m)$$\n",
    "1. 总体主成分y的方差之和等于随机变量x的方差之和$$\\sum\\limits_{i=1}^m\\lambda_i=\\sum\\limits_{i=1}^m\\sigma_{ii}$$\n",
    " $\\sigma_{ii}$是随机变量$x_i$的方差, 即协方差矩阵$\\Sigma$的对角元素\n",
    "$$\\sum\\limits_{i=1}^m \\mathrm{var}(x_i)=\\mathrm{tr}(\\mit{\\Sigma}^\\mathrm{T}\\mathrm)=tr\\mathrm(A\\Lambda A^\\mathrm{T}\\mathrm)=\\mathrm{tr}\\mathrm(\\Lambda\\mathrm)=\\sum\\limits_{i=1}^m\\lambda_i=\\sum\\limits_{i=1}^m \\mathrm{var}\\mathrm(y_i\\mathrm)$$\n",
    "1. 因子负荷量(factor loading),\n",
    "$$\\rho(y_k, x_i)=\\frac {\\sqrt{\\lambda_k}\\alpha_{ik}}{\\sqrt{\\sigma_{ii}}}$$,表示第k个主成分和变量$x_i$的相关系数.\n",
    "当$\\rho(y_k, x_i)>0$时代表$y_k与x_i正相关, x_i越大, y_i就越大$, 小于零代表负相关, 等于零表示不相关\n",
    "\n",
    "    第k个主成分$y_k$与m个变量的因子负荷量满足\n",
    "    $$\\sum_{i=1}^m \\sigma_{ii}\\rho^2(y_k, x_i) = \\lambda_k $$\n",
    "    m个主成分与第i个变量的$x_i$的因子负荷量满足\n",
    "    $$\n",
    "    \\sum_{k=1}^m \\rho^2(y_k, x_i) = 1\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主成分的个数\n",
    "主成分分析的主要目的是降维, 所以一般选择$k(k << m)$个主成分(线性无关变量)来代替m个原有变量(线性相关变量)使得问题简化, 并能保留原有变量的大部分信息(方差).\n",
    "将x从m维变换到q维的正交线性变化\n",
    " $$y = B^Tx$$\n",
    "当B为x的前q个主成分时, 能最大限度地保留原有变量方差的信息.\n",
    "\n",
    "**方差贡献率**: 第k主成分的方差贡献率定义为$y_k$的方差与所有方差之和的比\n",
    "$$\\eta_k = \\frac {\\lambda_k}{\\sum_{i=1}^m \\lambda_i}$$\n",
    "**累计方差贡献率**:\n",
    "$$\\sum_{i=1}^k\\eta_i = \\frac {\\sum_{i=1}^k\\lambda_i}{\\sum_{i=1}^m \\lambda_i}$$\n",
    "通常取k使得累计方差贡献率达到规定的百分比以上.\n",
    "\n",
    "k个主成分$y_1, y_2, \\cdots, y_k$对原有变量$x_i$的贡献率($x_i$保留信息的比例)\n",
    "$$\\nu_i = \\rho^2(x_i, (y_1, y_2, \\cdots, y_k)) = \\sum_{j=1}^k \\rho^2(x_i, y_j) = \\sum_{j=1}^k \\frac {\\lambda_j\\alpha_{ij}^2}{\\sigma_{ii}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 规范化变量的总体主成分\n",
    "这部分内容描述了规范化随机变量的总体主成分的性质，概括下就是：特征值，特征值的和，特征变量，特征变量按行求和; 特征变量按列求和。\n",
    "1. 对随机变量进行规范化, 使其均值为0, 方差为1 $$x_i^* = \\frac {x_i - E(x_i)}{\\sqrt{var(x_i)}}$$\n",
    "1. $\\Lambda^*=\\mathrm{diag}(\\lambda_1^*, \\lambda_2^*, \\cdots, \\lambda_m^*)$\n",
    "1. $\\sum\\limits_{k=1}^m \\lambda_k^*=m$\n",
    "1. $\\rho(y_k^*, x_i^*)=\\sqrt{\\lambda_k^*}e_{ik}^*, k,i=1,2,\\cdots,m$\n",
    "1. $\\sum\\limits_{i=1}^m\\rho^2(y_k^*,x_i^*)=\\sum\\limits_{i=1}^m\\lambda_k^*e_{ik}^{*2}=\\lambda_k^*,k=1,2,\\cdots,m$\n",
    "1. $\\sum\\limits_{k=1}^m\\rho^2(y_k^*,x_i^*)=\\sum\\limits_{k=1}^m\\lambda_k^*e_{ik}^{*2}=1,i=1,2,\\cdots,m$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样本主成分分析\n",
    "在观测数据上进行主成分分析就是样本主成分分析.\n",
    "- 样本矩阵\n",
    "$$X = \\begin{bmatrix} \\boldsymbol x_1 & \\boldsymbol x_2&  \\cdots& \\boldsymbol x_n\\end{bmatrix}$$\n",
    "其中$\\boldsymbol x_j = (x_{1j}, x_{2j}, \\cdots, x_{mj})^T$表示第$j$个观测样本.\n",
    "\n",
    "- 样本均值向量\n",
    "$$\\bar x = \\frac 1 n \\sum_{j=1}^n \\boldsymbol x_j$$\n",
    "- 样本协方差矩阵\n",
    "$$S = [s_{ij}]_{m \\times m} \\\\ \n",
    "s_{ij} = \\frac 1 {n-1}\\sum_{k=1}^n(x_{ik} - \\bar x_i)(x_{jk} - \\bar x_j)\n",
    "$$\n",
    "其中$\\bar x_i = \\frac 1 n sum_{k=1}^n x_{ik}$为第i个变量的样本均值.\n",
    "- 样本相关矩阵$R$为\n",
    "$$R = [r_{ij}]_{m\\times m}, \\quad r_{ij} = \\frac {s_{ij}} {\\sqrt{s_{ii}s_{jj}}}, \\quad i,j= 1, 2, \\cdots, m$$\n",
    "- 线性变换后的m维向量$\\boldsymbol y$ \n",
    "$$ y_i = \\alpha_i^T\\boldsymbol x$$\n",
    "$y_i$的样本均值为\n",
    "$$\\bar y_i = \\frac 1 n \\sum_{j=1}\\alpha_i^T\\boldsymbol x_j = \\alpha_i^T \\bar x$$\n",
    "- $y_i$的样本方差\n",
    "$$var(y_i) = \\frac 1{n-1}\\sum_{j=1}^n(\\alpha_i^Tx_j - \\alpha_i^T\\bar x)^2 = \\alpha_i^TS\\alpha_i$$\n",
    "\n",
    "- 任意两个线性变换$y_i$和$y_k$的样本协方差\n",
    "$$cov(y_i, y_k)=\\alpha_i^TS\\alpha_k$$\n",
    "- 规范化后的样本矩阵仍记作X,这是样本协方差矩阵S就是样本相关矩阵R\n",
    "$$R = \\frac 1 {n-1} XX^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关矩阵的特征值分解算法\n",
    "1. 对样本数据进行规范化处理, 样本矩阵仍记为X\n",
    "$$x_{ij}^* = \\frac {x_{ij} - \\bar x_i}{\\sqrt{s_{ii}}} \\\\\n",
    "\\bar x_i = \\frac 1 n \\sum_{j=1}^nx_{ij} \\\\\n",
    "s_{ii} = \\frac 1 {n-1} \\sum_{j=1}^n(x_{ij} - \\bar x_i)^2\n",
    "$$\n",
    "1. 计算样本相关矩阵R\n",
    "$$R= [r_{ij}]_{m\\times m} \\frac 1 {n-1} XX^T \\\\ r_{ij} = \\frac 1 {n-1} \\sum_{l=1}^nx_{il}x_{lj}$$\n",
    "1. 求样本相关矩阵R的k个特征值和对应的k个单位特征向量. 特征方程\n",
    "$$|R - \\lambda I| = 0$$求解得到m个特征值\n",
    "$$\\lambda_1 \\geq \\lambda_2 \\geq \\cdots \\geq \\lambda_m$$\n",
    "求累计方差贡献率$\\sum_{i=1}^k\\eta_i$达到预定值的主成分个数k.\n",
    "再求前k个特征值对应的单位特征向量\n",
    "$$\\alpha_i = (\\alpha_1i, \\alpha_2i, \\cdots, \\alpha_mi)^T$$\n",
    "1. 求k个样本主成分  \n",
    "以k个单位特征向量为系数进行线性变换$$y_i = \\alpha_i^Tx$$\n",
    "1. 计算k个主成分$y_j$与原变量$x_i$的相关系数$\\rho(x_i, y_j)$(因子负荷量),\n",
    "$$\\rho(y_k, x_i)=\\sqrt{\\lambda_k}e_{ik}, k,i=1,2,\\cdots,m$$\n",
    "以及k个主成分对原变量$x_i$的贡献率$\\nu_i$\n",
    "$$\n",
    "\\nu_i=\\rho^2(x_i,(y_1, y_2, \\cdots,y_k))=\\sum_{j=1}^k\\rho^2(x_i,y_j)=\\sum_{j=1}^k\\lambda_ja_{ij}^2\\\\\n",
    "i=1,2,\\cdots,m\n",
    "$$\n",
    "1. 计算n个样本的主成分值  \n",
    "将规范化样本数据带入k个主成分值, 得到n个样本的主成分值\n",
    "$$\n",
    "y_{ij}=(a_{1i},a_{2i},\\cdots,a_{mi})(x_{1j},x_{2j},\\cdots,x_{mj})^\\mathrm{T}=\\sum\\limits_{l=1}^m a_{li}x_{lj}\\\\\n",
    "i=1,2,\\cdots,m, j=1,2,\\cdots,n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**例16.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规范后相关矩阵\n",
    "R = np.array([[1, 0.44, 0.229, 0.33], [0.44, 1 , 0.35, 0.32],\n",
    "              [0.29, 0.35, 1, 0.6], [0.33, 0.32, 0.6, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_, Q = np.linalg.eig(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.15514838, 0.88770169, 0.57042585, 0.38672408])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征值\n",
    "lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44208665,  0.60379618,  0.65959827, -0.2750863 ],\n",
       "       [ 0.47931469,  0.44017854, -0.72282528,  0.21902085],\n",
       "       [ 0.53516279, -0.48102096, -0.10443631, -0.65206586],\n",
       "       [ 0.53704526, -0.4585759 ,  0.17761415,  0.67169004]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征向量矩阵\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征值的和等于维度m\n",
    "np.sum(lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64900193, 0.70365427, 0.78564164, 0.7884052 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(lambda_[0]) * Q[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64900193,  0.56888422],\n",
       "       [ 0.70365427,  0.41472708],\n",
       "       [ 0.78564164, -0.45320795],\n",
       "       [ 0.7884052 , -0.43206069]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取75%累计方差贡献率 等到k =2 \n",
    "# y1 = Q[:, 0]x, y2 = Q[:, 1]x\n",
    "\n",
    "# 因子负荷量 k个主成分和变量 x_i 的相关系数. \n",
    "# rho = \\sqrt(\\lambda_k)\\alpha_ik\n",
    "rho = np.sqrt(lambda_[:2]) * Q[:, :2]\n",
    "rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74483276, 0.66712788, 0.82263024, 0.8082592 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y1, y2对x_i的贡献率 vu = rho^2\n",
    "vu = np.sum(rho ** 2, axis=1)\n",
    "vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11e4fd30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 因子负荷量分布图\n",
    "for i in range(4):\n",
    "    plt.scatter(rho[i, 0], rho[i, 1], label=f'x{i+1}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y_1$是原始特征的线性组合，并且，各个原始特征的权重(系数)基本相同，说明大家同样重要。$y_1$和总成绩有关系。\n",
    "$y_2$的贡献可能更多的体现在文理科的差异上，他们的作用相反。\n",
    "\n",
    "| 类型 | 主成分 | 特征值 | $x_1$ | $x_2$ | $x_3$ | $x_4$ | 方差贡献率 | 备注|\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |---|\n",
    "| 特征向量 |$y_1$| 2.17 | 0.460 | 0.476 | 0.523 | 0.537 | 0.543 ||\n",
    "| 特征向量 |$y_2$| 0.87 | 0.574 | 0.486 | -0.476 | -0.456 | 0.218 |累计0.761|\n",
    "| 因子负荷量|$y_1$|2.17|0.678|0.701|0.770|0.791|$\\sqrt{\\lambda_1}e_{i1}$|平方和=2.169|\n",
    "| 因子负荷量|$y_2$|0.87|0.536|0.697|0.790|0.806|$\\sqrt{\\lambda_2}e_{i2}$|平方和=0.870|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据矩阵的奇异值分解算法\n",
    "\n",
    "关键词：**数据矩阵**，**截断奇异值分解**  \n",
    "算法16.1 主成分分析法  \n",
    "输入：$m\\times n$样本矩阵$X$，每一行元素均值为0。`这里每一行是一个特征`  \n",
    "输出：$k\\times n$样本主成分矩阵$Y$  \n",
    "参数：主成分个数$k$  \n",
    "1. 构造新的$n\\times m$矩阵\n",
    "$$\n",
    "X^\\prime=\\frac{1}{\\sqrt{n-1}}X^\\mathrm{T}\n",
    "$$\n",
    "$X^\\prime$每一列均值为0，其实就是转置了。\n",
    "2. 对矩阵$X^\\prime$进行截断奇异值分解\n",
    "$$\n",
    "X^\\prime=U\\mit{\\Sigma}V^\\mathrm{T}\n",
    "$$\n",
    "矩阵$V$的前$k$列构成$k$个样本主成分\n",
    "3. 求$k\\times n$样本主成分矩阵\n",
    "$$\n",
    "Y=V^\\mathrm{T}X\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 项目案例: 对半导体数据进行降维处理\n",
    "\n",
    "### 项目概述\n",
    "```\n",
    "半导体是在一些极为先进的工厂中制造出来的。设备的生命早期有限，并且花费极其巨大。\n",
    "虽然通过早期测试和频繁测试来发现有瑕疵的产品，但仍有一些存在瑕疵的产品通过测试。\n",
    "如果我们通过机器学习技术用于发现瑕疵产品，那么它就会为制造商节省大量的资金。\n",
    "\n",
    "具体来讲，它拥有590个特征。我们看看能否对这些特征进行降维处理。\n",
    "\n",
    "对于数据的缺失值的问题，我们有一些处理方法(参考第5章)\n",
    "目前该章节处理的方案是：将缺失值NaN(Not a Number缩写)，全部用平均值来替代(如果用0来处理的策略就太差劲了)。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparing():\n",
    "    data = np.loadtxt('secom.data')\n",
    "    _, n_features = data.shape\n",
    "    # 每个特征的NaN值用均值替代\n",
    "    for i in range(n_features):\n",
    "        nan_indices = np.isnan(data[:, i])\n",
    "        mean_data = np.mean(data[~nan_indices, i])\n",
    "        data[nan_indices, i] = mean_data\n",
    "        \n",
    "#         # 标准化\n",
    "#         std = data[:, i].std()\n",
    "#         if std == 0:\n",
    "#             data[:, i] = 0\n",
    "#         else:\n",
    "#             data[:, i] = (data[:, i] - mean_data) / std\n",
    "    return data\n",
    "\n",
    "def stand_(data):\n",
    "    _, n_features = data.shape\n",
    "    data_std = data.copy()\n",
    "    for i in range(n_features):\n",
    "        # 标准化\n",
    "        mean_data = data_std[:, i].mean()\n",
    "        std = data[:, i].std()\n",
    "        if std == 0:\n",
    "            data_std[:, i] = 0\n",
    "        else:\n",
    "            data_std[:, i] = (data_std[:, i] - mean_data) / std\n",
    "    return data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_preparing()\n",
    "data_std = stand_(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(6)\n",
    "pca.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0556, 0.0362, 0.0282, 0.0253, 0.022 , 0.0208])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA1:\n",
    "    # 使用特征值分解的方法\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # 使用特征值分解的方法\n",
    "        # X array-like shape(n_samples, n_features)\n",
    "        # 相关矩阵\n",
    "        n_samples, n_features = X.shape\n",
    "        # 规范化时 除以n, 这里也除以n\n",
    "        R = np.dot(X.T, X) / n_features  # n_features * n_features\n",
    "\n",
    "        # 求相关矩阵R的k个特征值和k个单位特征向量\n",
    "        eigenvalues_, eigenvectors_ = np.linalg.eig(R)\n",
    "        \n",
    "        self.eigenvalues_ = np.real(eigenvalues_)\n",
    "        self.eigenvectors_ = np.real(eigenvectors_)\n",
    "        \n",
    "        # 第k主成分的方差\n",
    "        self.explained_variance_ = self.eigenvalues_\n",
    "        # 方差贡献率\n",
    "        self.explained_variance_ratio_ = self.eigenvalues_ / np.sum(self.eigenvalues_)\n",
    "        \n",
    "    def fit_transform(self, X):\n",
    "        # X array-like shape(n_samples, n_features)\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # k*n_features  n_features*n_samples \n",
    "        return np.dot(self.eigenvectors_[:, :self.n_components].T, X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6883,  2.2321, -0.4147, ...,  1.1219,  1.1428, -2.0069],\n",
       "       [-2.8817, -0.7943, -1.1289, ...,  1.4987,  3.1285,  2.8508],\n",
       "       [-3.7875, -2.8072, -1.2519, ...,  1.2691,  3.4476,  2.332 ],\n",
       "       [-2.6559, -2.0989, -0.4541, ...,  1.1545,  3.2299,  3.905 ],\n",
       "       [ 0.651 ,  0.6133, -0.3436, ...,  0.4895, -0.4285, -0.8127],\n",
       "       [-1.1792, -1.5667,  2.2607, ..., -2.162 ,  3.0725,  3.8516]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1 = PCA1(n_components=6)\n",
    "pca1.fit_transform(data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9254164077785221"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.explained_variance_ratio_[:150].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0059,  0.0242,  0.0089,  0.0088, -0.0148, -0.0135],\n",
       "       [ 0.    , -0.0127,  0.0034,  0.0081,  0.0123,  0.0046],\n",
       "       [ 0.0039, -0.0093,  0.008 ,  0.0135, -0.0011, -0.0003],\n",
       "       ...,\n",
       "       [ 0.0004, -0.0215, -0.0023,  0.0114,  0.0013,  0.04  ],\n",
       "       [ 0.0001, -0.0178, -0.0025,  0.011 ,  0.0031,  0.036 ],\n",
       "       [-0.015 , -0.0177,  0.0093,  0.0034, -0.008 ,  0.0223]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.eigenvectors_[:, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA2:\n",
    "    # 奇异值分解\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "    def fit(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        X_ = X / np.sqrt(n_samples)\n",
    "        U, Sigma, Vt = np.linalg.svd(X_)\n",
    "        \n",
    "        self.eigenvalues_ = Sigma ** 2\n",
    "        self.eigenvectors_ = Vt\n",
    "        # 第k主成分的方差\n",
    "        self.explained_variance_ = self.eigenvalues_\n",
    "        # 方差贡献率\n",
    "        self.explained_variance_ratio_ = self.eigenvalues_ / np.sum(self.eigenvalues_)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        # X array-like shape(n_samples, n_features)\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # k*n_features  n_features*n_samples \n",
    "        return np.dot(self.eigenvectors_[:, :self.n_components], X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA2(6)\n",
    "pca2.fit(data_std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0556, 0.0362, 0.0282, 0.0253, 0.022 , 0.0208])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2.explained_variance_ratio_[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0059, -0.    , -0.0039,  0.0024,  0.0008, -0.    ],\n",
       "       [ 0.0242, -0.0127, -0.0093,  0.033 ,  0.0086,  0.    ],\n",
       "       [ 0.0089,  0.0034,  0.008 ,  0.0254,  0.0213, -0.    ],\n",
       "       ...,\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    , -0.    , -0.    ],\n",
       "       [ 0.    ,  0.    , -0.    ,  0.    , -0.    , -0.    ],\n",
       "       [ 0.    , -0.    , -0.    ,  0.    , -0.    ,  0.027 ]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2.eigenvectors_[:, :6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
